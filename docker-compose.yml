# docker-compose.yml (local/dev)
services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    image: brickers-ai:base
    container_name: brickers-ai-container
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      # ✅ 데이터 및 환경 설정
      - ./.env:/app/.env
      - ./public:/app/public
      # ✅ HuggingFace 모델 캐시 (재시작 시 다시 다운로드 방지)
      - hf_cache:/root/.cache/huggingface
    environment:
      - TZ=Asia/Seoul
      - KIDS_TOTAL_TIMEOUT_SEC=840
      - TRIPO_WAIT_TIMEOUT_SEC=780
      - S3_PREFIX=uploads/ai-generated
      - PYTHONUNBUFFERED=1

      # SQS
      - AWS_SQS_REQUEST_QUEUE_URL=${AWS_SQS_REQUEST_QUEUE_URL}
      - AWS_SQS_RESULT_QUEUE_URL=${AWS_SQS_RESULT_QUEUE_URL}
      - AWS_SQS_ENABLED=${AWS_SQS_ENABLED:-true}
      - SQS_POLL_INTERVAL=${SQS_POLL_INTERVAL:-5}
      - SQS_MAX_MESSAGES=${SQS_MAX_MESSAGES:-1}
      - SQS_VISIBILITY_TIMEOUT=${SQS_VISIBILITY_TIMEOUT:-1800}
      - SQS_WAIT_TIME=${SQS_WAIT_TIME:-10}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - NANO_BANANA_MODEL=${NANO_BANANA_MODEL}

      # Backend stage update
      - BACKEND_URL=${BACKEND_URL:-http://backend:8080}

      # Co-Scientist Memory (RAG)
      - ATLAS_VECTOR_INDEX_MEMORY=${ATLAS_VECTOR_INDEX_MEMORY:-co_scientist_memory_index}
      - HF_EMBED_MODEL=${HF_EMBED_MODEL:-intfloat/multilingual-e5-small}

volumes:
  hf_cache:
