# ============================================================================
# FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼
# Kids Mode AI ì„œë²„ + ì±—ë´‡ APIë¥¼ í†µí•© ì œê³µ
# ============================================================================
from __future__ import annotations

import asyncio
import os
from datetime import datetime

import httpx

from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware

import config
from route import kids_render
from route.sqs_consumer import start_consumer
from route import color_variant
# instructions_pdf router moved to blueprint server
from route import admin             # âœ… [NEW] Admin/Logs
from route import kids_background   # âœ… [NEW] Background Generation

from chat.router import router as chat_router
from chat.memory import InMemoryConversationStore
from chat.service import ChatService


# ============================================================================
# ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë‹¨ í•œ ë²ˆë§Œ!)
# ============================================================================
app = FastAPI(title="Brickers AI API", version="0.2.0")

# âœ… [DEBUG] ëª¨ë“  ìš”ì²­ì„ ê°•ì œë¡œ ì°ì–´ë³´ëŠ” ë¯¸ë“¤ì›¨ì–´ (ê°•ë ¥í•œ ë²„ì „)
@app.middleware("http")
async def debug_middleware(request, call_next):
    print(f"\n>>>> [DEBUG_IN] {request.method} {request.url.path} <<<<", flush=True)
    response = await call_next(request)
    print(f">>>> [DEBUG_OUT] {response.status_code} for {request.url.path} <<<<\n", flush=True)
    return response

# ============================================================================
# CORS ë¯¸ë“¤ì›¨ì–´
# ============================================================================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # âœ… ë°°í¬/ë¡œì»¬ ëª¨ë‘ í—ˆìš© (ë³´ì•ˆìƒ í•„ìš”ì‹œ ë„ë©”ì¸ ì§€ì •)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸
# ============================================================================
app.mount(
    "/api/generated",
    StaticFiles(directory=str(kids_render.GENERATED_DIR)),
    name="api_generated",
)
app.mount(
    "/generated",
    StaticFiles(directory=str(kids_render.GENERATED_DIR)),
    name="generated",
)

# ============================================================================
# ë¼ìš°í„° ë“±ë¡ (ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸)
# ============================================================================
app.include_router(admin.router)            # âœ… [CRITICAL] Admin ë¼ìš°í„°ë¥¼ ê°€ìž¥ ë¨¼ì € ë“±ë¡
app.include_router(kids_render.router)      # Kids Mode
app.include_router(color_variant.router)    # Color Variant
# instructions_pdf.router moved to blueprint server (port 8001)
app.include_router(kids_background.router) # âœ… [NEW] Background Generation
app.include_router(chat_router)             # âœ… ì±—ë´‡ (/api/v1/chat)

# --- [Integrate] Brick Judge (Rust Viewer) ---
import brick_judge.server as bj_server  # noqa: E402

# 1. ë·°ì–´ íŽ˜ì´ì§€ (HTML) - ë£¨íŠ¸(/)ì™€ /brick-judge/viewer ëª¨ë‘ ëŒ€ì‘
app.add_api_route("/", bj_server.viewer, methods=["GET"], include_in_schema=False)
app.add_api_route("/brick-judge/viewer", bj_server.viewer, methods=["GET"], include_in_schema=False)
# 2. ë·°ì–´ìš© API (HTMLì—ì„œ í˜¸ì¶œí•˜ëŠ” ì ˆëŒ€ ê²½ë¡œ /api/verify ëŒ€ì‘)
app.add_api_route("/api/verify", bj_server.verify_ldr, methods=["POST"], tags=["viewer"])
# 3. LLMìš© Judge API
app.add_api_route("/api/judge", bj_server.judge_ldr, methods=["POST"], tags=["judge"])
# 4. S3 URL ê¸°ë°˜ Judge API (Admin í”„ë¡ íŠ¸ìš©)
app.add_api_route("/api/judge-url", bj_server.judge_ldr_url, methods=["POST"], tags=["judge"])
# 5. ì •ë³´ API
app.add_api_route("/api/info", bj_server.info, methods=["GET"], tags=["info"])

# 5. [DEBUG] ì•±ì— ì§ì ‘ ë“±ë¡í•˜ëŠ” í…ŒìŠ¤íŠ¸ ê²½ë¡œ
@app.get("/ai-admin/final-debug")
def final_debug_test():
    return {"status": "ok", "source": "direct_app_route", "timestamp": str(datetime.now())}

@app.get("/final-debug")
def final_debug_no_prefix():
    return {"status": "ok", "source": "no_prefix_direct_app_route"}


# ============================================================================
# Startup ì´ë²¤íŠ¸
# ============================================================================
@app.on_event("startup")
async def startup():
    """ì„œë²„ ì‹œìž‘ ì‹œ ì´ˆê¸°í™”"""
    print("=" * 70, flush=True)
    print("[FastAPI] ðŸš€ Application Startup", flush=True)
    print("=" * 70, flush=True)

    # --- OpenAI/Gemini HTTP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
    openai_key = (os.getenv("OPENAI_API_KEY") or "").strip()
    gemini_key = (os.getenv("GEMINI_API_KEY") or "").strip()

    api_key = openai_key or gemini_key
    base_url = "https://api.openai.com/v1/" if openai_key else "https://generativelanguage.googleapis.com/v1beta/openai/"

    if not api_key:
        print("âš ï¸ [Warn] OPENAI_API_KEY/GEMINI_API_KEY ë‘˜ ë‹¤ ì—†ìŒ. ì±—ë´‡ ê¸°ëŠ¥ ë¹„í™œì„±í™”.", flush=True)
        app.state.openai_http = None
        app.state.chat_service = None
    else:
        print(f"[Startup] Using API at {base_url}", flush=True)
        app.state.openai_http = httpx.AsyncClient(
            base_url=base_url,
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            },
            timeout=httpx.Timeout(connect=10.0, read=30.0, write=10.0, pool=10.0),
        )

        store = InMemoryConversationStore(
            max_messages=int(os.getenv("CHAT_MAX_MESSAGES", "20")),
            ttl_seconds=int(os.getenv("CHAT_TTL_SECONDS", "3600")),
        )
        app.state.chat_service = ChatService(http=app.state.openai_http, store=store)

        # --- [NEW] Analytics Agent Service ì´ˆê¸°í™” ---
        from service.analytics_agent_service import AnalyticsAgentService
        app.state.analytics_agent = AnalyticsAgentService(http_client=app.state.openai_http)
        print("[FastAPI] âœ… Analytics Agent Service Enabled", flush=True)

    # --- [NEW] Global log capture ---
    try:
        from service.log_context import GlobalLogCapture
        glc = GlobalLogCapture() # ì‹±ê¸€í†¤ì´ë¼ í•œë²ˆë§Œ ì‹¤í–‰ë¨
        glc.start_flusher() # Start Start Smart Batching Flusher
        print("[FastAPI] âœ… Global Logging Enabled", flush=True)
    except ImportError as e:
        print(f"âš ï¸ [Warn] GlobalLogCapture failed: {e}", flush=True)

    # --- SQS Consumer ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œìž‘ ---
    asyncio.create_task(start_consumer())
    print("[FastAPI] âœ… SQS Consumer ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œìž‘", flush=True)

    # --- ë¼ìš°íŠ¸ ë””ë²„ê¹… (ë“±ë¡ëœ ëª¨ë“  API ì£¼ì†Œ ì¶œë ¥) ---
    print("\n[Debug] Registered Routes:", flush=True)
    for route in app.routes:
        if hasattr(route, "path"):
            methods = getattr(route, "methods", {"?"})
            print(f"  - {methods} {route.path}", flush=True)
    print("=" * 70, flush=True)


@app.on_event("shutdown")
async def shutdown():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    if app.state.openai_http:
        await app.state.openai_http.aclose()


# ============================================================================
# Health Check
# ============================================================================
@app.get("/health")
def health():
    return {
        "status": "ok",
        "mode": "kids-only",
        "env": getattr(config, "ENV", "unknown"),
    }
