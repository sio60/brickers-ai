import logging
import os
from datetime import datetime
from typing import Optional, Dict, Any, List
from service import backend_client

log = logging.getLogger(__name__)

class AnalyticsAgentService:
    def __init__(self, http_client=None):
        """
        http_client: LLM í˜¸ì¶œì„ ìœ„í•œ httpx AsyncClient (OpenAI/Gemini í˜¸í™˜ API)
        """
        self.http = http_client
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o")

    async def get_analyst_report(self, days: int = 7) -> str:
        """
        1ë²ˆ ê¸°ëŠ¥: ë°ì´í„° ë¶„ì„ê°€ ì—ì´ì „íŠ¸
        ë°±ì—”ë“œ APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ LLMì´ í•´ì„í•œ ë³´ê³ ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        summary = await backend_client.get_analytics_summary(days)
        daily_users = await backend_client.get_daily_users(days)
        
        if not summary:
            return "í˜„ì¬ ë¶„ì„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

        # LLMì—ê²Œ ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = f"""
[Brickers GA4 Analytics Data - Last {days} days]
- Total Active Users: {summary.get('activeUsers')}
- Total Page Views: {summary.get('pageViews')}
- Total Sessions: {summary.get('sessions')}

[Daily Users Trend]
{daily_users}
"""
        prompt = f"""
You are the 'Brickers Data Analyst Agent'. 
Based on the following GA4 data, provide a brief, professional, and friendly analysis in Korean.
Focus on:
1. Overall performance trend.
2. Any notable insights (growth, user engagement).
3. Suggestions for improvement.

Data:
{context}
"""
        return await self._call_llm(prompt)

    async def run_anomaly_detection(self) -> Dict[str, Any]:
        """
        3ë²ˆ ê¸°ëŠ¥: ì´ìƒ ì§•í›„ ê°ì§€
        ìµœê·¼ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê¸‰ê²©í•œ í•˜ë½ì´ë‚˜ ì´ìƒ í˜„ìƒì„ íƒì§€í•©ë‹ˆë‹¤.
        """
        # ìµœê·¼ 7ì¼ê°„ì˜ ì„±ê³µëŸ‰ í™•ì¸
        stats = await backend_client.get_event_stats("generate_success", days=7)
        if not stats or len(stats) < 2:
            return {"status": "insufficient_data", "message": "ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # ì˜¤ëŠ˜ ë°ì´í„°ì™€ í‰ê·  ë¹„êµ (ê°„ë‹¨í•œ ë¡œì§)
        # stats: [{"date": "20260211", "count": 10}, ...]
        counts = [s['count'] for s in stats]
        today_count = counts[-1]
        prev_avg = sum(counts[:-1]) / len(counts[:-1]) if len(counts) > 1 else today_count

        threshold = 0.5 # 50% ì´í•˜ë¡œ ë–¨ì–´ì§€ë©´ ê²½ê³ 
        is_anomaly = today_count < (prev_avg * threshold) and prev_avg > 5

        result = {
            "status": "anomaly" if is_anomaly else "normal",
            "today": today_count,
            "previous_average": round(prev_avg, 2),
            "drop_rate": round((1 - today_count/prev_avg) * 100, 1) if prev_avg > 0 else 0
        }

        if is_anomaly:
            result["message"] = f"ğŸš¨ ê²½ê³ : ë¸Œë¦­ ìƒì„± ì„±ê³µë¥ ì´ í‰ì†Œ ëŒ€ë¹„ {result['drop_rate']}% í•˜ë½í–ˆìŠµë‹ˆë‹¤. ì„œë²„ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            result["message"] = "âœ… ì„œë¹„ìŠ¤ ìƒíƒœê°€ ì •ìƒì…ë‹ˆë‹¤."
        
        return result

    async def _call_llm(self, prompt: str) -> str:
        if not self.http:
            return "LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        body = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3
        }
        try:
            resp = await self.http.post("chat/completions", json=body)
            resp.raise_for_status()
            data = resp.json()
            return data["choices"][0]["message"]["content"]
        except Exception as e:
            log.error(f"LLM call failed in AnalyticsAgent: {e}")
            return f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
