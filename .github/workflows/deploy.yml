name: Deploy AI & Blueprint Servers

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  # ============================================
  # Job 1: AI Server (EC2 m7i-flex.large)
  # ============================================
  deploy-ai:
    name: Deploy AI Server
    needs: [deploy-screenshot]
    runs-on: ubuntu-latest
    steps:
      - name: Deploy AI Server via SSH
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.AI_HOST }}
          username: ${{ secrets.AI_USERNAME }}
          key: ${{ secrets.KEY }}
          port: ${{ secrets.AI_PORT }}
          timeout: 30m
          command_timeout: 30m
          script: |
            set -euo pipefail
            cd /home/${{ secrets.AI_USERNAME }}/brickers-ai

            echo "ðŸ“¥ Pulling latest code..."
            git fetch origin main
            git reset --hard origin/main

            echo "ðŸ“„ Writing .env..."
            if [ -d .env ]; then rm -rf .env; fi

            cat > .env <<'EOF'
            TZ=Asia/Seoul

            # --- API Keys ---
            GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }}
            TRIPO_API_KEY=${{ secrets.TRIPO_API_KEY }}
            OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
            OPENAI_MODEL=${{ secrets.OPENAI_MODEL }}
            NANO_BANANA_MODEL=${{ secrets.NANO_BANANA_MODEL }}

            # --- S3 ---
            AWS_S3_BUCKET=${{ secrets.AWS_S3_BUCKET }}
            AWS_REGION=${{ secrets.AWS_REGION }}
            AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
            S3_PUBLIC_BASE_URL=${{ secrets.S3_PUBLIC_BASE_URL }}
            S3_PREFIX=uploads/ai-generated
            USE_S3=true

            # --- SQS (4ê°œ Queue) ---
            AWS_SQS_REQUEST_QUEUE_URL=${{ secrets.AWS_SQS_REQUEST_QUEUE_URL }}
            AWS_SQS_RESULT_QUEUE_URL=${{ secrets.AWS_SQS_RESULT_QUEUE_URL }}
            AWS_SQS_PDF_QUEUE_URL=${{ secrets.AWS_SQS_PDF_QUEUE_URL }}
            AWS_SQS_SCREENSHOT_QUEUE_URL=${{ secrets.AWS_SQS_SCREENSHOT_QUEUE_URL }}
            AWS_SQS_ENABLED=true

            # --- Celery (Screenshot Server) ---
            CELERY_SQS_SCREENSHOT_QUEUE_URL=${{ secrets.CELERY_SQS_SCREENSHOT_QUEUE_URL }}
            CELERY_SCREENSHOT_ENABLED=true
            SQS_POLL_INTERVAL=5
            SQS_MAX_MESSAGES=1
            SQS_VISIBILITY_TIMEOUT=1800
            SQS_WAIT_TIME=10

            # --- Backend ---
            BACKEND_URL=${{ secrets.BACKEND_URL }}

            # --- MongoDB / RAG ---
            MONGODB_URI=${{ secrets.MONGODB_URI }}
            MONGODB_DB=${{ secrets.MONGODB_DB }}
            ATLAS_VECTOR_INDEX_MEMORY=co_scientist_memory_index
            HF_EMBED_MODEL=intfloat/multilingual-e5-small

            # --- Timeouts ---
            KIDS_TOTAL_TIMEOUT_SEC=1800
            TRIPO_WAIT_TIMEOUT_SEC=900

            # --- Internal Token ---
            INTERNAL_API_TOKEN=${{ secrets.INTERNAL_API_TOKEN }}

            # --- LangSmith ---
            LANGCHAIN_TRACING_V2=true
            LANGCHAIN_API_KEY=${{ secrets.LANGCHAIN_API_KEY }}
            LANGCHAIN_PROJECT=brickers-production
            EOF

            echo "ðŸ”¨ Building & starting AI Server..."
            sudo docker compose build app
            sudo docker compose down
            sudo docker compose up -d

            echo "ðŸ“‹ Status:"
            sudo docker ps | grep brickers-ai || true
            echo "âœ… AI Server deployed!"

  # ============================================
  # Job 2: Blueprint PDF Server (EC2 m7i-flex.large)
  # ============================================
  deploy-blueprint:
    name: Deploy Blueprint Server
    runs-on: ubuntu-latest
    steps:
      - name: Deploy Blueprint Server via SSH
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.BLUEPRINT_HOST }}
          username: ${{ secrets.BLUEPRINT_USERNAME }}
          key: ${{ secrets.KEY }}
          port: ${{ secrets.BLUEPRINT_PORT }}
          timeout: 30m
          command_timeout: 30m
          script: |
            set -euo pipefail

            DEPLOY_DIR=/home/${{ secrets.BLUEPRINT_USERNAME }}/blueprint

            # ìµœì´ˆ ë°°í¬ ì‹œ clone, ì´í›„ pull
            if [ ! -d "$DEPLOY_DIR" ]; then
              echo "ðŸ“¥ First deploy - cloning repo..."
              git clone --depth 1 --branch main https://github.com/${{ github.repository }}.git /tmp/brickers-ai-clone
              mkdir -p "$DEPLOY_DIR"
              cp -r /tmp/brickers-ai-clone/blueprint/* "$DEPLOY_DIR/"
              cp -r /tmp/brickers-ai-clone/blueprint/.* "$DEPLOY_DIR/" 2>/dev/null || true
              rm -rf /tmp/brickers-ai-clone
            else
              echo "ðŸ“¥ Pulling latest code..."
              cd /tmp
              rm -rf brickers-ai-clone
              git clone --depth 1 --branch main https://github.com/${{ github.repository }}.git brickers-ai-clone
              rsync -a --delete brickers-ai-clone/blueprint/ "$DEPLOY_DIR/"
              rm -rf brickers-ai-clone
            fi

            cd "$DEPLOY_DIR"

            echo "ðŸ“„ Writing .env..."
            cat > .env <<'EOF'
            TZ=Asia/Seoul

            # --- S3 ---
            AWS_S3_BUCKET=${{ secrets.AWS_S3_BUCKET }}
            AWS_REGION=${{ secrets.AWS_REGION }}
            AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
            S3_PUBLIC_BASE_URL=${{ secrets.S3_PUBLIC_BASE_URL }}
            USE_S3=true

            # --- SQS ---
            AWS_SQS_PDF_QUEUE_URL=${{ secrets.AWS_SQS_PDF_QUEUE_URL }}
            AWS_SQS_ENABLED=true
            SQS_POLL_INTERVAL=5
            SQS_MAX_MESSAGES=5
            SQS_WAIT_TIME=10
            SQS_VISIBILITY_TIMEOUT=600

            # --- Backend ---
            BACKEND_URL=${{ secrets.BACKEND_URL }}
            INTERNAL_API_TOKEN=${{ secrets.INTERNAL_API_TOKEN }}
            EOF

            echo "ðŸ”¨ Building & starting Blueprint Server..."
            sudo docker compose build blueprint
            sudo docker compose down
            sudo docker compose up -d

            echo "ðŸ“‹ Status:"
            sudo docker ps | grep brickers-blueprint || true
            echo "âœ… Blueprint Server deployed!"

  # ============================================
  # Job 3: Screenshot Server (EC2 m7i-flex.large)
  # ============================================
  deploy-screenshot:
    name: Deploy Screenshot Server
    runs-on: ubuntu-latest
    steps:
      - name: Deploy Screenshot Server via SSH
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.SCREENSHOT_HOST }}
          username: ${{ secrets.SCREENSHOT_USERNAME }}
          key: ${{ secrets.KEY }}
          port: ${{ secrets.SCREENSHOT_PORT }}
          timeout: 30m
          command_timeout: 30m
          script: |
            set -euo pipefail

            DEPLOY_DIR=/home/${{ secrets.SCREENSHOT_USERNAME }}/screenshot

            # ìµœì´ˆ ë°°í¬ ì‹œ clone, ì´í›„ pull
            if [ ! -d "$DEPLOY_DIR" ]; then
              echo "ðŸ“¥ First deploy - cloning repo..."
              git clone --depth 1 --branch main https://github.com/${{ github.repository }}.git /tmp/brickers-ai-clone
              mkdir -p "$DEPLOY_DIR"
              cp -r /tmp/brickers-ai-clone/screenshot-server/* "$DEPLOY_DIR/"
              cp -r /tmp/brickers-ai-clone/screenshot-server/.* "$DEPLOY_DIR/" 2>/dev/null || true
              rm -rf /tmp/brickers-ai-clone
            else
              echo "ðŸ“¥ Pulling latest code..."
              cd /tmp
              rm -rf brickers-ai-clone
              git clone --depth 1 --branch main https://github.com/${{ github.repository }}.git brickers-ai-clone
              rsync -a --delete brickers-ai-clone/screenshot-server/ "$DEPLOY_DIR/"
              rm -rf brickers-ai-clone
            fi

            cd "$DEPLOY_DIR"

            echo "ðŸ“„ Writing .env..."
            cat > .env <<'EOF'
            TZ=Asia/Seoul

            # --- S3 ---
            AWS_S3_BUCKET=${{ secrets.AWS_S3_BUCKET }}
            AWS_REGION=${{ secrets.AWS_REGION }}
            AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
            S3_PUBLIC_BASE_URL=${{ secrets.S3_PUBLIC_BASE_URL }}
            USE_S3=true

            # --- SQS (legacy, fallback) ---
            AWS_SQS_SCREENSHOT_QUEUE_URL=${{ secrets.AWS_SQS_SCREENSHOT_QUEUE_URL }}
            AWS_SQS_ENABLED=true
            SQS_POLL_INTERVAL=5
            SQS_MAX_MESSAGES=1
            SQS_WAIT_TIME=10
            SQS_VISIBILITY_TIMEOUT=300

            # --- Celery (primary) ---
            CELERY_SQS_SCREENSHOT_QUEUE_URL=${{ secrets.CELERY_SQS_SCREENSHOT_QUEUE_URL }}

            # --- Backend ---
            BACKEND_URL=${{ secrets.BACKEND_URL }}
            INTERNAL_API_TOKEN=${{ secrets.INTERNAL_API_TOKEN }}

            # --- Gemini ---
            GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }}
            NANO_BANANA_MODEL=${{ secrets.NANO_BANANA_MODEL }}
            EOF

            echo "ðŸ§¹ Stopping old containers..."
            sudo docker stop brickers-screenshot 2>/dev/null && sudo docker rm brickers-screenshot 2>/dev/null || true

            echo "ðŸ”¨ Building & starting Screenshot Server..."
            sudo docker compose build
            sudo docker compose down --remove-orphans
            sudo docker compose up -d

            echo "ðŸ“‹ Status:"
            sudo docker ps | grep brickers-screenshot || true
            echo "âœ… Screenshot Server deployed!"
