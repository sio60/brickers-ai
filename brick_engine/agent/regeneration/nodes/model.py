# ============================================================================
# Model ë…¸ë“œ: LLMì´ ìƒí™© ë¶„ì„ + ë„êµ¬ ì„ íƒ
# ============================================================================

import re
import time
from typing import Dict, Any

from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

from ..prompts import STRATEGY_GUIDE, build_stability_hint
from ..rag_ranker import rerank_and_filter_cases


def node_model(graph, state) -> Dict[str, Any]:
    """LLMì´ ìƒí™©ì„ ë¶„ì„í•˜ê³  ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ë…¸ë“œ"""
    from ...agent_tools import TuneParameters, RemoveBricks
    from ...memory_utils import memory_manager

    print("\n[Co-Scientist] ìƒí™© ë¶„ì„ ì¤‘...")
    graph._log("ANALYZE", "ë¶ˆí•„ìš”í•œ ë³µì¡ì„±ì´ ìˆëŠ”ì§€ ê²€í† í•˜ê³  ìˆì–´ìš”.")

    tools = [TuneParameters, RemoveBricks]

    # --- ì „ëµ ê°€ì´ë“œ ì£¼ì… ---
    messages_to_send = state['messages'][:]
    messages_to_send.append(SystemMessage(content=STRATEGY_GUIDE))

    # --- Memory ì •ë³´ ì£¼ì… (RAG) ---
    last_human_msg = next((m for m in reversed(messages_to_send) if isinstance(m, HumanMessage)), None)
    subject_prefix = f"[{state.get('subject_name', 'Object')}] "
    current_observation = subject_prefix + (last_human_msg.content if last_human_msg else "")

    if memory_manager:
        verification_metrics = state.get("verification_result")
        raw_cases = memory_manager.search_similar_cases(
            current_observation,
            limit=10,
            min_score=0.4,
            verification_metrics=verification_metrics,
            subject_name=state.get("subject_name", "Object")
        )
        similar_cases = rerank_and_filter_cases(graph.default_client, current_observation, raw_cases)

        if similar_cases:
            memory_info = "\n**ğŸ“š ìœ ì‚¬í•œ ê³¼ê±° ì‹¤í—˜ ì‚¬ë¡€ (RAG):**\n"
            for i, case in enumerate(similar_cases, 1):
                exp = case.get('experiment', {})
                ver = case.get('verification', {})
                imp = case.get('improvement', {})

                metrics = ver.get('metrics_after', ver)
                vol = metrics.get('total_volume', 0)
                dims = metrics.get('dimensions', {})
                dim_str = f"{dims.get('width', 0):.0f}x{dims.get('height', 0):.0f}x{dims.get('depth', 0):.0f}" if dims else "N/A"

                tool = exp.get('tool', 'Unknown')
                result = ver.get('numerical_analysis', 'N/A')
                lesson = imp.get('lesson_learned', 'No lesson')
                outcome = "ì„±ê³µ" if case.get('result_success') else "ì‹¤íŒ¨"
                score = case.get('similarity_score', 0)
                rel = case.get('reliability_grade', 'Low')

                memory_info += f"[{i}] {outcome} ì‚¬ë¡€ (ì‹ ë¢°ë„: {rel}, ìœ ì‚¬ë„: {score:.2f})\n"
                memory_info += f"    - ë¬¼ë¦¬ íŠ¹ì„±: ë¶€í”¼ {vol:.1f}, í¬ê¸° {dim_str}, ë¸Œë¦­ {metrics.get('total_bricks', 0)}ê°œ\n"
                memory_info += f"    - ë„êµ¬: {tool} -> ê²°ê³¼: {result}\n"
                memory_info += f"    - êµí›ˆ: {lesson}\n"

            memory_info += "\nìœ„ ë¶€í”¼ì™€ í˜•íƒœì  ìœ ì‚¬ì„±ì„ ê³ ë ¤í•˜ì—¬ ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê²°ì •í•˜ì„¸ìš”.\n"
            messages_to_send.append(SystemMessage(content=memory_info))
            print(f"  ğŸ“š RAG ê²€ìƒ‰ ê²°ê³¼ {len(similar_cases)}ê±´ ì£¼ì…ë¨")

    # Legacy Memory (Fallback)
    memory = state.get('memory', {})
    lessons = memory.get('lessons', [])
    failed_approaches = memory.get('failed_approaches', [])

    if lessons or failed_approaches:
        memory_info = "\n**ğŸ“š ì´ì „ ê²½í—˜ (Memory):**\n"
        if lessons:
            memory_info += "- ìµœê·¼ êµí›ˆ: " + "; ".join(lessons[-3:]) + "\n"
        if failed_approaches:
            memory_info += "- í”¼í•´ì•¼ í•  ì ‘ê·¼ë²•: " + "; ".join(failed_approaches[-3:]) + "\n"

        messages_to_send.append(SystemMessage(content=memory_info))
        print(f"  ğŸ“š Memory ì •ë³´ {len(lessons)}ê°œ êµí›ˆ ì „ë‹¬ë¨")

    # ì§ì „ ê²€ì¦ ê²°ê³¼ì—ì„œ ì•ˆì •ì„± ë“±ê¸‰ íŒŒì‹± â†’ íŒíŠ¸ ì£¼ì…
    target_msg = None
    for msg in reversed(messages_to_send):
        if isinstance(msg, HumanMessage) and "ê²€ì¦ ê²°ê³¼" in str(msg.content):
            target_msg = msg
            break

    if target_msg:
        content = str(target_msg.content)
        grade_match = re.search(r"ì•ˆì •ì„± ë“±ê¸‰: \S+ \((\w+)\)", content)
        score_match = re.search(r"ì ìˆ˜:\s*(\d+)", content)

        grade = grade_match.group(1) if grade_match else "UNKNOWN"
        score = int(score_match.group(1)) if score_match else 0

        hint = build_stability_hint(grade, score)
        if hint:
            if score >= 90:
                print(f"  ğŸ’¡ [Strategy Hint] ğŸŒŸ ì•ˆì • (ì ìˆ˜: {score}) -> ì”ì¡´ë¬¼ ì‚­ì œ ëª¨ë“œ")
            elif grade == "UNSTABLE":
                print(f"  ğŸ’¡ [Strategy Hint] ë¶ˆì•ˆì • (ì ìˆ˜: {score}) -> íŒŒë¼ë¯¸í„° ëŒ€í­ ë³€ê²½ í•„ìš”")
            elif grade == "MEDIUM":
                print(f"  ğŸ’¡ [Strategy Hint] ì¤‘ê°„ (ì ìˆ˜: {score}) -> íŒŒë¼ë¯¸í„° ì†Œí­ ì¡°ì • í•„ìš”")
            messages_to_send.append(SystemMessage(content=hint))

    # ëª¨ë¸ í˜¸ì¶œ
    try:
        client_to_use = graph.gemini_client
        print(f"  ğŸ¤– Active Model: Gemini-2.5-Flash (Fixed)")

        model_with_tools = client_to_use.bind_tools(tools)
        response = model_with_tools.invoke(messages_to_send)

        if response.tool_calls:
            tc = response.tool_calls[0]
            tool_name = tc['name']
            print(f"  ğŸ”¨ ë„êµ¬ ì„ íƒ: {[tc['name'] for tc in response.tool_calls]}")

            if tool_name == "RemoveBricks":
                graph._log("MODEL", "êµ¬ì¡°ê°€ ê±°ì˜ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ë¶ˆì•ˆì •í•œ ë¸Œë¦­ë“¤ë§Œ í•€ì…‹ìœ¼ë¡œ ë„ë ¤ë‚¼ê²Œìš”.")
            elif tool_name == "TuneParameters":
                graph._log("MODEL", "í˜„ì¬ íŒŒë¼ë¯¸í„°ë¡œëŠ” í•œê³„ê°€ ìˆë„¤ìš”. ìƒˆë¡œìš´ ê´€ì ì—ì„œ ì„¤ê³„ë¥¼ ë‹¤ì‹œ ì‹œë„í•´ ë³´ê² ìŠµë‹ˆë‹¤.")

            return {"messages": [response], "next_action": "tool"}
        else:
            print(f"  ğŸ’­ LLM ì˜ê²¬: {response.content}")

            current_metrics = state.get('current_metrics', {})
            floating_count = current_metrics.get('floating_count', 0)
            failure_ratio = current_metrics.get('failure_ratio', 0)

            if floating_count == 0 and failure_ratio <= state['acceptable_failure_ratio']:
                print("ğŸ‰ ëª¨ë“  ì¡°ê±´ ì¶©ì¡±. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return {"messages": [response], "next_action": "end"}
            else:
                print(f"âš ï¸ ê²½ê³ : ë¬¸ì œê°€ ë‚¨ì•˜ëŠ”ë°({floating_count}ê°œ ê³µì¤‘ë¶€ì–‘) ì¢…ë£Œ ì‹œë„í•¨. ì¬ì§€ì‹œ ì¤‘...")
                error_feedback = f"ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. {floating_count}ê°œì˜ ê³µì¤‘ë¶€ì–‘ ë¸Œë¦­ì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤. TuneParametersë¡œ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ì•Œê³ ë¦¬ì¦˜ì´ ë” ì•ˆì •ì ì¸ êµ¬ì¡°ë¥¼ ìƒì„±í•˜ë„ë¡ í•˜ì„¸ìš”."
                hint = HumanMessage(content=error_feedback)
                return {"messages": [response, hint], "next_action": "model"}

    except Exception as e:
        print(f"  âš ï¸ LLM í˜¸ì¶œ ì—ëŸ¬: {e}")
        if "429" in str(e):
            print("  ğŸ’¤ API í• ë‹¹ëŸ‰ ì´ˆê³¼. ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
            time.sleep(10)
            return {"next_action": "model"}
        return {"next_action": "end"}
