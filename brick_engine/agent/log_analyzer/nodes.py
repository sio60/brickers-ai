"""
Log Analyzer â€” Node í•¨ìˆ˜
========================
LangGraph ê·¸ë˜í”„ì˜ ê° ë…¸ë“œë¥¼ êµ¬ì„±í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ë“¤.

Nodes:
  1. fetch_logs_node        â€” ë¡œê·¸ ìˆ˜ì§‘ (Docker SDK + DB í´ë°±)
  2. no_logs_report_node    â€” [NEW] ë¡œê·¸ ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬í¬íŠ¸ ìƒì„±
  3. parse_error_node       â€” Traceback ì¶”ì¶œ ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (infra vs code)
  4. agent_investigate_node  â€” ReAct Loop (ì½”ë“œ ë²„ê·¸ ì¤‘ì‹¬)
  5. investigate_infra_node â€” [NEW] ReAct Loop (ì¸í”„ë¼ ì¥ì•  ì¤‘ì‹¬)
  6. simple_summary_node    â€” ì—ëŸ¬ ë¯¸ê°ì§€ ì‹œ ê°„ë‹¨ ìš”ì•½
  7. generate_report_node   â€” ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
  8. validate_report_node   â€” [NEW] ë¦¬í¬íŠ¸ JSON ê²€ì¦ ë° ì¬ì‹œë„ ì œì–´
  9. alert_admin_node       â€” [NEW] Critical ì—ëŸ¬ ì‹œ ì•Œë¦¼ ì „ì†¡
"""

import json
import logging
import re
import asyncio
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage

from .state import LogAnalysisState
from .persistence import get_archived_logs
from .config import (
    TOOL_SCHEMAS,
    TOOL_EXECUTOR_MAP,
    MAX_INVESTIGATION_ROUNDS,
    DOCKER_LOG_TAIL_LINES,
    JOB_FAILURE_PATTERN,
    JOB_START_PATTERN,
    INFRA_ERROR_TYPES,
    INFRA_ERROR_KEYWORDS,
    MAX_REPORT_RETRIES,
    REPORT_REQUIRED_FIELDS,
    DEEP_DIVE_THRESHOLD,
)
from .prompts import (
    INVESTIGATE_SYSTEM_PROMPT,
    INVESTIGATE_INFRA_SYSTEM_PROMPT,
    DEEP_DIVE_PROMPT,
    REPORT_SYSTEM_PROMPT,
    SIMPLE_SUMMARY_SYSTEM_PROMPT,
    SIMPLE_SUMMARY_USER_TEMPLATE,
)
from ..llm_clients import GeminiClient

logger = logging.getLogger("agent.log_analyzer.nodes")


# ============================================================
# NODE 1: fetch_logs â€” ë¡œê·¸ ìˆ˜ì§‘
# ============================================================
async def fetch_logs_node(state: LogAnalysisState):
    """ë¡œê·¸ í™•ë³´ (ìš°ì„ ìˆœìœ„: State > DB > Docker)"""
    target_job_id = state.get("job_id")
    raw_logs = state.get("logs", "")
    container_name = state.get("container_name", "brickers-ai-container")

    logger.info(f"--- [Node 1: fetch_logs] Job: {target_job_id} ---")

    if raw_logs:
        logger.info(f"âœ… Stateì—ì„œ ë¡œê·¸ í™•ë³´ ({len(raw_logs)} chars)")
    elif target_job_id:
        archived = await get_archived_logs(target_job_id)
        if archived:
            raw_logs = archived
            logger.info(f"âœ… DB ì•„ì¹´ì´ë¸Œì—ì„œ ë¡œê·¸ ë¡œë“œ ({len(raw_logs)} chars)")
    
    if not raw_logs:
        try:
            import docker
            client = docker.from_env()
            container = client.containers.get(container_name)
            raw_logs = container.logs(tail=DOCKER_LOG_TAIL_LINES).decode("utf-8", errors="replace")
            logger.info(f"âœ… Docker SDK ë¡œê·¸ ìˆ˜ì§‘ ì™„ë£Œ ({len(raw_logs)} chars)")
        except Exception as e:
            logger.warning(f"âš ï¸ Docker ì—°ê²° ì‹¤íŒ¨: {e}")
            raw_logs = ""

    # Job ID ìë™ íƒìƒ‰ & í•„í„°ë§
    if not target_job_id and raw_logs:
        failure_matches = re.findall(JOB_FAILURE_PATTERN, raw_logs)
        target_job_id = failure_matches[-1] if failure_matches else None
        if not target_job_id:
            start_matches = re.findall(JOB_START_PATTERN, raw_logs)
            target_job_id = start_matches[-1] if start_matches else None
    
    if target_job_id and raw_logs:
        job_lines = [line for line in raw_logs.splitlines() if target_job_id in line]
        if job_lines:
            filtered = "\n".join(job_lines)
            raw_logs = filtered if len(filtered) > 500 else filtered + "\n\n[=== ì›ë³¸ ë¡œê·¸ ===]\n" + raw_logs[-2000:]

    return {
        "logs": raw_logs,
        "job_id": target_job_id,
        "iteration": 0,
        "investigation_notes": [],
        "report_retry_count": 0,
    }


# ============================================================
# NODE 1-alt: no_logs_report â€” ë¡œê·¸ ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ
# ============================================================
async def no_logs_report_node(state: LogAnalysisState):
    """ë¡œê·¸ê°€ ì—†ì„ ë•Œ 'ìˆ˜ì§‘ ì‹¤íŒ¨' ë¦¬í¬íŠ¸ ìƒì„±"""
    logger.info("--- [Node: no_logs_report] ë¡œê·¸ ì—†ìŒ â†’ ì¢…ë£Œ ---")
    fallback = {
        "error_identification": {"error_type": "DataFetchError", "severity": "medium"},
        "root_cause": {"summary": "ë¡œê·¸ ë°ì´í„°ë¥¼ í™•ë³´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."},
        "summary": "DB ì•„ì¹´ì´ë¸Œì™€ Docker ì»¨í…Œì´ë„ˆ ëª¨ë‘ì—ì„œ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.",
    }
    return {"analysis_result": json.dumps(fallback, ensure_ascii=False)}


# ============================================================
# NODE 2: parse_error â€” Traceback ì¶”ì¶œ & ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
# ============================================================
async def parse_error_node(state: LogAnalysisState):
    """ì—ëŸ¬ íŒŒì‹± ë° infra vs code ì¹´í…Œê³ ë¦¬ ê²°ì •"""
    logs = state.get("logs", "")
    logger.info("--- [Node 2: parse_error] ì—ëŸ¬ ë¶„ì„ ì¤‘ ---")

    # ì „ì²´ Traceback ë¸”ë¡ ì¶”ì¶œ
    traceback_pattern = r'(Traceback \(most recent call last\):.*?)(?=\n\S|\Z)'
    traceback_blocks = re.findall(traceback_pattern, logs, re.DOTALL)

    # ì—ëŸ¬ íƒ€ì…/ë©”ì‹œì§€ ì¶”ì¶œ
    error_type = ""
    error_message = ""
    for line in reversed(logs.splitlines()):
        err_match = re.match(r'^(\w+(?:Error|Exception|Warning|Timeout))\s*:\s*(.+)', line.strip())
        if err_match:
            error_type = err_match.group(1)
            error_message = err_match.group(2).strip()
            break

    # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    category = "code_bug"
    if error_type in INFRA_ERROR_TYPES:
        category = "infra_issue"
    else:
        # ë©”ì‹œì§€ í‚¤ì›Œë“œ ê²€ì‚¬
        msg_lower = error_message.lower()
        if any(kw in msg_lower for kw in INFRA_ERROR_KEYWORDS):
            category = "infra_issue"

    # í˜¸ì¶œ ìŠ¤íƒ ì¶”ì¶œ
    file_pattern = r'File "(?P<file>[^"]+)", line (?P<line>\d+), in (?P<func>\S+)'
    all_frames = []
    user_frames = []
    for m in re.finditer(file_pattern, logs):
        frame = {"file": m.group("file"), "line": int(m.group("line")), "function": m.group("func")}
        all_frames.append(frame)
        if "site-packages" not in frame["file"]:
            user_frames.append(frame)

    primary = user_frames[-1] if user_frames else (all_frames[-1] if all_frames else {})

    error_context = {
        "error_type": error_type,
        "error_message": error_message,
        "call_stack": user_frames,
        "primary_file": primary.get("file", "unknown"),
        "primary_line": primary.get("line", 0),
        "primary_function": primary.get("function", "unknown"),
        "total_frames": len(all_frames),
        "user_code_frames": len(user_frames),
        "traceback_raw": traceback_blocks[-1][:800] if traceback_blocks else "",
    }

    logger.info(f"ğŸ“Š Category: {category}, Error: {error_type}")
    return {"error_context": error_context, "error_category": category}


# ============================================================
# Core Investigation Node (Shared Logic)
# ============================================================
async def _run_investigation(state: LogAnalysisState, system_prompt: str, node_name: str):
    iteration = state.get("iteration", 0)
    error_ctx = state.get("error_context", {})
    logs = state.get("logs", "")[-3000:]

    logger.info(f"--- [{node_name}] Round {iteration + 1}/{MAX_INVESTIGATION_ROUNDS} ---")

    # â”€â”€ ë©”ì‹œì§€ êµ¬ì„± â”€â”€
    if iteration == 0:
        initial_context = f"""[ì—ëŸ¬ ì •ë³´]
- Type: {error_ctx.get('error_type', 'Unknown')}
- Message: {error_ctx.get('error_message', 'Unknown')}
- File: {error_ctx.get('primary_file', 'Unknown')}:{error_ctx.get('primary_line', '?')}
- Function: {error_ctx.get('primary_function', 'Unknown')}

[í˜¸ì¶œ ìŠ¤íƒ (ì‚¬ìš©ì ì½”ë“œ)]
{json.dumps(error_ctx.get('call_stack', []), indent=2, ensure_ascii=False)}

[Traceback]
{error_ctx.get('traceback_raw', 'ì—†ìŒ')}

[ë¡œê·¸ (ìµœê·¼)]
{logs}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¡°ì‚¬ë¥¼ ì‹œì‘í•˜ì„¸ìš”. ì—ëŸ¬ ë°œìƒ íŒŒì¼ë¶€í„° ì½ì–´ë³´ì„¸ìš”."""
        messages = [SystemMessage(content=system_prompt), HumanMessage(content=initial_context)]
    else:
        current_msgs = state.get("messages", [])
        if iteration >= DEEP_DIVE_THRESHOLD:
            # 3ë¼ìš´ë“œ ì´ìƒ ì‹œ Deep Dive ìœ ë„
            deep_dive_msg = HumanMessage(content=DEEP_DIVE_PROMPT.format(iteration=iteration+1, prev_rounds=iteration))
            messages = current_msgs + [deep_dive_msg]
        else:
            messages = current_msgs + [HumanMessage(content=f"[ì¡°ì‚¬ ë¼ìš´ë“œ {iteration + 1}] ì´ì „ ì¡°ì‚¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì¶”ê°€ë¡œ í™•ì¸ì´ í•„ìš”í•œ íŒŒì¼ì´ë‚˜ ì¸í”„ë¼ê°€ ìˆìœ¼ë©´ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”. ì¶©ë¶„í•˜ë‹¤ë©´ ë„êµ¬ í˜¸ì¶œ ì—†ì´ ì‘ë‹µí•˜ì„¸ìš”.")]

    # â”€â”€ LLM í˜¸ì¶œ â”€â”€
    llm = GeminiClient()
    model = llm.bind_tools(TOOL_SCHEMAS)
    response = await asyncio.to_thread(model.invoke, messages)

    # â”€â”€ ë„êµ¬ ì‹¤í–‰ â”€â”€
    tool_messages = []
    notes = []
    if hasattr(response, "tool_calls") and response.tool_calls:
        for tc in response.tool_calls:
            name, args, tid = tc["name"], tc["args"], tc.get("id", tc["name"])
            executor = TOOL_EXECUTOR_MAP.get(name)
            result = str(executor(args))[:2000] if executor else f"Unknown tool: {name}"
            tool_messages.append(ToolMessage(content=result, tool_call_id=tid))
            notes.append(f"[{name}] {json.dumps(args, ensure_ascii=False)} -> {result[:100]}...")

    # ì´ë²ˆ ë¼ìš´ë“œì— ì¶”ê°€ëœ ë©”ì‹œì§€ë“¤ë§Œ ë°˜í™˜ (operator.addë¡œ ëˆ„ì ë¨)
    if iteration == 0:
        # ì²« ë¼ìš´ë“œ: System + Human + AI + Tool
        new_messages = messages + [response] + tool_messages
    else:
        # ì´í›„ ë¼ìš´ë“œ: Human(last) + AI + Tool
        # messages[-1]ì´ ë°©ê¸ˆ ì¶”ê°€í•œ HumanMessageì„
        new_messages = [messages[-1], response] + tool_messages

    note_summary = f"[Round {iteration+1}] " + ("; ".join(notes) if notes else "No tools used.")
    return {
        "messages": new_messages,
        "iteration": iteration + 1,
        "investigation_notes": [note_summary],
    }

# NODE 3: ì¼ë°˜ ì¡°ì‚¬
async def agent_investigate_node(state: LogAnalysisState):
    return await _run_investigation(state, INVESTIGATE_SYSTEM_PROMPT, "Node 3: investigate")

# NODE 3-alt: ì¸í”„ë¼ ì¡°ì‚¬
async def investigate_infra_node(state: LogAnalysisState):
    return await _run_investigation(state, INVESTIGATE_INFRA_SYSTEM_PROMPT, "Node 3-infra: invest_infra")


# ============================================================
# NODE 4: simple_summary â€” ì—ëŸ¬ ë¯¸ê°ì§€
# ============================================================
async def simple_summary_node(state: LogAnalysisState):
    logs = state.get("logs", "")[-2000:]
    llm = GeminiClient()
    try:
        response = await asyncio.to_thread(llm.generate_json, SIMPLE_SUMMARY_USER_TEMPLATE.format(logs=logs), SIMPLE_SUMMARY_SYSTEM_PROMPT)
        return {"analysis_result": json.dumps(response, ensure_ascii=False)}
    except Exception as e:
        return {"analysis_result": json.dumps({"summary": f"Error summarizing: {e}"})}


# ============================================================
# NODE 5: generate_insight â€” ê´€ë¦¬ììš© ì¸ì‚¬ì´íŠ¸ ìƒì„±
# ============================================================
async def generate_report_node(state: LogAnalysisState):
    """
    ê¸°ì¡´ì˜ ê¸°ìˆ  ë¦¬í¬íŠ¸ ëŒ€ì‹ , ê´€ë¦¬ììš© BIA ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    logger.info("--- [Node 5: generate_insight] ì–´ë“œë¯¼ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘ ---")
    error_ctx = state.get("error_context", {})
    notes = state.get("investigation_notes", [])
    logs = state.get("logs", "")[-3000:]

    prompt = f"[ì—ëŸ¬ ì •ë³´]\n{json.dumps(error_ctx)}\n\n[ì¡°ì‚¬ ê¸°ë¡]\n{chr(10).join(notes)}\n\n[ì›ë³¸ ë¡œê·¸]\n{logs}"
    
    try:
        from service.nano_banana import GeminiClient
        llm = GeminiClient()
        # INSIGHT_SYSTEM_PROMPT ì‚¬ìš© (ë¹„ê°œë°œì ê´€ë¦¬ì íƒ€ê²Ÿ)
        response = await asyncio.to_thread(llm.generate_json, prompt, INSIGHT_SYSTEM_PROMPT)
        
        # ìƒíƒœì— ê°œë³„ ì¸ì‚¬ì´íŠ¸ í•„ë“œ ì €ì¥
        return {
            "analysis_result": json.dumps(response, ensure_ascii=False),
            "plain_summary": response.get("plain_summary"),
            "user_impact_level": response.get("user_impact_level"),
            "suggested_actions": response.get("suggested_actions"),
            "business_insight": response.get("business_insight")
        }
    except Exception as e:
        logger.error(f"âŒ [generate_insight] AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"analysis_result": json.dumps({"plain_summary": f"ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}"})}


# ============================================================
# NODE 6: validate_report â€” [NEW] ë¦¬í¬íŠ¸ ê²€ì¦
# ============================================================
async def validate_report_node(state: LogAnalysisState):
    """ë¦¬í¬íŠ¸ JSON ìœ íš¨ì„± ë° í•„ìˆ˜ í•„ë“œ ê²€ì‚¬"""
    result_str = state.get("analysis_result", "{}")
    retry_count = state.get("report_retry_count", 0)
    logger.info(f"--- [Node 6: validate_report] ê²€ì¦ ì‹œì‘ (ì‹œë„ {retry_count + 1}) ---")

    try:
        data = json.loads(result_str)
        missing = [f for f in REPORT_REQUIRED_FIELDS if f not in data]
        if not missing:
            logger.info("âœ… ë¦¬í¬íŠ¸ ê²€ì¦ í†µê³¼")
            return {"report_retry_count": retry_count} # ê°’ ìœ ì§€
        else:
            logger.warning(f"âš ï¸ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {missing}")
    except Exception as e:
        logger.warning(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

    return {"report_retry_count": retry_count + 1}


# ============================================================
# NODE 7: alert_admin â€” [NEW] Critical ì•Œë¦¼
# ============================================================
async def alert_admin_node(state: LogAnalysisState):
    """Critical ì—ëŸ¬ ë°œìƒ ì‹œ ì™¸ë¶€ ì•Œë¦¼ (ë¡œê¹…/Slack)"""
    result_str = state.get("analysis_result", "{}")
    try:
        data = json.loads(result_str)
        severity = data.get("error_identification", {}).get("severity", "unknown")
        summary = data.get("summary", "No summary")
        
        if severity == "critical":
            logger.error(f"ğŸš¨ [CRITICAL ALERT] ì‹œìŠ¤í…œ ì¥ì•  ê°ì§€!\nì‚¬ìœ : {summary}")
            # ì¶”í›„ Slack Webhook ë“± ì—°ë™ ì§€ì 
    except:
        pass
    
    return {}

