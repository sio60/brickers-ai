import json
import logging
import re
import asyncio
from typing import List, Optional, Dict, Any, Union
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langgraph.graph import StateGraph, END

from .state import LogAnalysisState
from .persistence import get_archived_logs
from ..llm_clients import GeminiClient
from ..agent_tools import (
    execute_read_file, 
    execute_check_db, 
    execute_check_system, 
    execute_check_sqs
)

# Logger configuration
logger = logging.getLogger("agent.log_analyzer.agent")

# --- Nodes (ë…¸ë“œ ì •ì˜) ---

async def fetch_logs_node(state: LogAnalysisState):
    """
    [ë…¸ë“œ 1: ë¡œê·¸ ìˆ˜ì§‘]
    DB(Persistence)ì—ì„œ ì•„ì¹´ì´ë¹™ëœ ë¡œê·¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (Docker ì§ì ‘ ì ‘ê·¼ ì œê±°)
    """
    target_job_id = state.get("job_id")
    raw_logs = state.get("logs", "")
    
    logger.info(f"--- [ë¡œê·¸ ë¶„ì„ê¸°] 1ë‹¨ê³„: ë¡œê·¸ ìˆ˜ì§‘ ì‹œì‘ (Job: {target_job_id or 'Unknown'}) ---")
    
    # 1. Stateì— ì´ë¯¸ ë¡œê·¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš© ë“±)
    if raw_logs:
        logger.info(f"âœ… ì…ë ¥ëœ ë¡œê·¸ ì‚¬ìš© ({len(raw_logs)} bytes)")
        filtered_logs = raw_logs
    
    # 2. Job IDë¡œ DB ì•„ì¹´ì´ë¸Œ ì¡°íšŒ
    elif target_job_id:
        logger.info(f"ğŸ” DB ì•„ì¹´ì´ë¸Œ ì¡°íšŒ ì¤‘... (Job: {target_job_id})")
        archived = await get_archived_logs(target_job_id)
        if archived:
            filtered_logs = archived
            logger.info(f"âœ… DBì—ì„œ ì•„ì¹´ì´ë¸Œëœ ë¡œê·¸ ë¡œë“œ ì„±ê³µ ({len(filtered_logs.splitlines())}ì¤„)")
        else:
            logger.warning(f"âš ï¸ DBì—ì„œ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Job: {target_job_id})")
            filtered_logs = "ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    else:
        logger.warning("âš ï¸ Job IDê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        filtered_logs = "ë¶„ì„í•  ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    user_prompt = f"""
    [ëŒ€ìƒ Job ID: {target_job_id or "ì•Œ ìˆ˜ ì—†ìŒ"}]
    
    [ë¡œê·¸ ë°ì´í„°]
    {filtered_logs}
    
    ì´ ë¡œê·¸ë¥¼ ì •ë°€ ë¶„ì„í•˜ì—¬ ë¬¸ì œì˜ ê·¼ë³¸ ì›ì¸ì„ ì°¾ìœ¼ì‹­ì‹œì˜¤. 
    í•„ìš”í•˜ë‹¤ë©´ ì œê³µëœ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œë‚˜ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì¶”ê°€ë¡œ í™•ì¸í•˜ì‹­ì‹œì˜¤.
    """
    
    return {
        "logs": filtered_logs,
        "messages": [HumanMessage(content=user_prompt)],
        "iteration": 0,
        "job_id": target_job_id
    }

async def diagnose_node(state: LogAnalysisState):
    """
    [ë…¸ë“œ 2: ì •ë°€ ì§„ë‹¨]
    """
    messages = state.get("messages", [])
    iteration = state.get("iteration", 0)
    
    system_prompt = """
    ë‹¹ì‹ ì€ ê³ ê¸‰ ì‹œìŠ¤í…œ ë””ë²„ê¹… ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
    ë¶„ì„ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ì—¬ ì œê³µí•˜ì‹­ì‹œì˜¤.
    
    1. ì›ì¸ íŒŒì•…: Traceback, DB ì—°ê²°, SQS ìƒíƒœ ë“±ì„ ì¢…í•© ë¶„ì„.
    2. ë„êµ¬ í™œìš©: êµ¬ì²´ì ì¸ íŒŒì¼ ë‚´ìš© í™•ì¸ì´ë‚˜ ìƒíƒœ ì¡°íšŒê°€ í•„ìš”í•˜ë©´ ë„êµ¬ë¥¼ í˜¸ì¶œ.
    3. í•´ê²°ì±… ì œì•ˆ: ë‹¨ìˆœíˆ ì—ëŸ¬ë©”ì‹œì§€ë¥¼ ì½ëŠ” ê²Œ ì•„ë‹ˆë¼, ì•„í‚¤í…ì²˜ ê°œì„ ì•ˆì´ë‚˜ ì½”ë“œ ìˆ˜ì •ì•ˆì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ.
    
    ì¶œë ¥ í˜•ì‹ (JSON):
    - ë„êµ¬ ì‚¬ìš©: {"action": "read_file", "args": {"file_path": "..."}, "reasoning": "..."}
    - ì™„ë£Œ: {"action": "finish", "analysis": {"error_found": true, "summary": "...", "root_cause": "...", "suggestion": "..."}}
    """
    
    try:
        llm = GeminiClient()
        response = await asyncio.to_thread(llm.generate_json, messages[-1].content, system_prompt)
        return {"analysis_result": json.dumps(response, ensure_ascii=False), "iteration": iteration + 1}
    except Exception as e:
        logger.error(f"AI ì§„ë‹¨ ì—ëŸ¬: {e}")
        return {"analysis_result": json.dumps({"action": "finish", "analysis": {"error_found": True, "summary": f"ì§„ë‹¨ ì—ëŸ¬: {e}"}})}

async def tool_execution_node(state: LogAnalysisState):
    """
    [ë…¸ë“œ 3: ë„êµ¬ ì‹¤í–‰]
    """
    decision = json.loads(state.get("analysis_result", "{}"))
    action = decision.get("action")
    args = decision.get("args", {})
    
    tool_map = {
        "read_file": execute_read_file,
        "check_db": execute_check_db,
        "check_system": execute_check_system,
        "check_sqs": execute_check_sqs
    }
    
    if action in tool_map:
        result = await asyncio.to_thread(tool_map[action], args)
        feedback = f"[{action} ê²°ê³¼]\n{result}\n\nìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ì„ ê³„ì†í•˜ê±°ë‚˜ ì¢…ë£Œí•˜ì‹­ì‹œì˜¤."
        
        curr_messages = state.get("messages", [])
        curr_messages.append(AIMessage(content=f"Executed {action}"))
        curr_messages.append(HumanMessage(content=feedback))
        return {"messages": curr_messages}
        
    return {}

def should_continue(state: LogAnalysisState):
    decision = json.loads(state.get("analysis_result", "{}"))
    if decision.get("action") in ["read_file", "check_db", "check_system", "check_sqs"] and state.get("iteration", 0) < 5:
        return "tool_exec"
    return END

# Graph
workflow = StateGraph(LogAnalysisState)
workflow.add_node("fetch", fetch_logs_node)
workflow.add_node("diagnose", diagnose_node)
workflow.add_node("tool_exec", tool_execution_node)

workflow.set_entry_point("fetch")
workflow.add_edge("fetch", "diagnose")
workflow.add_conditional_edges("diagnose", should_continue, {"tool_exec": "tool_exec", END: END})
workflow.add_edge("tool_exec", "diagnose")

app = workflow.compile()
