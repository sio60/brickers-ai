import json
import logging
import os
import re
import asyncio
from typing import List, Optional, Dict, Any, Union
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langgraph.graph import StateGraph, END

from .state import LogAnalysisState
from .persistence import get_archived_logs
from ..llm_clients import GeminiClient
from ..agent_tools import (
    execute_read_file, 
    execute_check_db, 
    execute_check_system, 
    execute_check_sqs
)

# Logger configuration
logger = logging.getLogger("agent.log_analyzer.agent")

# --- Nodes (ë…¸ë“œ ì •ì˜) ---

async def fetch_logs_node(state: LogAnalysisState):
    """
    [Node 1: Fetch] DB/Memoryì—ì„œ ë¡œê·¸ ë¡œë“œ
    """
    target_job_id = state.get("job_id")
    raw_logs = state.get("logs", "")
    
    logger.info(f"--- [ë¡œê·¸ ë¶„ì„ê¸°] 1. ë¡œê·¸ ìˆ˜ì§‘ (Job: {target_job_id}) ---")
    
    if not raw_logs and target_job_id:
        archived = await get_archived_logs(target_job_id)
        if archived:
            raw_logs = archived
            logger.info(f"âœ… DB ë¡œê·¸ ë¡œë“œ ì™„ë£Œ ({len(raw_logs)} chars)")
        else:
            raw_logs = "ë¡œê·¸ ì—†ìŒ"

    return {"logs": raw_logs, "iteration": 0}


async def parse_error_node(state: LogAnalysisState):
    """
    [Node 2: Parse Error] ë¡œê·¸ì—ì„œ ì „ì²´ Traceback ì²´ì¸ ì¶”ì¶œ
    - ë‹¨ì¼ ì—ëŸ¬ê°€ ì•„ë‹ˆë¼, í˜¸ì¶œ ìŠ¤íƒ ì „ì²´ë¥¼ ì¶”ì¶œí•˜ì—¬ ë§¥ë½ì„ ë³´ì¡´
    """
    logs = state.get("logs", "")
    logger.info("--- [ë¡œê·¸ ë¶„ì„ê¸°] 2. ì—ëŸ¬ íŒŒì‹± (Full Traceback) ---")
    
    # 1. ì „ì²´ Traceback ë¸”ë¡ ì¶”ì¶œ
    traceback_pattern = r'(Traceback \(most recent call last\):.*?)(?=\n\S|\Z)'
    traceback_blocks = re.findall(traceback_pattern, logs, re.DOTALL)
    
    # 2. ëª¨ë“  File ì°¸ì¡° ì¶”ì¶œ (í˜¸ì¶œ ìŠ¤íƒ ì „ì²´)
    file_pattern = r'File "(?P<file>[^"]+)", line (?P<line>\d+), in (?P<func>\S+)'
    
    all_frames = []  # ì „ì²´ í˜¸ì¶œ ìŠ¤íƒ
    user_frames = []  # ì‚¬ìš©ì ì½”ë“œë§Œ
    
    for match in re.finditer(file_pattern, logs):
        file_path = match.group("file")
        line_no = int(match.group("line"))
        func_name = match.group("func")
        
        frame = {
            "file": file_path,
            "line": line_no,
            "function": func_name,
            "is_user_code": "site-packages" not in file_path
        }
        all_frames.append(frame)
        
        if frame["is_user_code"]:
            user_frames.append(frame)
    
    # 3. ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ (ë§ˆì§€ë§‰ Exception ë¼ì¸)
    error_message = ""
    error_type = ""
    lines = logs.splitlines()
    for line in reversed(lines):
        # Python Exception íŒ¨í„´: ExceptionType: message
        err_match = re.match(r'^(\w+(?:Error|Exception|Warning|Timeout))\s*:\s*(.+)', line.strip())
        if err_match:
            error_type = err_match.group(1)
            error_message = err_match.group(2).strip()
            break
    
    # 4. ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ê°€ì¥ ì¤‘ìš”í•œ ì‚¬ìš©ì ì½”ë“œ í”„ë ˆì„ ìš°ì„ )
    primary_frame = user_frames[-1] if user_frames else (all_frames[-1] if all_frames else {})
    
    error_context = {
        "primary_file": primary_frame.get("file", "unknown"),
        "primary_line": primary_frame.get("line", 0),
        "primary_function": primary_frame.get("function", "unknown"),
        "error_type": error_type,
        "error_message": error_message,
        "call_stack": user_frames,  # ì‚¬ìš©ì ì½”ë“œ í˜¸ì¶œ ìŠ¤íƒ ì „ì²´
        "total_frames": len(all_frames),
        "user_code_frames": len(user_frames),
        "traceback_raw": traceback_blocks[-1][:500] if traceback_blocks else ""
    }
    
    logger.info(f"ğŸ¯ ì—ëŸ¬ ê°ì§€: {error_type}: {error_message[:80]}")
    logger.info(f"ğŸ“ ìœ„ì¹˜: {primary_frame.get('file', '?')}:{primary_frame.get('line', '?')} in {primary_frame.get('function', '?')}")
    logger.info(f"ğŸ“Š í˜¸ì¶œ ìŠ¤íƒ: ì „ì²´ {len(all_frames)}ê°œ í”„ë ˆì„, ì‚¬ìš©ì ì½”ë“œ {len(user_frames)}ê°œ")

    return {"error_context": error_context}


async def context_retrieval_node(state: LogAnalysisState):
    """
    [Node 3: Context Retrieval] 
    - ì—ëŸ¬ ë°œìƒ íŒŒì¼ + ì—°ê´€ íŒŒì¼ë“¤ (í˜¸ì¶œ ìŠ¤íƒ ê¸°ë°˜) ì½”ë“œ ì½ê¸°
    - DB / System / SQS ì¸í”„ë¼ ì¢…í•© ì¡°íšŒ
    """
    error_ctx = state.get("error_context", {})
    job_id = state.get("job_id")
    logs = state.get("logs", "")
    logger.info("--- [ë¡œê·¸ ë¶„ì„ê¸°] 3. ë¬¸ë§¥ í™•ë³´ (Multi-File + Infra) ---")
    
    related_code_sections = []
    db_context = ""
    system_info = ""
    sqs_info = ""
    
    # ========================================================
    # 1. Multi-File Code Reading (í˜¸ì¶œ ìŠ¤íƒì˜ ëª¨ë“  ì‚¬ìš©ì ì½”ë“œ íŒŒì¼)
    # ========================================================
    call_stack = error_ctx.get("call_stack", [])
    
    # ì¤‘ë³µ íŒŒì¼ ì œê±° (ê°™ì€ íŒŒì¼ì˜ ë‹¤ë¥¸ ë¼ì¸ì€ ë²”ìœ„ë¥¼ í•©ì¹¨)
    files_to_read = {}
    for frame in call_stack:
        fp = frame["file"]
        ln = frame["line"]
        fn = frame["function"]
        
        if fp not in files_to_read:
            files_to_read[fp] = {"lines": [], "functions": []}
        files_to_read[fp]["lines"].append(ln)
        files_to_read[fp]["functions"].append(fn)
    
    # ìµœëŒ€ 5ê°œ íŒŒì¼ê¹Œì§€ ì½ê¸° (ë„ˆë¬´ ë§ìœ¼ë©´ í† í° ë‚­ë¹„)
    for file_path, info in list(files_to_read.items())[:5]:
        try:
            # ê° íŒŒì¼ì—ì„œ ì—ëŸ¬ ê´€ë ¨ ë¼ì¸ Â±15ì¤„ ì½ê¸°
            min_line = max(1, min(info["lines"]) - 15)
            max_line = max(info["lines"]) + 15
            
            read_result = execute_read_file({
                "file_path": file_path,
                "line_start": min_line,
                "line_end": max_line
            })
            
            if "Error" not in str(read_result):
                section_header = f"ğŸ“„ File: {file_path} (Lines {min_line}-{max_line})"
                section_header += f"\n   Functions: {', '.join(info['functions'])}"
                section_header += f"\n   Error Lines: {info['lines']}"
                related_code_sections.append(f"{section_header}\n```python\n{read_result}\n```")
                logger.info(f"âœ… ì½”ë“œ ì½ê¸° ì„±ê³µ: {os.path.basename(file_path)} ({len(info['lines'])} ì§€ì )")
            else:
                related_code_sections.append(f"âš ï¸ ì½ê¸° ì‹¤íŒ¨: {file_path} â†’ {read_result}")
                logger.warning(f"âš ï¸ ì½”ë“œ ì½ê¸° ì‹¤íŒ¨: {file_path}")
                
        except Exception as e:
            related_code_sections.append(f"âŒ ì½ê¸° ì—ëŸ¬: {file_path} â†’ {e}")
            logger.error(f"âŒ ì½”ë“œ ì½ê¸° ì—ëŸ¬: {file_path}: {e}")
    
    # ì—ëŸ¬ê°€ ë°œìƒí•œ íŒŒì¼ì´ call_stackì— ì—†ëŠ” ê²½ìš° (primary_file ë³´ì¶©)
    primary_file = error_ctx.get("primary_file", "")
    if primary_file and primary_file not in files_to_read and primary_file != "unknown":
        try:
            primary_line = error_ctx.get("primary_line", 1)
            read_result = execute_read_file({
                "file_path": primary_file,
                "line_start": max(1, primary_line - 20),
                "line_end": primary_line + 20
            })
            if "Error" not in str(read_result):
                related_code_sections.insert(0, f"ğŸ“„ [PRIMARY] File: {primary_file} (Line {primary_line})\n```python\n{read_result}\n```")
                logger.info(f"âœ… Primary íŒŒì¼ ì½ê¸° ì„±ê³µ: {primary_file}")
        except Exception as e:
            logger.error(f"âŒ Primary íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    related_code = "\n\n---\n\n".join(related_code_sections) if related_code_sections else "ì½”ë“œ í™•ë³´ ì‹¤íŒ¨"
    
    # ========================================================
    # 2. DB Check (Job Status + ì—°ê²° ìƒíƒœ)
    # ========================================================
    if job_id:
        try:
            db_res = execute_check_db({"query": {"jobId": job_id}, "collection": "kids_jobs"})
            db_context = f"[DB ì¡°íšŒ ê²°ê³¼]\nJob Metadata: {db_res}"
            logger.info("âœ… DB ë©”íƒ€ë°ì´í„° í™•ë³´")
        except Exception as e:
            db_context = f"[DB ì¡°íšŒ ì‹¤íŒ¨] {e}"
            logger.warning(f"âš ï¸ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # ========================================================
    # 3. System Health Check (CPU/ë©”ëª¨ë¦¬/ë””ìŠ¤í¬)
    # ========================================================
    try:
        sys_res = execute_check_system({"dummy": "ignore"})
        system_info = f"[System Health]\n{sys_res}"
        logger.info("âœ… ì‹œìŠ¤í…œ ìƒíƒœ í™•ë³´")
    except Exception as e:
        system_info = f"[System Check ì‹¤íŒ¨] {e}"
        logger.warning(f"âš ï¸ System Check ì‹¤íŒ¨: {e}")

    # ========================================================
    # 4. SQS Queue Status (ì¡°ê±´ë¶€ â€” ë¡œê·¸ì— SQS ê´€ë ¨ í‚¤ì›Œë“œ ìˆì„ ë•Œ)
    # ========================================================
    sqs_keywords = ["sqs", "boto", "queue", "empty message", "timeout", "connection"]
    if any(kw in logs.lower() for kw in sqs_keywords):
        try:
            sqs_res = execute_check_sqs({"queue_type": "all"})
            sqs_info = f"[SQS Status]\n{sqs_res}"
            logger.info("âœ… SQS ìƒíƒœ í™•ë³´")
        except Exception as e:
            sqs_info = f"[SQS Check ì‹¤íŒ¨] {e}"
            logger.warning(f"âš ï¸ SQS Check ì‹¤íŒ¨: {e}")
    else:
        sqs_info = "[SQS] ê´€ë ¨ ì—ëŸ¬ ë¯¸ê°ì§€ â†’ ì¡°íšŒ ìƒëµ"

    # ëª¨ë“  ì¸í”„ë¼ ì •ë³´ ë³‘í•©
    infra_context = f"{db_context}\n\n{system_info}\n\n{sqs_info}"
    
    logger.info(f"ğŸ“Š ë¬¸ë§¥ í™•ë³´ ì™„ë£Œ: ì½”ë“œ {len(related_code_sections)}ê°œ íŒŒì¼, Infra 3ê°œ ì„¹ì…˜")

    return {"related_code": related_code, "db_context": infra_context}


async def solution_generation_node(state: LogAnalysisState):
    """
    [Node 4: Solution] ì¢…í•© ë¶„ì„ ë° ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
    - ê´€ë¦¬ì í˜ì´ì§€ìš©: ìµœëŒ€í•œ ì„¸ì„¸í•˜ê³  ìì„¸í•˜ê³  ì •í™•í•œ ë¶„ì„
    """
    logger.info("--- [ë¡œê·¸ ë¶„ì„ê¸°] 4. ìƒì„¸ ì†”ë£¨ì…˜ ìƒì„± (Admin Grade) ---")
    
    logs = state.get("logs", "")[-4000:]  # ê´€ë¦¬ììš©ì´ë¯€ë¡œ ë” ë§ì€ ë¡œê·¸ í¬í•¨
    error_ctx = state.get("error_context", {})
    related_code = state.get("related_code", "ì½”ë“œ í™•ë³´ ì‹¤íŒ¨")
    db_ctx = state.get("db_context", "")
    
    system_prompt = """
    ë‹¹ì‹ ì€ Brickers AI ì‹œìŠ¤í…œì˜ **ìˆ˜ì„ ë””ë²„ê¹… ì „ë¬¸ê°€(Senior Debugging Specialist)**ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ë¶„ì„ ë¦¬í¬íŠ¸ëŠ” **ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ**ì— í‘œì‹œë˜ë©°, ê°œë°œíŒ€ì´ ì´ ë¦¬í¬íŠ¸ë§Œ ë³´ê³  ì¦‰ì‹œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    [í•µì‹¬ ì›ì¹™] 
    - "í•œ ì¤„ ìš”ì•½"ìœ¼ë¡œ ëë‚´ì§€ ë§ˆì‹­ì‹œì˜¤. ë°˜ë“œì‹œ **ìƒì„¸í•œ ë‹¤ë‹¨ê³„ ë¶„ì„**ì„ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤.
    - ëª¨ë“  ë¶„ì„ì€ **í•œêµ­ì–´**ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    - ì¶”ìƒì  ì¡°ì–¸ ê¸ˆì§€. "ì½”ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”"ê°€ ì•„ë‹ˆë¼ "315ë¼ì¸ì˜ `last_progress` ë³€ìˆ˜ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ì„¸ìš”"ì²˜ëŸ¼ êµ¬ì²´ì ìœ¼ë¡œ.
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    [ë¶„ì„ ì ˆì°¨ â€” ë°˜ë“œì‹œ ì´ ìˆœì„œëŒ€ë¡œ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤]
    
    â–  STEP 1: ì—ëŸ¬ ì‹ë³„
    - ì–´ë–¤ ì¢…ë¥˜ì˜ ì—ëŸ¬(Exception Type)ê°€ ë°œìƒí–ˆëŠ”ê°€?
    - ì—ëŸ¬ ë©”ì‹œì§€ê°€ ì˜ë¯¸í•˜ëŠ” ë°”ëŠ” ë¬´ì—‡ì¸ê°€?
    - ì´ ì—ëŸ¬ê°€ Python ë‚´ì¥ ì—ëŸ¬ì¸ê°€, ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—ëŸ¬ì¸ê°€, ì»¤ìŠ¤í…€ ì—ëŸ¬ì¸ê°€?
    
    â–  STEP 2: í˜¸ì¶œ ìŠ¤íƒ ë¶„ì„
    - Tracebackì˜ í˜¸ì¶œ ìŠ¤íƒ(Call Stack)ì„ ë”°ë¼ê°€ë©° ì‹¤í–‰ íë¦„ì„ ì„¤ëª…í•˜ì‹œì˜¤.
    - ì–´ë–¤ í•¨ìˆ˜ê°€ ì–´ë–¤ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí–ˆê³ , ì–´ë””ì„œ ì‹¤íŒ¨í–ˆëŠ”ê°€?
    - `call_stack` ë°ì´í„°ì—ì„œ ì‚¬ìš©ì ì½”ë“œ í”„ë ˆì„ì„ ëª¨ë‘ ë¶„ì„í•˜ì‹œì˜¤.
    
    â–  STEP 3: ê·¼ë³¸ ì›ì¸ ë¶„ì„ (Root Cause)
    - ì—ëŸ¬ê°€ ë°œìƒí•œ ì½”ë“œ(`related_code`)ë¥¼ ì •ë°€ ê²€í† í•˜ì‹œì˜¤.
    - **"ì™œ"** ì´ ì½”ë“œê°€ ì‹¤íŒ¨í–ˆëŠ”ê°€? (ë³€ìˆ˜ ë¯¸ì´ˆê¸°í™”, None ì ‘ê·¼, íƒ€ì… ë¶ˆì¼ì¹˜, ì¸ì½”ë”©, íƒ€ì„ì•„ì›ƒ ë“±)
    - ì´ ì—ëŸ¬ê°€ ì¼ì‹œì (transient)ì¸ê°€, êµ¬ì¡°ì (structural)ì¸ê°€?
    
    â–  STEP 4: ì—°ê´€ ì½”ë“œ ê²€í† 
    - ì—ëŸ¬ ë°œìƒ íŒŒì¼ ì™¸ì—ë„, í˜¸ì¶œ ìŠ¤íƒì— í¬í•¨ëœ **ë‹¤ë¥¸ íŒŒì¼ë“¤ì˜ ì½”ë“œ**ë„ ê²€í† í•˜ì‹œì˜¤.
    - í•´ë‹¹ íŒŒì¼ë“¤ì—ì„œ ìˆ˜ì •ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆëŠ”ê°€?
    - í•¨ìˆ˜ ê°„ ë°ì´í„° ì „ë‹¬ ê³¼ì •ì—ì„œ íƒ€ì…ì´ë‚˜ ê°’ì´ ì˜ëª»ëœ ê³³ì€ ì—†ëŠ”ê°€?
    - ë¹„ë™ê¸°(async/await) ì²˜ë¦¬ê°€ ì˜¬ë°”ë¥´ê²Œ ë˜ì–´ ìˆëŠ”ê°€? (await ëˆ„ë½, ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œ í˜¸ì¶œ ë“±)
    
    â–  STEP 5: ì¸í”„ë¼ ìƒíƒœ ì ê²€
    - DB ì—°ê²° ìƒíƒœ: ì •ìƒì¸ê°€? íƒ€ì„ì•„ì›ƒì´ ë°œìƒí•  ë§Œí•œ ìƒíƒœì¸ê°€? ê°’ì´ ì˜ˆìƒê³¼ ë‹¤ë¥¸ê°€?
    - System Health: CPU/ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ì—¬ OOM Killì´ ë°œìƒí•  ìˆ˜ ìˆëŠ”ê°€?
    - SQS í: ë©”ì‹œì§€ê°€ ìŒ“ì—¬ì„œ ì²˜ë¦¬ê°€ ì§€ì—°ë˜ê³  ìˆëŠ”ê°€? Dead Letter Queueì— ë¹ ì§„ ë©”ì‹œì§€ê°€ ìˆëŠ”ê°€?
    
    â–  STEP 6: ìˆ˜ì •ì•ˆ ì œì‹œ
    - **Before (ë¬¸ì œ ì½”ë“œ)**: í˜„ì¬ ë¬¸ì œê°€ ë˜ëŠ” ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë³´ì—¬ì£¼ì‹œì˜¤.
    - **After (ìˆ˜ì • ì½”ë“œ)**: ìˆ˜ì •ëœ ì½”ë“œë¥¼ ì™„ì „í•œ í˜•íƒœë¡œ ë³´ì—¬ì£¼ì‹œì˜¤.
    - ìˆ˜ì •ì´ í•„ìš”í•œ **ëª¨ë“  íŒŒì¼**ì— ëŒ€í•´ ê°ê° Before/Afterë¥¼ ì œì‹œí•˜ì‹œì˜¤.
    - ì™œ ì´ë ‡ê²Œ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ì§€ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì‹œì˜¤.
    
    â–  STEP 7: ì¶”ê°€ ê¶Œì¥ ì‚¬í•­
    - ì´ ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì˜ˆë°©ì  ì¡°ì¹˜ (ì˜ˆ: ì…ë ¥ ê²€ì¦, try-except ì¶”ê°€, íƒ€ì„ì•„ì›ƒ ì„¤ì • ë“±)
    - í”„ë¡¬í”„íŠ¸ íŠœë‹ì´ í•„ìš”í•œ ê²½ìš° êµ¬ì²´ì  ë¬¸êµ¬ ì œì•ˆ (Gemini/Tripo)
    - íŒŒë¼ë¯¸í„° ì¡°ì •ì´ í•„ìš”í•œ ê²½ìš° êµ¬ì²´ì  ìˆ˜ì¹˜ ì œì•ˆ (ex: timeout 60s â†’ 120s)

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    [ì¶œë ¥ í˜•ì‹ â€” JSON]
    ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ì—„ìˆ˜í•˜ì‹­ì‹œì˜¤. ëª¨ë“  í•„ë“œë¥¼ ë¹ ì§ì—†ì´ ì±„ìš°ì‹­ì‹œì˜¤.
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    {
        "error_identification": {
            "error_type": "ì—ëŸ¬ íƒ€ì… (ex: RuntimeError)",
            "error_message": "ì—ëŸ¬ ë©”ì‹œì§€ ì „ë¬¸",
            "error_category": "code_bug | api_timeout | infra_issue | data_mismatch | async_issue | config_error",
            "severity": "critical | high | medium | low"
        },
        "call_stack_analysis": "í˜¸ì¶œ ìŠ¤íƒì„ ë”°ë¼ê°€ë©° ì‹¤í–‰ íë¦„ì„ ì„¤ëª… (ì–´ë–¤ í•¨ìˆ˜ â†’ ì–´ë–¤ í•¨ìˆ˜ â†’ ì‹¤íŒ¨ ì§€ì )",
        "root_cause": {
            "summary": "ê·¼ë³¸ ì›ì¸ í•œ ì¤„ ìš”ì•½",
            "detail": "ê·¼ë³¸ ì›ì¸ ìƒì„¸ ì„¤ëª… (ì½”ë“œ íë¦„, ë³€ìˆ˜ ìƒíƒœ, ì™¸ë¶€ ì˜ì¡´ì„± ë“±)",
            "is_transient": false
        },
        "investigation_steps": [
            "1ë‹¨ê³„: [ì–´ë–¤ íŒŒì¼]ì˜ [ì–´ë–¤ í•¨ìˆ˜]ë¥¼ í™•ì¸í•¨ â†’ [ë°œê²¬í•œ ì‚¬ì‹¤]",
            "2ë‹¨ê³„: [ì–´ë–¤ DB/API]ë¥¼ ì¡°íšŒí•¨ â†’ [ë°œê²¬í•œ ì‚¬ì‹¤]",
            "3ë‹¨ê³„: ..."
        ],
        "code_patches": [
            {
                "file_path": "ìˆ˜ì • ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ",
                "function_name": "ìˆ˜ì • ëŒ€ìƒ í•¨ìˆ˜ëª…",
                "line_range": "ìˆ˜ì • ë²”ìœ„ (ex: 310-320)",
                "before_code": "í˜„ì¬ ë¬¸ì œ ì½”ë“œ (ì›ë³¸)",
                "after_code": "ìˆ˜ì •ëœ ì½”ë“œ",
                "reason": "ì´ë ‡ê²Œ ìˆ˜ì •í•´ì•¼ í•˜ëŠ” ì´ìœ "
            }
        ],
        "related_issues": [
            {
                "file_path": "ì—°ê´€ íŒŒì¼ ê²½ë¡œ",
                "issue": "ë°œê²¬ëœ ë¬¸ì œ",
                "suggestion": "ìˆ˜ì • ì œì•ˆ"
            }
        ],
        "infra_diagnosis": {
            "db_status": "ì •ìƒ | ì´ìƒ | ë¯¸í™•ì¸",
            "db_detail": "DB ê´€ë ¨ ìƒì„¸ ì†Œê²¬",
            "system_status": "ì •ìƒ | ì´ìƒ | ë¯¸í™•ì¸",
            "system_detail": "CPU/ë©”ëª¨ë¦¬/ë””ìŠ¤í¬ ìƒì„¸ ì†Œê²¬",
            "sqs_status": "ì •ìƒ | ì´ìƒ | ë¯¸í™•ì¸",
            "sqs_detail": "SQS í ìƒì„¸ ì†Œê²¬"
        },
        "async_check": {
            "has_issue": false,
            "detail": "ë¹„ë™ê¸° ì²˜ë¦¬ ê´€ë ¨ ì†Œê²¬ (await ëˆ„ë½, ë™ê¸°/ë¹„ë™ê¸° í˜¼ìš© ë“±)"
        },
        "recommendations": [
            "ì˜ˆë°©ì  ì¡°ì¹˜ 1",
            "ì˜ˆë°©ì  ì¡°ì¹˜ 2"
        ],
        "summary": "ì „ì²´ ë¶„ì„ì„ 3-5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ (ê´€ë¦¬ìê°€ ë¹ ë¥´ê²Œ ì½ì„ ìˆ˜ ìˆë„ë¡)"
    }
    """
    
    user_prompt = f"""
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ë¶„ì„ ëŒ€ìƒ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    [Job ID]
    {state.get("job_id", "Unknown")}
    
    [Error Context (íŒŒì‹± ê²°ê³¼)]
    - Error Type: {error_ctx.get("error_type", "Unknown")}
    - Error Message: {error_ctx.get("error_message", "Unknown")}
    - Primary File: {error_ctx.get("primary_file", "Unknown")}:{error_ctx.get("primary_line", "?")}
    - Primary Function: {error_ctx.get("primary_function", "Unknown")}
    - Call Stack ({error_ctx.get("user_code_frames", 0)} user frames / {error_ctx.get("total_frames", 0)} total):
    {json.dumps(error_ctx.get("call_stack", []), indent=2, ensure_ascii=False)}
    
    [Raw Traceback]
    {error_ctx.get("traceback_raw", "ì—†ìŒ")}
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ì†ŒìŠ¤ ì½”ë“œ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    [Related Code (í˜¸ì¶œ ìŠ¤íƒ ê¸°ë°˜ ë‹¤ì¤‘ íŒŒì¼)]
    {related_code}
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ë¡œê·¸ ì „ë¬¸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    [Log Snippet (ìµœê·¼ 4000ì)]
    {logs}
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ì¸í”„ë¼ ìƒíƒœ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    [Infra Info (DB / System / SQS)]
    {db_ctx}
    """
    
    try:
        llm = GeminiClient()
        response = await asyncio.to_thread(llm.generate_json, user_prompt, system_prompt)
        result = json.dumps(response, ensure_ascii=False)
        logger.info(f"âœ… ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ ({len(result)} chars)")
        return {"analysis_result": result}
    except Exception as e:
        logger.error(f"âŒ AI ë¶„ì„ ì—ëŸ¬: {e}")
        fallback = {
            "error_identification": {"error_type": "AnalysisError", "error_message": str(e)},
            "root_cause": {"summary": f"AI ë¶„ì„ ìì²´ê°€ ì‹¤íŒ¨í•¨: {e}", "detail": str(e)},
            "summary": f"AI ë¶„ì„ ì—ëŸ¬ ë°œìƒ: {e}"
        }
        return {"analysis_result": json.dumps(fallback, ensure_ascii=False)}


# ============================================================
# Graph Construction
# ============================================================
workflow = StateGraph(LogAnalysisState)

workflow.add_node("fetch", fetch_logs_node)
workflow.add_node("parse_error", parse_error_node)
workflow.add_node("retrieve", context_retrieval_node)
workflow.add_node("solve", solution_generation_node)

workflow.set_entry_point("fetch")
workflow.add_edge("fetch", "parse_error")
workflow.add_edge("parse_error", "retrieve")
workflow.add_edge("retrieve", "solve")
workflow.add_edge("solve", END)

app = workflow.compile()
