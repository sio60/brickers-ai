# brickers-ai/route/kids_render.py
from __future__ import annotations

import os
import sys
import base64
import uuid
import traceback
import time
from pathlib import Path
from typing import Dict, Optional, Any
from datetime import datetime

import anyio
from fastapi import APIRouter, UploadFile, File, Form, HTTPException
from pydantic import BaseModel

import httpx


def log(msg: str) -> None:
    """íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ë¡œê·¸ ì¶œë ¥"""
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
    print(f"[{ts}] {msg}")

# ---- OpenAI ----
# OpenAI import removed - no longer needed

# ---- Tripo ----
from tripo3d import TripoClient
from tripo3d.models import TaskStatus

# ---- Gemini (Nano Banana) ----
from google import genai
from google.genai import types as genai_types


router = APIRouter(prefix="/api/v1/kids", tags=["kids"])

# -----------------------------
# Backend ì—°ë™ (Stage ì—…ë°ì´íŠ¸)
# -----------------------------
BACKEND_URL = os.environ.get("BACKEND_URL", "http://backend:8080").rstrip("/")

async def update_job_stage(job_id: str, stage: str) -> None:
    """
    Backendì— Job stage ì—…ë°ì´íŠ¸ ìš”ì²­
    - ì‹¤íŒ¨í•´ë„ ì „ì²´ í”Œë¡œìš°ì— ì˜í–¥ ì—†ìŒ (ë¡œê·¸ë§Œ ì¶œë ¥)
    """
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            await client.patch(
                f"{BACKEND_URL}/api/kids/jobs/{job_id}/stage",
                json={"stage": stage},
                headers={"X-Internal-Token": os.environ.get("INTERNAL_API_TOKEN", "")},
            )
        print(f"   âœ… [Stage Update] {stage}")
    except Exception as e:
        print(f"   âš ï¸ [Stage Update] ì‹¤íŒ¨ (ë¬´ì‹œ) | stage={stage} | error={str(e)}")

async def update_job_suggested_tags(job_id: str, tags: list[str]) -> None:
    """
    Backendì— Geminiê°€ ì¶”ì¶œí•œ suggested_tags ì €ì¥ ìš”ì²­
    - ì‹¤íŒ¨í•´ë„ ì „ì²´ í”Œë¡œìš°ì— ì˜í–¥ ì—†ìŒ (ë¡œê·¸ë§Œ ì¶œë ¥)
    """
    if not tags:
        return
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            resp = await client.patch(
                f"{BACKEND_URL}/api/kids/jobs/{job_id}/suggested-tags",
                json={"suggestedTags": tags},
                headers={"X-Internal-Token": os.environ.get("INTERNAL_API_TOKEN", "")},
            )
            if resp.status_code >= 400:
                 print(f"   âš ï¸ [Suggested Tags] Backend ì‘ë‹µ ì—ëŸ¬: Status={resp.status_code} | Body={resp.text}")
            else:
                 print(f"   âœ… [Suggested Tags] ì €ì¥ ì„±ê³µ: Status={resp.status_code} | Tags={tags}")
    except Exception as e:
        print(f"   âš ï¸ [Suggested Tags] ì €ì¥ ì‹¤íŒ¨ (í†µì‹  ì˜¤ë¥˜) | tags={tags} | error={str(e)}")

def _make_agent_log_sender(job_id: str):
    """CoScientist ì—ì´ì „íŠ¸ ë¡œê·¸ ì „ì†¡ ì½œë°± ìƒì„± (sync contextìš©)"""
    def send_log(step: str, message: str):
        url = f"{BACKEND_URL}/api/kids/jobs/{job_id}/logs"
        token = os.environ.get("INTERNAL_API_TOKEN", "")
        try:
            # Sync context ì´ë¯€ë¡œ httpx.post(sync) ì‚¬ìš©
            resp = httpx.post(
                url,
                json={"step": step, "message": message[:2000]},
                headers={"X-Internal-Token": token},
                timeout=5.0
            )
            if resp.status_code == 200:
                print(f"  [AgentLog] âœ… sent: [{step}] {message[:50]}...")
            else:
                print(f"  [AgentLog] âš ï¸ HTTP {resp.status_code} | url={url}")
        except Exception as e:
            print(f"  [AgentLog] âŒ failed: {e}")
    return send_log

# -----------------------------
# Helpers / Config
# -----------------------------
def _is_truthy(v: str) -> bool:
    return v.strip().lower() in ("1", "true", "yes", "y", "on")

DEBUG = _is_truthy(os.environ.get("DEBUG", "false"))

def _find_project_root(start: Path) -> Path:
    cur = start.resolve()
    if cur.is_file():
        cur = cur.parent
    markers = ("pyproject.toml", "requirements.txt", ".git")
    for p in [cur] + list(cur.parents):
        for m in markers:
            if (p / m).exists():
                return p
    return cur

PROJECT_ROOT = Path(os.environ.get("PROJECT_ROOT", "")).expanduser()
PROJECT_ROOT = PROJECT_ROOT.resolve() if str(PROJECT_ROOT).strip() else _find_project_root(Path(__file__))

PUBLIC_DIR = Path(os.environ.get("PUBLIC_DIR", PROJECT_ROOT / "public")).resolve()
GENERATED_DIR = Path(os.environ.get("GENERATED_DIR", PUBLIC_DIR / "generated")).resolve()
GENERATED_DIR.mkdir(parents=True, exist_ok=True)

# âœ… URL prefixëŠ” /api/generated ë¡œ í†µì¼
STATIC_PREFIX = os.environ.get("GENERATED_URL_PREFIX", "/api/generated").rstrip("/")

# íƒ€ì„ì•„ì›ƒ(í•„ìš”í•˜ë©´ envë¡œ ì¡°ì ˆ)
KIDS_TOTAL_TIMEOUT_SEC = int(os.environ.get("KIDS_TOTAL_TIMEOUT_SEC", "1800"))     # ì „ì²´ 30ë¶„
TRIPO_WAIT_TIMEOUT_SEC = int(os.environ.get("TRIPO_WAIT_TIMEOUT_SEC", "900"))     # íŠ¸ë¦¬í¬ ëŒ€ê¸° 15ë¶„
DOWNLOAD_TIMEOUT_SEC = float(os.environ.get("KIDS_DOWNLOAD_TIMEOUT_SEC", "180.0"))

# -----------------------------
# âœ… S3 ì—…ë¡œë“œ ì˜µì…˜ (AWS_* ì‹œí¬ë¦¿ ê¸°ë°˜)
# -----------------------------
# boto3 lazy import
try:
    import boto3
    from botocore.exceptions import ClientError
except ImportError:
    boto3 = None  # type: ignore
    ClientError = Exception  # type: ignore

AI_PUBLIC_BASE_URL = os.environ.get("AI_PUBLIC_BASE_URL", "").strip().rstrip("/")

AWS_REGION = (
    os.environ.get("AWS_REGION", "").strip()
    or os.environ.get("AWS_DEFAULT_REGION", "").strip()
)

S3_BUCKET = os.environ.get("AWS_S3_BUCKET", "").strip()

# ë²„í‚· URLì„ ì§ì ‘ ì§€ì •í•˜ê³  ì‹¶ìœ¼ë©´ ì´ê²ƒë„ ì‹œí¬ë¦¿ìœ¼ë¡œ ì¶”ê°€ ê°€ëŠ¥(ì„ íƒ)
# ì˜ˆ) https://my-bucket.s3.ap-northeast-2.amazonaws.com  ë˜ëŠ” CloudFront ë„ë©”ì¸
S3_PUBLIC_BASE_URL = os.environ.get("S3_PUBLIC_BASE_URL", "").strip().rstrip("/")

# S3 ì¼¤ì§€ ì—¬ë¶€: ê¸°ë³¸ì€ "ë²„í‚· ìˆìœ¼ë©´ ì¼œì§"
USE_S3 = _is_truthy(os.environ.get("USE_S3", "true" if S3_BUCKET else "false"))

# prefix (ì„ íƒ)
S3_PREFIX = os.environ.get("S3_PREFIX", "uploads/ai-generated").strip().strip("/")

# ê³µê°œ URLì´ ì•ˆ ë˜ë©´ presignìœ¼ë¡œ ë‚´ë ¤ì£¼ê¸°(ì„ íƒ)
S3_PRESIGN = _is_truthy(os.environ.get("S3_PRESIGN", "false"))
S3_PRESIGN_EXPIRES = int(os.environ.get("S3_PRESIGN_EXPIRES", "86400"))

# ë‹¤ìš´ë¡œë“œë¡œ ê°•ì œ(ldr/glb)
S3_FORCE_ATTACHMENT = _is_truthy(os.environ.get("S3_FORCE_ATTACHMENT", "true"))

# ë²„í‚·ì´ ACL public-read í—ˆìš©ì¼ ë•Œë§Œ(ë³´í†µì€ false ìœ ì§€ ì¶”ì²œ)
S3_USE_ACL_PUBLIC_READ = _is_truthy(os.environ.get("S3_USE_ACL_PUBLIC_READ", "false"))

_S3_CLIENT = None

def _require_s3_ready() -> None:
    if not USE_S3:
        return
    if boto3 is None:
        raise RuntimeError("boto3 is not installed (pip install boto3)")
    if not S3_BUCKET:
        raise RuntimeError("AWS_S3_BUCKET is not set")
    if not AWS_REGION:
        raise RuntimeError("AWS_REGION is not set")

def _get_s3_client():
    global _S3_CLIENT
    if _S3_CLIENT is not None:
        return _S3_CLIENT
    _require_s3_ready()

    # boto3ëŠ” ì•„ë˜ envë¥¼ ìë™ìœ¼ë¡œ ì½ìŒ:
    # AWS_ACCESS_KEY_ID / AWS_SECRET_ACCESS_KEY / AWS_REGION
    _S3_CLIENT = boto3.client("s3", region_name=AWS_REGION)
    return _S3_CLIENT

def _public_s3_url(key: str) -> str:
    # 1) ëª…ì‹œí•œ base url ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš© (CloudFrontë©´ ì—¬ê¸° ë„£ëŠ” ê²Œ ë² ìŠ¤íŠ¸)
    if S3_PUBLIC_BASE_URL:
        return f"{S3_PUBLIC_BASE_URL}/{key}"

    # 2) ì—†ìœ¼ë©´ region ê¸°ë°˜ ê¸°ë³¸ URL ìƒì„± (ë²„í‚·ì´ public/ë˜ëŠ” CloudFront ì—†ìœ¼ë©´ ì ‘ê·¼ ì•ˆ ë  ìˆ˜ ìˆìŒ)
    if AWS_REGION == "us-east-1":
        return f"https://{S3_BUCKET}.s3.amazonaws.com/{key}"
    return f"https://{S3_BUCKET}.s3.{AWS_REGION}.amazonaws.com/{key}"

def _presigned_get_url(key: str) -> str:
    client = _get_s3_client()
    return client.generate_presigned_url(
        "get_object",
        Params={"Bucket": S3_BUCKET, "Key": key},
        ExpiresIn=S3_PRESIGN_EXPIRES,
    )

def _s3_url_for_key(key: str) -> str:
    # public ì ‘ê·¼ì´ ì•ˆ ë˜ë©´ presign ì¼œ
    if S3_PRESIGN:
        return _presigned_get_url(key)
    return _public_s3_url(key)

def _upload_to_s3(local_path: Path, key: str, content_type: str | None = None) -> str:
    """
    ë¡œì»¬ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œí•˜ê³  public URL ë°˜í™˜.
    USE_S3=falseë©´ ì•„ë¬´ê²ƒë„ ì•ˆ í•¨.
    """
    if not USE_S3:
        return ""
    
    client = _get_s3_client()
    
    extra_args: dict = {}
    if content_type:
        extra_args["ContentType"] = content_type
    
    # ldr/glbëŠ” ë‹¤ìš´ë¡œë“œ ê°•ì œ
    if S3_FORCE_ATTACHMENT and local_path.suffix.lower() in (".ldr", ".glb"):
        extra_args["ContentDisposition"] = f'attachment; filename="{local_path.name}"'
    
    if S3_USE_ACL_PUBLIC_READ:
        extra_args["ACL"] = "public-read"
    
    client.upload_file(str(local_path), S3_BUCKET, key, ExtraArgs=extra_args if extra_args else None)
    
    return _s3_url_for_key(key)

def _guess_content_type(path: Path) -> str:
    ext = path.suffix.lower()
    return {
        ".png": "image/png",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".webp": "image/webp",
        ".glb": "application/octet-stream",
        ".gltf": "model/gltf+json",
        ".ldr": "text/plain",
        ".json": "application/json",
    }.get(ext, "application/octet-stream")

def _mime_to_ext(mime: str) -> str:
    m = (mime or "").lower()
    if "png" in m:
        return ".png"
    if "jpeg" in m or "jpg" in m:
        return ".jpg"
    if "webp" in m:
        return ".webp"
    return ".png"

async def _write_bytes_async(path: Path, data: bytes) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    await anyio.to_thread.run_sync(path.write_bytes, data)

async def _read_bytes_async(path: Path) -> bytes:
    return await anyio.to_thread.run_sync(path.read_bytes)

def _write_error_log(out_dir: Path, text: str) -> None:
    try:
        out_dir.mkdir(parents=True, exist_ok=True)
        (out_dir / "error.log").write_text(text, encoding="utf-8")
    except Exception:
        pass

def _to_generated_url(p: Path, out_dir: Path) -> str:
    """
    USE_S3=trueë©´: S3ì— ì—…ë¡œë“œ í›„ S3 URL ë°˜í™˜
    USE_S3=falseë©´: GENERATED_DIR ê¸°ì¤€ /api/generated/... URL ë°˜í™˜
    GENERATED_DIR ë°– íŒŒì¼ì´ë©´: out_dirë¡œ ë³µì‚¬ í›„ ì²˜ë¦¬
    """
    from datetime import datetime

    p = Path(p).resolve()
    gen = GENERATED_DIR.resolve()

    # GENERATED_DIR ë°– íŒŒì¼ì´ë©´ out_dirë¡œ ë³µì‚¬
    try:
        rel = p.relative_to(gen)
    except ValueError:
        out_dir = out_dir.resolve()
        out_dir.mkdir(parents=True, exist_ok=True)
        dst = out_dir / p.name
        if p != dst:
            dst.write_bytes(p.read_bytes())
        p = dst
        rel = dst.relative_to(gen)

    # âœ… S3 ì—…ë¡œë“œ ëª¨ë“œ (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ê²½ë¡œ êµ¬ì¡°í™”)
    if USE_S3:
        try:
            now = datetime.now()
            year, month = now.year, now.month
            # uploads/ai-generated/2026/01/req_abc/corrected.png
            s3_key = f"{S3_PREFIX}/{year:04d}/{month:02d}/{rel.as_posix()}" if S3_PREFIX else rel.as_posix()
            content_type = _guess_content_type(p)
            s3_url = _upload_to_s3(p, s3_key, content_type)
            if s3_url:
                return s3_url
        except Exception as e:
            print(f"[S3 upload failed, fallback to local] {e}")

    # âœ… ë¡œì»¬ fallback
    url = f"{STATIC_PREFIX}/" + rel.as_posix()
    if AI_PUBLIC_BASE_URL:
        return f"{AI_PUBLIC_BASE_URL}{url}"
    return url

async def _download_http_to_file(url: str, dst: Path) -> Path:
    dst.parent.mkdir(parents=True, exist_ok=True)
    async with httpx.AsyncClient(timeout=DOWNLOAD_TIMEOUT_SEC, follow_redirects=True) as client:
        r = await client.get(url)
        r.raise_for_status()
        await _write_bytes_async(dst, r.content)
    return dst

async def _download_from_s3(url: str) -> bytes:
    """S3 URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    async with httpx.AsyncClient(timeout=120.0, follow_redirects=True) as client:
        resp = await client.get(url)
        resp.raise_for_status()
        return resp.content

def _generate_bom_from_ldr(ldr_path: Path) -> Dict[str, Any]:
    """
    LDR íŒŒì¼ì—ì„œ BOM (Bill of Materials) ìƒì„±
    Returns: {
        "total_parts": int,
        "parts": [{"part_id": str, "color": str, "quantity": int}, ...]
    }
    """
    from collections import Counter

    if not ldr_path.exists():
        return {"total_parts": 0, "parts": []}

    content = ldr_path.read_text(encoding="utf-8", errors="ignore")
    lines = content.splitlines()

    # LDraw íŒŒì¸  ë¼ì¸ ì¶”ì¶œ (íƒ€ì… 1)
    parts_counter = Counter()

    for line in lines:
        line = line.strip()
        if not line or line.startswith("0"):  # ì£¼ì„ ë˜ëŠ” ë©”íƒ€ë°ì´í„°
            continue

        parts = line.split()
        if len(parts) >= 15 and parts[0] == "1":  # íƒ€ì… 1: ì„œë¸ŒíŒŒì¼ ì°¸ì¡° (íŒŒì¸ )
            color = parts[1]
            part_id = parts[14] if len(parts) > 14 else "unknown"
            # .dat í™•ì¥ì ì œê±°
            if part_id.endswith(".dat"):
                part_id = part_id[:-4]

            key = f"{part_id}_{color}"
            parts_counter[key] += 1

    # BOM ìƒì„±
    bom_parts = []
    for key, qty in parts_counter.most_common():
        part_id, color = key.rsplit("_", 1)
        bom_parts.append({
            "part_id": part_id,
            "color": color,
            "quantity": qty
        })

    return {
        "total_parts": sum(parts_counter.values()),
        "parts": bom_parts
    }

def _parse_bool(v: str | bool | None, default: bool = False) -> bool:
    if v is None:
        return default
    if isinstance(v, bool):
        return v
    return v.strip().lower() in ("1", "true", "yes", "y", "on")

def _pick_model_url(files_url: Dict[str, str]) -> str:
    for k, u in files_url.items():
        if "glb" in k.lower() or u.lower().endswith(".glb"):
            return u
    for k, u in files_url.items():
        if "pbr" in k.lower():
            return u
    return next(iter(files_url.values()))

def _sanitize_glb_url(u: str) -> str:
    u = (u or "").strip()
    if u.startswith("/api/api/"):
        u = u.replace("/api/api/", "/api/", 1)
    return u

def _local_generated_path_from_url(u: str) -> Optional[Path]:
    u = _sanitize_glb_url(u)
    if u.startswith("/api/generated/"):
        rel = u[len("/api/generated/"):]
        return (GENERATED_DIR / rel).resolve()
    if u.startswith("/generated/"):
        rel = u[len("/generated/"):]
        return (GENERATED_DIR / rel).resolve()
    return None

# -----------------------------
# OpenAI prompt builder - REMOVED (ì§ì ‘ ì´ë¯¸ì§€ë¡œ Tripo í˜¸ì¶œ)
# -----------------------------
# âœ… OpenAI í”„ë¡¬í”„íŠ¸ ìƒì„± ë‹¨ê³„ ì œê±°ë¨
# âœ… Nano Banana ì´ë¯¸ì§€ë¥¼ Tripoì— ì§ì ‘ ì „ë‹¬

# -----------------------------
# Nano Banana (Gemini) - sync -> thread
# -----------------------------
PROMPT_NANO_BANANA = """
Create a high-quality, vibrant image suitable for 3D modeling.

Requirements:
- Single view from the best angle to capture the subject's key features
- Clean white studio background
- Soft, even lighting with subtle shadows
- Vivid, saturated colors with clear color separation
- Sharp, well-defined edges and contours
- High contrast between subject and background
- Professional product photography style
- Remove any text, logos, patterns, or decorative details
- Simplify complex textures into solid, uniform colors
- Maintain the overall shape and proportions of the subject

[METADATA_REQUEST]
Also, identify the subject in a single word and provide 3-5 relevant hashtags.
Format: SUBJECT: <word> | TAGS: <tag1>, <tag2>, ...
Example: SUBJECT: Pikachu | TAGS: Pokemon, Kids, Brick, Yellow
"""

def _decode_if_base64_image(data: bytes | str) -> bytes:
    if data is None:
        return b""

    if isinstance(data, str):
        s = data.strip()
    else:
        try:
            s = data.decode("utf-8", errors="strict").strip()
        except Exception:
            return data

    if s.startswith("data:image"):
        try:
            s = s.split(",", 1)[1].strip()
        except Exception:
            pass

    looks_like_base64 = (
        s.startswith("iVBOR") or
        s.startswith("/9j/") or
        all(c.isalnum() or c in "+/=\n\r" for c in s[:200])
    )

    if looks_like_base64:
        try:
            return base64.b64decode(s, validate=False)
        except Exception:
            return data if isinstance(data, (bytes, bytearray)) else s.encode("utf-8")

    return data if isinstance(data, (bytes, bytearray)) else s.encode("utf-8")

def _render_one_image_sync(img_bytes: bytes, mime: str) -> tuple[bytes, str, list[str]]:
    gemini_key = os.environ.get("GEMINI_API_KEY", "")
    if not gemini_key:
        raise RuntimeError("GEMINI_API_KEY is not set")

    model = os.environ.get("NANO_BANANA_MODEL", "gemini-2.5-flash-image")
    client = genai.Client(api_key=gemini_key)

    resp = client.models.generate_content(
        model=model,
        contents=[
            {"text": PROMPT_NANO_BANANA},
            {"inline_data": {"mime_type": mime, "data": img_bytes}},
        ],
        config=genai_types.GenerateContentConfig(response_modalities=["Text", "Image"]),
    )

    if not resp.candidates:
        raise ValueError("no candidates from model")

    parts = resp.candidates[0].content.parts if resp.candidates[0].content else []
    out_bytes = None
    meta_text = ""
    
    for i, part in enumerate(parts):
        # 1. ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
        if hasattr(part, "inline_data") and part.inline_data and part.inline_data.data:
            out_bytes = part.inline_data.data
        elif hasattr(part, "file_data") and part.file_data: # ë§Œì•½ì˜ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ file_data ì²´í¬
            # file_dataëŠ” ë³´í†µ ê°€ê³µì´ ë” í•„ìš”í•˜ì§€ë§Œ ì—¬ê¸°ì„  inline ìœ„ì£¼ë¡œ ì²˜ë¦¬
            pass

        # 2. ë©”íƒ€ë°ì´í„° (í…ìŠ¤íŠ¸) ì¶”ì¶œ
        if hasattr(part, "text") and part.text:
            meta_text += part.text
            
    # [Log] Gemini ì‘ë‹µ ì›ë³¸ í™•ì¸
    log(f"   ğŸ¤– [Gemini Raw Response] {meta_text.replace(chr(10), ' ')[:200]}...")

            
    # ì—ëŸ¬ ë°©ì§€: ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ì—ì„œë¼ë„ ì´ë¯¸ì§€ë¥¼ ì°¾ê±°ë‚˜(Base64) ì¬ì‹œë„ ë¡œì§ ê³ ë ¤ ê°€ëŠ¥
    if out_bytes is None:
        # í…ìŠ¤íŠ¸ ë‚´ì— Base64 ì´ë¯¸ì§€ê°€ ì„ì—¬ ìˆì„ ê°€ëŠ¥ì„± ì²´í¬
        if "data:image" in meta_text or (len(meta_text) > 1000 and any(prefix in meta_text for prefix in ["iVBOR", "/9j/"])):
             out_bytes = meta_text.strip() # _decode_if_base64_imageì—ì„œ ì²˜ë¦¬ë  ê²ƒ
        else:
             raise ValueError(f"no image returned from model (meta_text len: {len(meta_text)})")

    out_bytes = _decode_if_base64_image(out_bytes)

    # --- [ì´ë¯¸ì§€ ìœ íš¨ì„± ì²´í¬ ë¡œì§ ë³µêµ¬] ---
    is_valid_image = False
    # PNG/JPG ë§¤ì§ë„˜ë²„ ì²´í¬
    if len(out_bytes) >= 2 and out_bytes[0] == 0xFF and out_bytes[1] == 0xD8:
        is_valid_image = True
    elif len(out_bytes) >= 8 and out_bytes[:8] == b"\x89PNG\r\n\x1a\n":
        is_valid_image = True
    
    # ë§¤ì§ë„˜ë²„ê°€ ì—†ìœ¼ë©´ ë‚¨ì•„ìˆëŠ” base64 í•œ ë²ˆ ë” ì‹œë„
    if not is_valid_image:
        try:
            head = out_bytes[:20].decode("utf-8", errors="ignore")
            if head.startswith("iVBOR") or head.startswith("/9j/"):
                out_bytes = base64.b64decode(out_bytes, validate=False)
        except Exception:
            pass
    # ----------------------------------

    # ë©”íƒ€ë°ì´í„° íŒŒì‹± (SUBJECT: ..., TAGS: ...)
    subject = "Object"
    tags = ["Kids", "Brick"]
    
    try:
        if meta_text:
            print(f"[Gemini Meta] Raw extraction text: {meta_text[:100]}...")

        if "SUBJECT:" in meta_text:
            s_part = meta_text.split("SUBJECT:")[1].split("|")[0].strip()
            if s_part: subject = s_part
        if "TAGS:" in meta_text:
            t_part = meta_text.split("TAGS:")[1].strip()
            tags = [t.strip() for t in t_part.replace("#", "").split(",") if t.strip()]
    except Exception as e:
        print(f"[Gemini Meta] Tag parse error: {e}")

    return out_bytes, subject, tags

async def render_one_image_async(img_bytes: bytes, mime: str) -> tuple[bytes, str, list[str]]:
    # âœ… gemini í˜¸ì¶œì€ ë™ê¸°ë¼ì„œ threadë¡œ ë¹¼ì•¼ â€œì™„ì „ async ì•ˆì „â€
    return await anyio.to_thread.run_sync(_render_one_image_sync, img_bytes, mime)

# -----------------------------
# Brickify engine loader
# -----------------------------
AGE_TO_BUDGET = {"4-5": 300, "6-7": 350, "8-10": 400}


def _budget_to_start_target(eff_budget: int) -> int:
    # Frontend budgets: 300 / 350 / 400 (4-5 / 6-7 / 8-10)
    # [Increased] +10~15 to capture more detail like noses/tails
    if eff_budget <= 300:
        return 110
    if eff_budget <= 350:
        return 125
    if eff_budget <= 400:
        return 140
    return 145

def _load_engine_convert():
    """
    brick-engine í´ë”ëª…ì´ í•˜ì´í”ˆì´ë¼ importê°€ ì•ˆ ë˜ë‹ˆê¹Œ íŒŒì¼ê²½ë¡œë¡œ ëª¨ë“ˆ ë¡œë“œ.
    """
    import importlib.util

    engine_path = (PROJECT_ROOT / "brick-engine" / "glb_to_ldr_embedded.py").resolve()
    if not engine_path.exists():
        raise RuntimeError(f"engine file missing: {engine_path}")

    spec = importlib.util.spec_from_file_location("glb_to_ldr_embedded", str(engine_path))
    if spec is None or spec.loader is None:
        raise RuntimeError("failed to load spec for glb_to_ldr_embedded")

    mod = importlib.util.module_from_spec(spec)
    # Ensure module is registered for dataclasses/type resolution
    sys.modules[spec.name] = mod
    spec.loader.exec_module(mod)  # type: ignore
    if not hasattr(mod, "convert_glb_to_ldr"):
        raise RuntimeError("convert_glb_to_ldr not found in engine module")

    return mod.convert_glb_to_ldr

_CONVERT_FN = None

# --- Agent ëª¨ë“ˆ lazy loader ---
_REGEN_LOOP_FN = None
_GEMINI_CLIENT_CLS = None

def _load_agent_modules():
    """brick-engine/agent ì—ì„œ regeneration_loop, GeminiClient ë™ì  ë¡œë“œ"""
    global _REGEN_LOOP_FN, _GEMINI_CLIENT_CLS
    if _REGEN_LOOP_FN is not None:
        return _REGEN_LOOP_FN, _GEMINI_CLIENT_CLS

    agent_dir = str((PROJECT_ROOT / "brick-engine").resolve())
    if agent_dir not in sys.path:
        sys.path.insert(0, agent_dir)

    from agent.llm_regeneration_agent import regeneration_loop
    from agent.llm_clients import GeminiClient

    _REGEN_LOOP_FN = regeneration_loop
    _GEMINI_CLIENT_CLS = GeminiClient
    return _REGEN_LOOP_FN, _GEMINI_CLIENT_CLS

def _find_glb_in_dir(out_dir: Path) -> Optional[Path]:
    glbs = [p for p in out_dir.rglob("*.glb") if p.is_file() and p.stat().st_size > 0]
    return glbs[0] if glbs else None

def _pick_glb_from_downloaded(downloaded: Dict[str, str], out_dir: Path) -> Optional[Path]:
    for _, v in (downloaded or {}).items():
        p = Path(v)
        if p.suffix.lower() == ".glb" and p.exists() and p.stat().st_size > 0:
            return p
    return _find_glb_in_dir(out_dir)

# -----------------------------
# Request schema
# -----------------------------
class KidsProcessRequest(BaseModel):
    sourceImageUrl: str  # S3 URL (Frontendê°€ ì§ì ‘ ì—…ë¡œë“œí•œ URL)
    age: str = "6-7"
    budget: Optional[int] = None
    subject: Optional[str] = None  # [ì¶”ê°€] ì‚¬ë¬¼ ì´ë¦„ (ì˜ˆ: "ê°•ì•„ì§€")
    prompt: Optional[str] = None
    returnLdrData: bool = False

# Response schema
# -----------------------------
class ProcessResp(BaseModel):
    ok: bool
    reqId: str

    correctedUrl: str

    taskId: str
    modelUrl: str
    files: Dict[str, str]

    ldrUrl: str
    ldrData: Optional[str] = None
    bomUrl: str  # âœ… BOM íŒŒì¼ URL ì¶”ê°€
    
    subject: str # [ì¶”ê°€] ì‚¬ë¬¼ ëª…ì¹­
    tags: list[str] # [ì¶”ê°€] í•´ì‹œíƒœê·¸ ëª©ë¡

    parts: int
    finalTarget: int

# -----------------------------
# âœ… ë‚´ë¶€ í•¨ìˆ˜ (SQS Consumerì—ì„œ í˜¸ì¶œ)
# -----------------------------
async def process_kids_request_internal(
    job_id: str,
    source_image_url: str,
    age: str,
    budget: Optional[int] = None,
    subject: Optional[str] = None, # [ì¶”ê°€] ì‚¬ë¬¼ ëª…ì¹­
) -> Dict[str, Any]:
    """
    Kids ë Œë”ë§ ë‚´ë¶€ ë¡œì§ (SQS Consumerì—ì„œ í˜¸ì¶œ)
    - S3ì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    - Gemini ë³´ì •
    - Tripo 3D ìƒì„±
    - Brickify LDR ë³€í™˜
    - BOM ìƒì„±

    Args:
        job_id: Job ID (MongoDB)
        source_image_url: S3 ì—…ë¡œë“œëœ ì›ë³¸ ì´ë¯¸ì§€ URL
        age: ë‚˜ì´ ë²”ìœ„ (4-5, 6-7, 8-10)
        budget: ì˜ˆì‚° (Noneì´ë©´ age ê¸°ë°˜ ìë™ ì„¤ì •)

    Returns:
        {
            "correctedUrl": str,
            "modelUrl": str,
            "ldrUrl": str,
            "bomUrl": str,
            "parts": int,
            "finalTarget": int,
        }

    Raises:
        RuntimeError: ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ
    """
    import time
    total_start = time.time()

    TRIPO_API_KEY = os.environ.get("TRIPO_API_KEY", "")
    if not TRIPO_API_KEY:
        raise RuntimeError("TRIPO_API_KEY is not set")

    req_id = job_id  # Job IDë¥¼ req_idë¡œ ì‚¬ìš©
    out_req_dir = GENERATED_DIR / f"req_{req_id}"
    out_tripo_dir = GENERATED_DIR / f"tripo_{req_id}"
    out_brick_dir = GENERATED_DIR / f"brickify_{req_id}"
    out_req_dir.mkdir(parents=True, exist_ok=True)
    out_tripo_dir.mkdir(parents=True, exist_ok=True)
    out_brick_dir.mkdir(parents=True, exist_ok=True)

    log("â•" * 70)
    log(f"ğŸš€ [AI-SERVER] ìš”ì²­ ì‹œì‘ | jobId={job_id}")
    log(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ URL: {source_image_url}")
    log(f"ğŸ“Š íŒŒë¼ë¯¸í„°: subject={subject} | age={age} | budget={budget}")
    log(f"âš™ï¸  S3 ëª¨ë“œ: {'âœ… ON' if USE_S3 else 'âŒ OFF'} | bucket={S3_BUCKET or 'N/A'}")
    log("â•" * 70)

    try:
        # âœ… ì „ì²´ íƒ€ì„ì•„ì›ƒ (ë¬´í•œ ëŒ€ê¸° ë°©ì§€)
        with anyio.fail_after(KIDS_TOTAL_TIMEOUT_SEC):

            # -----------------
            # 0) S3ì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            # -----------------
            step_start = time.time()
            log(f"ğŸ“Œ [STEP 0/5] S3ì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            img_bytes = await _download_from_s3(source_image_url)
            raw_path = out_req_dir / "raw.png"
            await _write_bytes_async(raw_path, img_bytes)
            log(f"âœ… [STEP 0/5] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ | {len(img_bytes)/1024:.1f}KB | {time.time()-step_start:.2f}s")

            # 1) ë³´ì • (Gemini) - threadë¡œ ì•ˆì „
            # -----------------
            step_start = time.time()
            log(f"ğŸ“Œ [STEP 1/5] Gemini ì´ë¯¸ì§€ ë³´ì • ë° íƒœê·¸ ì¶”ì¶œ ì‹œì‘...")
            corrected_bytes, ai_subject, ai_tags = await render_one_image_async(img_bytes, "image/png")
            
            # ì‚¬ìš©ì ì œê³µ subjectê°€ ì—†ìœ¼ë©´ AIê°€ ì°¾ì€ ì´ë¦„ ì‚¬ìš©
            final_subject = subject or ai_subject
            
            corrected_path = out_req_dir / "corrected.png"
            await _write_bytes_async(corrected_path, corrected_bytes)
            corrected_url = _to_generated_url(corrected_path, out_dir=out_req_dir)
            log(f"âœ… [STEP 1/5] Gemini ì™„ë£Œ | Subject: {final_subject} | Tags: {ai_tags} | {time.time()-step_start:.2f}s")
            
            # âœ… Backendì— Geminiê°€ ì¶”ì¶œí•œ íƒœê·¸ ì €ì¥
            await update_job_suggested_tags(job_id, ai_tags)

            # -----------------
            # 2) Tripo 3D (ì´ë¯¸ì§€ â†’ 3D ëª¨ë¸ ìƒì„±)
            # -----------------
            step_start = time.time()
            log(f"ğŸ“Œ [STEP 2/4] Tripo 3D ëª¨ë¸ ìƒì„± ì‹œì‘ (image-to-model)... (timeout={TRIPO_WAIT_TIMEOUT_SEC}s)")

            # âœ… Backendì— stage ì—…ë°ì´íŠ¸
            await update_job_stage(job_id, "THREE_D_PREVIEW")

            async with TripoClient(api_key=TRIPO_API_KEY) as client:
                # âœ… image_to_model: Nano Banana ì´ë¯¸ì§€ë¥¼ ì§ì ‘ Tripoì— ì „ë‹¬
                task_id = await client.image_to_model(image=str(corrected_path))
                print(f"   ğŸ”„ Tripo ì‘ì—… ìƒì„±ë¨ | taskId={task_id}")

                # âœ… Tripo ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ
                with anyio.fail_after(TRIPO_WAIT_TIMEOUT_SEC):
                    task = await client.wait_for_task(task_id, verbose=DEBUG)

                if task.status != TaskStatus.SUCCESS:
                    raise RuntimeError(f"Tripo task failed: status={task.status}")

                print(f"   âœ… Tripo ì‘ì—… ì™„ë£Œ | status={task.status}")
                downloaded = await client.download_task_models(task, str(out_tripo_dir))
                print(f"   ğŸ“¥ Tripo íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ | files={list(downloaded.keys()) if downloaded else 'None'}")

            tripo_elapsed = time.time() - step_start
            log(f"âœ… [STEP 2/4] Tripo ì™„ë£Œ | {tripo_elapsed:.2f}s")

            # -----------------
            # 3-1) downloaded ì •ê·œí™” (URLì´ë©´ ë‹¤ì‹œ ë°›ì•„ì„œ íŒŒì¼ë¡œ)
            # -----------------
            fixed_downloaded: Dict[str, str] = {}
            for model_type, path_or_url in (downloaded or {}).items():
                if not path_or_url:
                    continue
                s = str(path_or_url)
                if s.startswith(("http://", "https://")):
                    ext_guess = ".glb" if ".glb" in s.lower() else ".bin"
                    dst = out_tripo_dir / f"{model_type}{ext_guess}"
                    await _download_http_to_file(s, dst)
                    fixed_downloaded[model_type] = str(dst)
                else:
                    fixed_downloaded[model_type] = s

            missing = []
            for k, v in fixed_downloaded.items():
                pv = Path(v)
                if not pv.exists():
                    missing.append((k, v, "NOT_EXISTS"))
                elif pv.stat().st_size == 0:
                    missing.append((k, v, "ZERO_SIZE"))
            if missing:
                raise RuntimeError(f"Downloaded files missing: {missing}")

            # -----------------
            # 3-2) Tripo íŒŒì¼ URL ë§µ ë§Œë“¤ê¸°
            # -----------------
            files_url: Dict[str, str] = {}
            for model_type, path_str in fixed_downloaded.items():
                files_url[model_type] = _to_generated_url(Path(path_str), out_dir=out_tripo_dir)

            if not any(u.lower().endswith(".glb") for u in files_url.values()):
                glb_fallback = _find_glb_in_dir(out_tripo_dir)
                if glb_fallback:
                    files_url["glb"] = _to_generated_url(glb_fallback, out_dir=out_tripo_dir)

            if not files_url:
                raise RuntimeError("No downloadable model files found in out_tripo_dir")

            model_url = _pick_model_url(files_url)

            # -----------------
            # 3) Brickify ì…ë ¥ GLB í™•ë³´
            # -----------------
            glb_path = _pick_glb_from_downloaded(fixed_downloaded, out_tripo_dir)

            if glb_path is None:
                local = _local_generated_path_from_url(model_url)
                if local and local.exists() and local.stat().st_size > 0:
                    glb_path = local
                else:
                    if not model_url.startswith(("http://", "https://")):
                        raise RuntimeError(f"Cannot resolve glb for brickify: {model_url}")
                    glb_path = out_brick_dir / "input.glb"
                    await _download_http_to_file(model_url, glb_path)

            if not glb_path.exists() or glb_path.stat().st_size == 0:
                raise RuntimeError(f"GLB missing/empty: {glb_path}")

            print(f"   ğŸ“¦ GLB ì¤€ë¹„ì™„ë£Œ | path={glb_path.name} | size={glb_path.stat().st_size/1024:.1f}KB")

            # -----------------
            # 4) Brickify ì‹¤í–‰ (CPU heavy -> thread)
            # -----------------
            step_start = time.time()
            eff_budget = int(budget) if budget is not None else int(AGE_TO_BUDGET.get(age.strip(), 100))
            start_target = _budget_to_start_target(eff_budget)
            log(f"ğŸ“Œ [STEP 3/4] Brickify LDR ë³€í™˜ ì‹œì‘... | budget={eff_budget} | target={start_target}")

            # âœ… Backendì— stage ì—…ë°ì´íŠ¸
            await update_job_stage(job_id, "MODEL")

            global _CONVERT_FN
            if _CONVERT_FN is None:
                _CONVERT_FN = _load_engine_convert()

            out_ldr = out_brick_dir / "result.ldr"

            # Agent ëª¨ë“ˆ ë¡œë“œ
            regeneration_loop, GeminiClient = _load_agent_modules()

            # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            gemini_key = os.environ.get("GEMINI_API_KEY", "")
            llm_client = GeminiClient(api_key=gemini_key)

            agent_params = {
                "target": start_target,
                "budget": eff_budget,
                "min_target": 5,
                "shrink": 0.85,
                "search_iters": 6,
                "kind": "brick",
                "plates_per_voxel": 3,
                "interlock": True,
                "max_area": 20,
                "solid_color": 4,
                "use_mesh_color": True,
                "invert_y": False,
                "smart_fix": True,
                "fill": False,  # [Reverted] Save budget for external detail
                "step_order": "bottomup",
                "span": 4,
                "max_new_voxels": 20000,  # [Increased] 12000 -> 20000
                "refine_iters": 8,
                "ensure_connected": True,
                "mode": "kids", # [Explicit] Use kids catalog
                "small_side_contact": False, # [Rollback] Must maintain vertical interlocking
                "min_embed": 2,
                "erosion_iters": 0,  # [Disabled] Prevent losing thin details (tails/noses)
                "fast_search": True,
                "extend_catalog": True,
                "max_len": 8,
            }

            agent_params["log_callback"] = _make_agent_log_sender(job_id)

            def run_agent_sync():
                return regeneration_loop(
                    glb_path=str(glb_path),
                    output_ldr_path=str(out_ldr),
                    subject_name=final_subject, # [ìˆ˜ì •] ìë™ ì¸ì‹ëœ ì´ë¦„ ì „ë‹¬
                    llm_client=llm_client,
                    max_retries=3,
                    gui=False,
                    params=agent_params,
                )

            result: Dict[str, Any] = await anyio.to_thread.run_sync(run_agent_sync)

            brickify_elapsed = time.time() - step_start
            log(f"âœ… [STEP 3/4] Brickify ì™„ë£Œ | parts={result.get('parts')} | target={result.get('final_target')} | {brickify_elapsed:.2f}s")

            if not out_ldr.exists() or out_ldr.stat().st_size == 0:
                raise RuntimeError("LDR output missing/empty")

            # -----------------
            # 5) ê²°ê³¼ URL ìƒì„± ë° BOM íŒŒì¼ ìƒì„±
            # -----------------
            step_start = time.time()
            log(f"ğŸ“Œ [STEP 4/4] ê²°ê³¼ URL ìƒì„± ë° BOM íŒŒì¼ ìƒì„± ì¤‘... (S3={'ON' if USE_S3 else 'OFF'})")
            ldr_url = _to_generated_url(out_ldr, out_dir=out_brick_dir)

            # âœ… BOM (Bill of Materials) íŒŒì¼ ìƒì„±
            print(f"   ğŸ“‹ BOM íŒŒì¼ ìƒì„± ì¤‘...")
            bom_data = await anyio.to_thread.run_sync(_generate_bom_from_ldr, out_ldr)
            out_bom = out_brick_dir / "bom.json"
            import json
            await _write_bytes_async(out_bom, json.dumps(bom_data, indent=2, ensure_ascii=False).encode("utf-8"))
            bom_url = _to_generated_url(out_bom, out_dir=out_brick_dir)
            print(f"   âœ… BOM íŒŒì¼ ìƒì„± ì™„ë£Œ | total_parts={bom_data['total_parts']} | unique={len(bom_data['parts'])}")

            log(f"âœ… [STEP 4/4] URL ìƒì„± ì™„ë£Œ | {time.time()-step_start:.2f}s")

            total_elapsed = time.time() - total_start
            log("â•" * 70)
            log(f"ğŸ‰ [AI-SERVER] ìš”ì²­ ì™„ë£Œ! | jobId={job_id}")
            log(f"â±ï¸  ì´ ì†Œìš”ì‹œê°„: {total_elapsed:.2f}s ({total_elapsed/60:.1f}ë¶„)")
            log(f"   - Tripo 3D: {tripo_elapsed:.2f}s")
            log(f"   - Brickify: {brickify_elapsed:.2f}s")
            log(f"ğŸ“¦ ê²°ê³¼: parts={result.get('parts')} | ldrSize={out_ldr.stat().st_size/1024:.1f}KB")
            print("â•" * 70)

            return {
                "correctedUrl": corrected_url,
                "modelUrl": model_url,
                "ldrUrl": ldr_url,
                "bomUrl": bom_url,
                "subject": final_subject,
                "tags": ai_tags,
                "parts": int(result.get("parts", 0)),
                "finalTarget": int(result.get("final_target", 0)),
            }

    except Exception as e:
        total_elapsed = time.time() - total_start
        tb = traceback.format_exc()
        log("â•" * 70)
        log(f"âŒ [AI-SERVER] ìš”ì²­ ì‹¤íŒ¨! | jobId={job_id} | ì†Œìš”ì‹œê°„={total_elapsed:.2f}s")
        log(f"âŒ ì—ëŸ¬: {str(e)}")
        log("â•" * 70)
        log(tb)
        _write_error_log(out_req_dir, tb)
        _write_error_log(out_tripo_dir, tb)
        _write_error_log(out_brick_dir, tb)

        raise RuntimeError(str(e)) from e


# -----------------------------
# âœ… HTTP API (í˜¸í™˜ì„± ìœ ì§€)
# -----------------------------
@router.post("/process-all", response_model=ProcessResp)
async def process(request: KidsProcessRequest):
    """
    Kids Mode ì²˜ë¦¬ (HTTP ì—”ë“œí¬ì¸íŠ¸)
    - ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€
    - ë‚´ë¶€ì ìœ¼ë¡œ process_kids_request_internal í˜¸ì¶œ
    """
    req_id = uuid.uuid4().hex

    try:
        result = await process_kids_request_internal(
            job_id=req_id,
            source_image_url=request.sourceImageUrl,
            age=request.age,
            budget=request.budget,
            subject=request.subject, # [ì¶”ê°€]
        )

        # âœ… S3 ì‚¬ìš© ì‹œì—ëŠ” ldrData ìƒëµ (ë¶ˆí•„ìš”í•œ base64 ì¸ì½”ë”© ì œê±°)
        ldr_data_uri: Optional[str] = None
        if not USE_S3 and request.returnLdrData:
            # ldrUrlì—ì„œ íŒŒì¼ ì½ê¸°
            ldr_path = _local_generated_path_from_url(result["ldrUrl"])
            if ldr_path and ldr_path.exists():
                b = await _read_bytes_async(ldr_path)
                b64_str = base64.b64encode(b).decode("utf-8")
                ldr_data_uri = f"data:text/plain;base64,{b64_str}"

        return {
            "ok": True,
            "reqId": req_id,
            "correctedUrl": result["correctedUrl"],
            "taskId": req_id,  # task_idëŠ” ì—†ì§€ë§Œ í˜¸í™˜ì„± ìœ ì§€
            "modelUrl": result["modelUrl"],
            "files": {},  # filesëŠ” ë‚´ë¶€ í•¨ìˆ˜ì—ì„œ ë°˜í™˜ ì•ˆ í•¨
            "ldrUrl": result["ldrUrl"],
            "ldrData": ldr_data_uri,
            "bomUrl": result["bomUrl"],
            "subject": result["subject"],
            "tags": result["tags"],
            "parts": result["parts"],
            "finalTarget": result["finalTarget"],
        }

    except HTTPException:
        raise
    except Exception as e:
        if DEBUG:
            raise HTTPException(status_code=500, detail={"reqId": req_id, "error": str(e)})
        raise HTTPException(status_code=500, detail="process failed")