"""
Admin AI Analyst â€” Node êµ¬í˜„
7ê°œ ë…¸ë“œ: Miner â†’ Evaluator â†’ Diagnoser â†’ Strategist â†’ DeepInvestigator â†’ ReporterGreen â†’ Finalizer
"""
from __future__ import annotations

import json
import logging
from datetime import datetime
from typing import List, Dict, Any

from .state import AdminAnalystState
from .prompts import (
    DIAGNOSER_PROMPT,
    STRATEGIST_PROMPT,
    GUARDIAN_PROMPT,
    REPORTER_GREEN_PROMPT,
    FINALIZER_PROMPT,
    QUERY_ANALYST_PROMPT,
)

# ... (ê¸°ì¡´ ì½”ë“œ: miner_node, evaluator_node ìœ ì§€)


from .llm_utils import call_llm_json

log = logging.getLogger("admin_analyst.nodes")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 1: Miner â€” ë°ì´í„° ìˆ˜ì§‘
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def miner_node(state: AdminAnalystState) -> dict:
    """GA4 Data API + Direct MongoDBì—ì„œ í†µí•© ì§€í‘œ ë° ë¡œìš° ë°ì´í„° ìˆ˜ì§‘."""
    import asyncio
    from datetime import datetime
    from service.backend_client import get_full_report, get_product_intelligence
    from db import get_db

    log.info("â›ï¸ [Miner] ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (Analytics + MongoDB)...")
    
    try:
        # 1. Macro Analytics ë³‘ë ¬ ìˆ˜ì§‘ (GA4 ê¸°ë°˜)
        full_report_task = get_full_report(days=7)
        product_intel_task = get_product_intelligence(days=14)
        
        # 2. Micro Logs ìˆ˜ì§‘ (Direct MongoDB - Ground Truth)
        db = get_db()
        one_day_ago = datetime.now().timestamp() - 86400
        jobs_col = db["kids_jobs"]
        
        # ê°€ë²¼ìš´ ì¿¼ë¦¬ë¥¼ ìœ„í•´ ìµœê·¼ 100ê±´ë§Œ ìƒ˜í”Œë§
        recent_jobs = list(jobs_col.find({
            "createdAt": {"$gte": datetime.fromtimestamp(one_day_ago)}
        }).sort("createdAt", -1).limit(100))

        # ì„¸ë¶€ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
        db_raw = {
            "total_jobs_24h": len(recent_jobs),
            "avg_stability": 0.0,
            "avg_gen_time": 0.0,
            "avg_brick_count": 0,
            "error_dist": {},
            "stage_dist": {}
        }

        if recent_jobs:
            stabilities = [j["result"]["stabilityScore"] for j in recent_jobs if j.get("result", {}).get("stabilityScore")]
            gen_times = []
            for j in recent_jobs:
                if j.get("startedAt") and j.get("endedAt"):
                    dur = (j["endedAt"] - j["startedAt"]).total_seconds()
                    if 0 < dur < 600: gen_times.append(dur)
                
                # ì—ëŸ¬ ë° ìŠ¤í…Œì´ì§€ ë¶„í¬
                stage = j.get("stage", "UNKNOWN")
                db_raw["stage_dist"][stage] = db_raw["stage_dist"].get(stage, 0) + 1
                if j.get("status") == "FAILED" and j.get("error"):
                    err = str(j["error"])[:50]
                    db_raw["error_dist"][err] = db_raw["error_dist"].get(err, 0) + 1

            db_raw["avg_stability"] = round(sum(stabilities) / len(stabilities), 2) if stabilities else 0.82
            db_raw["avg_gen_time"] = round(sum(gen_times) / len(gen_times), 1) if gen_times else 45.0
            
        # 3. ë¹„ë™ê¸° ì‘ì—… ëŒ€ê¸° ë° ê²°ê³¼ ë³‘í•©
        full_report, product_intel = await asyncio.gather(full_report_task, product_intel_task)
        
        raw_data = full_report or {}
        raw_metrics = {
            "summary": raw_data.get("summary", {}),
            "daily_users": raw_data.get("dailyUsers", []),
            "top_tags": raw_data.get("topTags", []),
            "heavy_users": raw_data.get("heavyUsers", []),
            "event_stats": raw_data.get("eventStats", {}),
            "product_intelligence": product_intel or {},
            "db_raw": db_raw,
            "today_stats": {
                "gen_success": sum(e.get("count", 0) for e in (raw_data.get("eventStats", {}).get("success_1d") or [])),
                "gen_fail": sum(e.get("count", 0) for e in (raw_data.get("eventStats", {}).get("fail_1d") or [])),
            }
        }

        return {
            "raw_metrics": raw_metrics,
            "temporal_context": {
                "now": datetime.now().isoformat(),
                "weekday": datetime.now().strftime("%A"),
            },
            "next_action": "evaluate"
        }

    except Exception as e:
        log.error(f"â›ï¸ [Miner] ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì¹˜ëª…ì  ì‹¤íŒ¨: {e}", exc_info=True)
        return {
            "raw_metrics": {},
            "temporal_context": {"now": datetime.now().isoformat()},
            "next_action": "evaluate"
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 2: Evaluator â€” ì´ìƒ íƒì§€ (ê·œì¹™ ê¸°ë°˜, LLM ë¯¸ì‚¬ìš©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def evaluator_node(state: AdminAnalystState) -> dict:
    """ì •êµí™”ëœ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì—°ì† ì§€í‘œ ë¶„ì„ ë° ì´ìƒ íƒì§€."""
    log.info("[Evaluator] ê³ í•´ìƒë„ ì§€í‘œ ë¶„ì„ ì‹œì‘...")
    anomalies: List[Dict[str, Any]] = []
    metrics = state.get("raw_metrics") or {}
    db_raw = metrics.get("db_raw") or {}

    # â”€â”€â”€ ğŸ“Š ì„¸ë¶€ ìœ„í—˜ ì ìˆ˜ (Sub-scores, 0.0 ~ 1.0) â”€â”€â”€
    s_dau = 0.0   # DAU ë³€ë™ ìœ„í—˜
    s_fail = 0.0  # ìƒì„± ì‹¤íŒ¨ìœ¨ ìœ„í—˜
    s_stab = 0.0  # ë¸Œë¦­ ì•ˆì •ì„± ìœ„í—˜
    s_lat = 0.0   # ì²˜ë¦¬ ì§€ì—° ìœ„í—˜
    s_conv = 0.0  # ì „í™˜ í’ˆì§ˆ ìœ„í—˜

    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚  CHECK 1: Macro Analytics (DAU, Fail Rate)                  â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    # â”€â”€ 1-A. DAU ë³€ë™ (Z-Score ê¸°ë°˜ ì—°ì† ì ìˆ˜) â”€â”€
    daily = metrics.get("daily_users") or []
    dau_spike = False
    if len(daily) >= 3:
        try:
            counts = [d.get("count", d.get("activeUsers", 0)) for d in daily]
            prev, today = counts[:-1], counts[-1]
            mean = sum(prev) / len(prev) if prev else 0
            std = (sum((x - mean) ** 2 for x in prev) / len(prev)) ** 0.5 if prev else 0

            if std > 0:
                z = (today - mean) / std
                # ê³µì‹: abs(z) / 5.0 (Z-score 5.0ì¼ ë•Œ ìœ„í—˜ë„ 100%)
                s_dau = min(1.0, abs(z) / 5.0)
                
                if abs(z) > 2.0:
                    direction = "DROP" if z < 0 else "SPIKE"
                    if direction == "SPIKE": dau_spike = True
                    anomalies.append({
                        "metric": "daily_active_users",
                        "current": today,
                        "baseline": round(mean, 1),
                        "severity": "HIGH" if abs(z) > 3.5 else "MEDIUM",
                        "z_score": round(z, 2),
                        "direction": direction,
                    })
        except Exception as e:
            log.warning(f"[Evaluator] DAU ë¶„ì„ ì˜¤ë¥˜: {e}")

    # â”€â”€ 1-B.ç”Ÿæˆ ì‹¤íŒ¨ìœ¨ (ì—°ì† ì ìˆ˜) â”€â”€
    today_failures = (metrics.get("today_stats") or {}).get("gen_fail", 0)
    recent_succ = (metrics.get("today_stats") or {}).get("gen_success", 0)
    total = today_failures + recent_succ
    
    if total > 5:
        rate = today_failures / total
        # ê³µì‹: Rate / 0.5 (ì‹¤íŒ¨ìœ¨ 50%ì¼ ë•Œ ìœ„í—˜ë„ 100%)
        s_fail = min(1.0, rate / 0.5)
        
        if rate > 0.15:
            anomalies.append({
                "metric": "generation_fail_rate",
                "current": f"{round(rate * 100, 1)}%",
                "baseline": "10.0%",
                "severity": "HIGH" if rate > 0.35 else "MEDIUM",
                "direction": "SPIKE",
            })

    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚  CHECK 2: Micro DB Quality (Stability, Latency)            â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    # â”€â”€ 2-A. ë¸Œë¦­ ì•ˆì •ì„± (ê¸°ì¤€ì¹˜ 0.85 ëŒ€ë¹„ í•˜ë½í­) â”€â”€
    avg_stability = db_raw.get("avg_stability", 0.0)
    if avg_stability > 0:
        # ê³µì‹: max(0, 1.0 - Avg/0.85) -> 0.85ì´ìƒì´ë©´ 0, 0ì´ë©´ 1.0
        s_stab = max(0.0, 1.0 - (avg_stability / 0.85))
        
        if avg_stability < 0.7:
            anomalies.append({
                "metric": "avg_stability_score",
                "current": avg_stability,
                "baseline": 0.85,
                "severity": "HIGH" if avg_stability < 0.5 else "MEDIUM",
                "direction": "DROP",
                "desc": "ë¬¼ë¦¬ì  ì•ˆì •ì„± ê¸°ì¤€ì¹˜ ë¯¸ë‹¬"
            })

    # â”€â”€ 2-B. ìƒì„± ì†Œìš” ì‹œê°„ (30s~120s ì„ í˜• ìŠ¤ì¼€ì¼ë§) â”€â”€
    avg_gen_time = db_raw.get("avg_gen_time", 0.0)
    if avg_gen_time > 0:
        # ê³µì‹: (Time - 30) / 90 -> 30ì´ˆ ì´í•˜ë©´ 0, 120ì´ˆë©´ 1.0
        s_lat = min(1.0, max(0.0, (avg_gen_time - 30) / 90))
        
        if avg_gen_time > 60:
            anomalies.append({
                "metric": "avg_generation_time",
                "current": f"{avg_gen_time}s",
                "baseline": "30s",
                "severity": "HIGH" if avg_gen_time > 100 else "MEDIUM",
                "direction": "DELAY",
            })

    # â”€â”€ 2-C. ì „í™˜ í’ˆì§ˆ (DAU Spike ì‹œ ì „í™˜ìœ¨ 10% ê¸°ì¤€ í•˜ë½í­) â”€â”€
    if dau_spike:
        total_jobs = db_raw.get("total_jobs_24h", 0)
        daily_count = metrics.get("daily_users", [])[-1].get("activeUsers", 1) if metrics.get("daily_users") else 1
        conversion_rate = total_jobs / max(daily_count, 1)
        
        # ê³µì‹: max(0, 1.0 - ConvRate / 0.1) -> 10% ì´ìƒì´ë©´ 0, 0%ë©´ 1.0
        s_conv = max(0.0, 1.0 - (conversion_rate / 0.1))
        
        if conversion_rate < 0.05:
            anomalies.append({
                "metric": "traffic_quality",
                "current": f"{round(conversion_rate*100, 1)}%",
                "baseline": "10.0%",
                "severity": "MEDIUM",
                "direction": "DROP",
                "desc": "íŠ¸ë˜í”½ ìœ ì… ëŒ€ë¹„ ë‚®ì€ ì‚¬ìš© ì „í™˜ìœ¨"
            })

    # â”€â”€ 3. ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìµœì¢… ìœ„í—˜ ì ìˆ˜ ì‚°ì¶œ â”€â”€
    # ê°€ì¤‘ì¹˜: ì‹¤íŒ¨ìœ¨(0.4), ì•ˆì •ì„±(0.3), DAUë³€ë™(0.1), ì§€ì—°(0.1), ì „í™˜í’ˆì§ˆ(0.1)
    risk = (0.4 * s_fail) + (0.3 * s_stab) + (0.1 * s_dau) + (0.1 * s_lat) + (0.1 * s_conv)
    risk = round(min(1.0, risk), 3)
    
    # 0.5(50%) ì´ìƒì´ë©´ ì‹¬ì¸µ ì§„ë‹¨ ë£¨í‹´ìœ¼ë¡œ ì§„ì…
    next_step = "diagnose" if risk >= 0.5 else "report_green"

    log.info(f"[Evaluator] ë¶„ì„ ì™„ë£Œ: ìœ„í—˜ë„={round(risk*100,1)}% ({next_step})")

    return {
        "anomalies": anomalies,
        "risk_score": risk,
        "next_action": next_step,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 3: Diagnoser â€” ì¸ê³¼ê´€ê³„ ì¶”ë¡  (LLM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def diagnoser_node(state: AdminAnalystState) -> dict:
    """LLMìœ¼ë¡œ ì´ìƒ ì§•í›„ì˜ ê·¼ë³¸ ì›ì¸ì„ ì¶”ë¡ ."""
    log.info("[Diagnoser] ì›ì¸ ì¶”ë¡  ì‹œì‘...")

    anomaly_text = json.dumps(state.get("anomalies", []), ensure_ascii=False, indent=2)
    summary = state.get("raw_metrics", {}).get("summary", {})
    db_raw = state.get("raw_metrics", {}).get("db_raw", {})
    temporal = state.get("temporal_context", {})
    tags = state.get("raw_metrics", {}).get("top_tags", [])

    prompt = DIAGNOSER_PROMPT.format(
        anomaly_text=anomaly_text,
        active_users=summary.get('activeUsers', 'N/A'),
        page_views=summary.get('pageViews', 'N/A'),
        sessions=summary.get('sessions', 'N/A'),
        total_jobs=db_raw.get('total_jobs_24h', 0),
        avg_stability=db_raw.get('avg_stability', 0.0),
        avg_gen_time=db_raw.get('avg_gen_time', 0.0),
        stage_dist=json.dumps(db_raw.get('stage_dist', {}), ensure_ascii=False),
        error_dist=json.dumps(db_raw.get('error_dist', {}), ensure_ascii=False),
        input_type_dist=json.dumps(db_raw.get('input_type_dist', {}), ensure_ascii=False),
        top_tags=json.dumps(tags[:10], ensure_ascii=False),
        date=temporal.get('date'),
        hour=temporal.get('hour'),
        day_of_week=temporal.get('day_of_week')
    )

    diagnosis = await call_llm_json(prompt)

    if not diagnosis:
        diagnosis = {
            "root_cause": "LLM ë¶„ì„ ì‹¤íŒ¨ â€” ìˆ˜ë™ í™•ì¸ í•„ìš”",
            "confidence": 0.3,
            "evidence": [f"{len(state.get('anomalies', []))}ê±´ ì´ìƒ ì§•í›„ ê°ì§€"],
            "affected_segment": "ì „ì²´ ìœ ì €",
        }

    log.info(f"[Diagnoser] ì™„ë£Œ: {diagnosis.get('root_cause', '')[:50]}...")
    return {"diagnosis": diagnosis, "next_action": "strategize"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 4: Strategist â€” ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½ (LLM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def strategist_node(state: AdminAnalystState) -> dict:
    """ì§„ë‹¨ ê¸°ë°˜ êµ¬ì²´ ëŒ€ì‘ ì „ëµ ë„ì¶œ."""
    log.info("[Strategist] ì „ëµ ìˆ˜ë¦½ ì‹œì‘...")

    dx = state.get("diagnosis", {})
    confidence = dx.get("confidence", 0.5)

    prompt = STRATEGIST_PROMPT.format(
        root_cause=dx.get('root_cause', '?'),
        risk_level=dx.get('risk_level', 'UNKNOWN'),
        confidence=confidence * 100,
        evidence=json.dumps(dx.get('evidence', []), ensure_ascii=False)
    )

    actions = await call_llm_json(prompt)

    if isinstance(actions, dict):
        actions = [actions]
    if not isinstance(actions, list):
        actions = [{"action": "ìˆ˜ë™ ëª¨ë‹ˆí„°ë§ ê°•í™”", "target": "ì„œë¹„ìŠ¤ ì „ì²´",
                     "expected_impact": "ì‹¤ì‹œê°„ íŒŒì•…", "risk": "LOW", "priority": 1}]

    iteration = state.get("iteration", 0) + 1

    # í™•ì‹ ë„ ë‚®ìœ¼ë©´ ë£¨í”„ë°±
    if confidence < 0.5 and iteration < state.get("max_iterations", 3):
        log.info(f"[Strategist] í™•ì‹ ë„ {confidence} < 0.5 â†’ ì‹¬ì¸µ ì¡°ì‚¬ (iter={iteration})")
        return {"proposed_actions": actions, "iteration": iteration, "next_action": "deep_investigate"}

    return {"proposed_actions": actions, "iteration": iteration, "next_action": "finalize"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 8: Content Miner â€” ê²€ì—´ ëŒ€ìƒ ìˆ˜ì§‘
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def content_miner_node(state: AdminAnalystState) -> dict:
    """ë°±ì—”ë“œì—ì„œ ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ìµœê·¼ ëŒ“ê¸€/ê²Œì‹œê¸€ ìˆ˜ì§‘."""
    from service import backend_client
    log.info("[ContentMiner] ê²€ì—´ ëŒ€ìƒ ìˆ˜ì§‘ ì‹œì‘...")

    # ìµœê·¼ 1ì¼ ë‚´ì˜ ë¯¸ê²€ì—´ ì½˜í…ì¸  ìµœëŒ€ 10ê°œ ìˆ˜ì§‘ (ì†ë„ ìµœì í™”)
    contents = await backend_client.get_recent_contents(days=1, limit=10)

    log.info(f"[ContentMiner] ìˆ˜ì§‘ ì™„ë£Œ: {len(contents or [])}ê±´")
    return {
        "moderation_queue": contents or [],
        "next_action": "guard"
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 9: Guardian â€” ì„ ì •ì„±/í­ë ¥ì„± íŒë‹¨ (LLM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def guardian_node(state: AdminAnalystState) -> dict:
    """LLMì„ ë¸”ë™ë°•ìŠ¤ ê²€ì—´ê´€ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë¶€ì ì ˆì„± íŒë‹¨."""
    log.info("[Guardian] ì½˜í…ì¸  ê²€ì—´ ì‹œì‘...")

    queue = state.get("moderation_queue", [])
    if not queue:
        return {"next_action": "execute_moderation"}

    queue_text = json.dumps(queue, ensure_ascii=False, indent=2)

    prompt = GUARDIAN_PROMPT.format(queue_text=queue_text)

    judgments = await call_llm_json(prompt)
    if not isinstance(judgments, list):
        judgments = []

    log.info(f"[Guardian] ê²€ì—´ ì™„ë£Œ: {len(judgments)}ê±´ íŒì •")
    return {
        "moderation_results": judgments,
        "next_action": "execute_moderation"
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 10: Moderator Executor â€” ìë™ ì¡°ì¹˜ ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def moderator_executor_node(state: AdminAnalystState) -> dict:
    """Guardianì˜ íŒë‹¨ì— ë”°ë¼ ë°±ì—”ë“œì— ìë™ ìˆ¨ê¹€ ì²˜ë¦¬ ìš”ì²­."""
    from service import backend_client
    log.info("[ModeratorExecutor] ìë™ ì¡°ì¹˜ ì‹¤í–‰ ì‹œì‘...")

    results = state.get("moderation_results", [])
    executed_count = 0

    for res in results:
        if res.get("is_violating") and res.get("confidence", 0) >= 0.8:
            target_id = res.get("target_id")
            target_type = res.get("type")
            reason = res.get("reason", "AI Automated Moderation")

            success = await backend_client.hide_content(target_type, target_id, reason)
            if success:
                executed_count += 1
                res["action_taken"] = "HIDDEN"
                log.info(f"[ModeratorExecutor] ì¡°ì¹˜ ì™„ë£Œ: {target_type} {target_id}")
            else:
                res["action_taken"] = "FAILED"

    log.info(f"[ModeratorExecutor] ì´ {executed_count}ê±´ ìë™ ì¡°ì¹˜ ì™„ë£Œ")
    return {
        "moderation_results": results,
        "next_action": "finalize"
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 5: Deep Investigator â€” ì‹¬ì¸µ ì¡°ì‚¬ (ë£¨í”„ë°±)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def deep_investigator_node(state: AdminAnalystState) -> dict:
    """30ì¼ ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘ í›„ Diagnoserë¡œ ë£¨í”„ë°±."""
    from service import backend_client

    log.info("[DeepInvestigator] 30ì¼ ì¥ê¸° ë°ì´í„° ìˆ˜ì§‘...")

    long_daily = await backend_client.get_daily_users(30)
    long_tags = await backend_client.get_top_tags(30, limit=20)

    metrics = dict(state.get("raw_metrics", {}))
    metrics["daily_users_30d"] = long_daily or []
    metrics["top_tags_30d"] = long_tags or []

    return {"raw_metrics": metrics, "next_action": "diagnose"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 6: Reporter Green â€” ì •ìƒ ë³´ê³ ì„œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def reporter_green_node(state: AdminAnalystState) -> dict:
    """ì´ìƒ ì§•í›„ê°€ ì—†ì„ ë•Œë„ LLMìœ¼ë¡œ ì‹¬ì¸µ ìš´ì˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±."""
    log.info("[Reporter] ì •ìƒ ìƒíƒœ ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘...")

    metrics = state.get("raw_metrics", {})
    summary = metrics.get("summary", {})
    daily = metrics.get("daily_users", [])
    tags = metrics.get("top_tags", [])
    temporal = state.get("temporal_context", {})

    # íŠ¸ë Œë“œ ìš”ì•½ (LLM ì°¸ê³ ìš©)
    trend_desc = "ë³´í•©ì„¸"
    if daily and len(daily) >= 3:
        try:
            counts = [d.get("count", d.get("activeUsers", 0)) for d in daily]
            recent_avg = sum(counts[-3:]) / 3
            prev_avg = sum(counts[-6:-3]) / 3 if len(counts) >= 6 else counts[0]
            chg = ((recent_avg - prev_avg) / max(prev_avg, 1)) * 100
            trend_desc = f"ìµœê·¼ 3ì¼ í‰ê· ì´ ì´ì „ ëŒ€ë¹„ {chg:+.1f}% {'ìƒìŠ¹' if chg > 0 else 'í•˜ë½'} ì¤‘"
        except: pass

    intel = metrics.get("product_intelligence") or {}
    
    prompt = REPORTER_GREEN_PROMPT.format(
        active_users=summary.get("activeUsers", 0),
        page_views=summary.get("screenPageViews", 0),
        sessions=summary.get("sessions", 0),
        trend_desc=trend_desc,
        funnel=json.dumps(intel.get("funnel", []), ensure_ascii=False),
        exits=json.dumps(intel.get("exits", []), ensure_ascii=False),
        quality=json.dumps(intel.get("quality", {}), ensure_ascii=False),
    )

    res = await call_llm_json(prompt)
    report = res.get("report") if res else None

    if not report:
        report = f"## âœ… ì„œë¹„ìŠ¤ ì•ˆì • ìš´ì˜ ì¤‘\n\nëª¨ë“  í•µì‹¬ ì§€í‘œê°€ ì •ìƒ ë²”ìœ„ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìœ ì € ìœ ì… ë° ì „í™˜ íŠ¸ë Œë“œê°€ ì•ˆì •ì ì…ë‹ˆë‹¤. ({trend_desc})"

    return {"final_report": report, "next_action": "end"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 7: Finalizer â€” ì´ìƒ ë°œê²¬ ì‹œ ì¢…í•© ë³´ê³ ì„œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def finalizer_node(state: AdminAnalystState) -> dict:
    """ì´ìƒ ì§•í›„ ë°œê²¬ ì‹œ LLMìœ¼ë¡œ ìœ ê¸°ì ì¸ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±."""
    log.info("[Finalizer] ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì‹œì‘...")

    dx = state.get("diagnosis") or {}
    actions = state.get("proposed_actions") or []
    anomalies = state.get("anomalies") or []
    mod_results = state.get("moderation_results") or []
    temporal = state.get("temporal_context") or {}

    # ìë™ ì¡°ì¹˜ ë‚´ì—­ ìš”ì•½
    hidden_count = sum(1 for r in mod_results if r.get("action_taken") == "HIDDEN")
    mod_text = ""
    if mod_results:
        mod_text = "\n### ğŸ›¡ï¸ ììœ¨ ì½˜í…ì¸  ê²€ì—´ ë° ì¡°ì¹˜ ë‚´ì—­\n"
        if hidden_count > 0:
            mod_text += f"- **ìë™ ìˆ¨ê¹€ ì²˜ë¦¬**: {hidden_count}ê±´ (AI í™•ì‹ ë„ 80% ì´ìƒ)\n"
        else:
            mod_text += "- íŠ¹ì´ì‚¬í•­: ìœ„ë°˜ ì˜ì‹¬ ì½˜í…ì¸  ì—†ìŒ (í´ë¦° ìƒíƒœ ìœ ì§€ ì¤‘)\n"

        for r in [r for r in mod_results if r.get("is_violating")][:5]:
             mod_text += f"  - [{r.get('violation_type')}] {r.get('target_id')}: {r.get('reason')} ({r.get('action_taken', 'PENDING')})\n"

    prompt = FINALIZER_PROMPT.format(
        anomalies=json.dumps(anomalies, ensure_ascii=False, indent=2),
        mod_text=mod_text,
        root_cause=dx.get('root_cause', '?'),
        forecast=dx.get('forecast', 'ë°ì´í„° ìˆ˜ì§‘ ì¤‘...'),
        confidence=dx.get('confidence', 0) * 100,
        evidence=json.dumps(dx.get('evidence', []), ensure_ascii=False),
        affected_segment=dx.get('affected_segment', 'ì „ì²´'),
        actions=json.dumps(actions, ensure_ascii=False, indent=2)
    )

    res = await call_llm_json(prompt)
    report = res.get("report") if res else None

    if not report:
        # Fallback í…œí”Œë¦¿
        report = f"## ğŸš¨ ê´€ë¦¬ì ì£¼ì˜: ì´ìƒ ì§•í›„ ê°ì§€\n\n- ì›ì¸: {dx.get('root_cause', '?')}\n- ì¡°ì¹˜: {len(actions)}ê±´ì˜ ì „ëµ ìˆ˜ë¦½ë¨."

    return {"final_report": report, "next_action": "end"}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 11: Query Analyst â€” ì¸í„°ë™í‹°ë¸Œ ì§ˆì˜ì‘ë‹µ (NEW)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def query_analyst_node(state: AdminAnalystState) -> dict:
    """ì „ëµì  AI ì–´ë“œë°”ì´ì €: ëŒ€í™” ì´ë ¥ê³¼ 100ì—¬ ì§€í‘œë¥¼ ì¢…í•©í•˜ì—¬ ì…ì²´ì  ì „ëµ ìˆ˜ë¦½."""
    log.info("[QueryAnalyst] ëŒ€í™” ë§¥ë½ í¬í•¨ ì „ëµ ë¶„ì„ ì‹œì‘...")

    user_query = state.get("user_query", "í˜„ì¬ ì„œë¹„ìŠ¤ ìš´ì˜ ìƒíƒœ ì¢…í•© ì§„ë‹¨")
    history = state.get("history", []) # [NEW] ëŒ€í™” ì´ë ¥
    metrics = state.get("raw_metrics", {})
    summary = metrics.get("summary", {})
    daily = metrics.get("daily_users", [])
    tags = metrics.get("top_tags", [])
    today = metrics.get("today_stats", {})
    db_raw = metrics.get("db_raw", {})
    top_posts = metrics.get("top_posts", [])
    temporal = state.get("temporal_context", {})

    # ì´ì „ ëŒ€í™” ë§¥ë½ ìš”ì•½
    history_context = ""
    if history:
        history_context = "\n[ì´ì „ ëŒ€í™” ë§¥ë½]\n" + "\n".join([f"{h['role']}: {h['content']}" for h in history[-3:]])

    prompt = QUERY_ANALYST_PROMPT.format(
        history_context=history_context,
        user_query=user_query,
        summary=json.dumps(summary, ensure_ascii=False),
        today_gen_success=today.get('gen_success'),
        today_gen_fail=today.get('gen_fail'),
        today_gallery=today.get('gallery_uploads'),
        total_jobs=db_raw.get('total_jobs_24h'),
        stage_dist=json.dumps(db_raw.get('stage_dist', {}), ensure_ascii=False),
        daily=json.dumps(daily, ensure_ascii=False),
        tags=json.dumps(tags[:10], ensure_ascii=False),
        top_posts=json.dumps(top_posts, ensure_ascii=False),
        product_intel=json.dumps(metrics.get("product_intelligence", {}), ensure_ascii=False),
        temporal=json.dumps(temporal, ensure_ascii=False)
    )

    res = await call_llm_json(prompt)
    report = res.get("report") if isinstance(res, dict) else str(res)
    
    if not report or report == "None":
        from .llm_utils import call_llm_text
        report = await call_llm_text(prompt)

    # ì´ë ¥ ì—…ë°ì´íŠ¸ëŠ” í˜¸ì¶œë¶€ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ì œì•ˆ (í˜„ì¬ ë…¸ë“œì—ì„œëŠ” ê²°ê³¼ë§Œ ë°˜í™˜)
    return {"final_report": report, "next_action": "end"}
