"""
Admin AI Analyst â€” Node êµ¬í˜„
7ê°œ ë…¸ë“œ: Miner â†’ Evaluator â†’ Diagnoser â†’ Strategist â†’ DeepInvestigator â†’ ReporterGreen â†’ Finalizer
"""
from __future__ import annotations

import json
import logging
from datetime import datetime
from typing import List, Dict, Any

from .state import AdminAnalystState
from .llm_utils import call_llm_json

log = logging.getLogger("admin_analyst.nodes")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 1: Miner â€” ë°ì´í„° ìˆ˜ì§‘
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def miner_node(state: AdminAnalystState) -> dict:
    """GA4 Data API + Direct MongoDBì—ì„œ ì›í•© ì§€í‘œ ë° ë¡œìš° ë°ì´í„° ìˆ˜ì§‘."""
    from service import backend_client
    from db import get_db
    import config

    log.info("[Miner] í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (Analytics + DB)...")

    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚  PART 1: Macro Analytics (GA4 & Backend Stats)              â”‚
    # â”‚  - ì „ì²´ ì„œë¹„ìŠ¤ì˜ ê±°ì‹œì  íë¦„(íŠ¸ë˜í”½, ìœ ì…) íŒŒì•…                 â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    summary = await backend_client.get_analytics_summary(7)
    daily = await backend_client.get_daily_users(14)
    tags = await backend_client.get_top_tags(7, limit=15)
    users = await backend_client.get_heavy_users(7, limit=10)
    top_posts = await backend_client.get_top_posts(7, limit=5)
    
    # [ë³µêµ¬] Evaluator ë…¸ë“œë¥¼ ìœ„í•œ ê³¼ê±° 7ì¼ê°„ì˜ ì´ë²¤íŠ¸ ë°ì´í„°
    fail_7d = await backend_client.get_event_stats("generate_fail", 7)
    success_7d = await backend_client.get_event_stats("generate_success", 7)

    # [ìˆ˜ì§‘] ì˜¤ëŠ˜ í•˜ë£¨ ìƒì„¸ í†µê³„ (API ê¸°ë°˜)
    today_gen_success = await backend_client.get_event_stats("generate_success", 1)
    today_gen_fail = await backend_client.get_event_stats("generate_fail", 1)
    today_gallery = await backend_client.get_event_stats("gallery_register_attempt", 1)

    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚  PART 2: Micro Logs (Direct MongoDB Access)                 â”‚
    # â”‚  - ê°œë³„ ì‘ì—…ì˜ êµ¬ì²´ì  ìƒíƒœ, í’ˆì§ˆ, ì—ëŸ¬ ë“± ë¯¸ì‹œì  ë°ì´í„° íŒŒì•…      â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    db_raw = {}
    try:
        db = get_db()
        # ìµœê·¼ 24ì‹œê°„ ë‚´ ìƒì„±ëœ ì‘ì—…ë“¤ì˜ ì›ë³¸ ìƒíƒœ ìš”ì•½
        one_day_ago = datetime.now().timestamp() - 86400
        jobs_col = db["kids_jobs"]
        
        # ì„±ê³µí–ˆê±°ë‚˜ ì‹¤íŒ¨í•œ ì‘ì—… ëª¨ë‘ í¬í•¨í•˜ì—¬ ë¶„ì„ (ìµœëŒ€ 200ê±´ ìƒ˜í”Œë§)
        recent_jobs = list(jobs_col.find({
            "createdAt": {"$gte": datetime.fromtimestamp(one_day_ago)}
        }).limit(200))
        
        db_raw["total_jobs_24h"] = len(recent_jobs)
        db_raw["stage_dist"] = {}
        
        # [NEW] ë¯¸ì‹œì  í’ˆì§ˆ ì§€í‘œ ê³„ì‚° (Custom Definitions ëŒ€ì²´/ë³´ì™„)
        stability_scores = []
        gen_times = []
        brick_counts = []
        error_dist = {}
        input_type_dist = {}
        
        for j in recent_jobs:
            st = j.get("stage", "UNKNOWN")
            db_raw["stage_dist"][st] = db_raw["stage_dist"].get(st, 0) + 1
            
            # ì•ˆì •ì„± ì ìˆ˜ (result.stabilityScore)
            if j.get("result") and "stabilityScore" in j["result"]:
                stability_scores.append(j["result"]["stabilityScore"])
                
            # ìƒì„± ì†Œìš” ì‹œê°„ (endedAt - startedAt)
            if j.get("startedAt") and j.get("endedAt"):
                try:
                    dur = (j["endedAt"] - j["startedAt"]).total_seconds()
                    if 0 < dur < 600: # 10ë¶„ ì´ìƒì€ ì´ìƒì¹˜ ì œì™¸
                        gen_times.append(dur)
                except: pass
                
            # ë¸Œë¦­ ê°œìˆ˜ (result.brickCount)
            if j.get("result") and "brickCount" in j["result"]:
                brick_counts.append(j["result"]["brickCount"])
            
            # ì—ëŸ¬ ìœ í˜• ë¶„í¬ (ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ìš©)
            if j.get("error"):
                # ì—ëŸ¬ ë©”ì‹œì§€ë‚˜ ì½”ë“œë¥¼ ë‹¨ìˆœí™”í•´ì„œ ì¹´ìš´íŒ…
                err_msg = str(j["error"])[:50] 
                error_dist[err_msg] = error_dist.get(err_msg, 0) + 1
            
            # ì…ë ¥ ë°©ì‹ ì„ í˜¸ë„ (Text Prompt vs Image Upload)
            inp = j.get("inputType", "unknown")
            input_type_dist[inp] = input_type_dist.get(inp, 0) + 1

        # í‰ê· ê°’ ë° ë¶„í¬ ì‚°ì¶œ
        db_raw["avg_stability"] = round(sum(stability_scores) / len(stability_scores), 2) if stability_scores else 0.0
        db_raw["avg_gen_time"] = round(sum(gen_times) / len(gen_times), 1) if gen_times else 0.0
        db_raw["avg_brick_count"] = int(sum(brick_counts) / len(brick_counts)) if brick_counts else 0
        db_raw["error_dist"] = error_dist
        db_raw["input_type_dist"] = input_type_dist
            
        log.info(f"[Miner] DB ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: Jobs={len(recent_jobs)} (AvgStability={db_raw['avg_stability']})")
    except Exception as e:
        log.warning(f"[Miner] DB ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")

    now = datetime.now()
    temporal = {
        "day_of_week": now.strftime("%a"),
        "is_weekend": now.weekday() >= 5,
        "hour": now.hour,
        "is_peak": 19 <= now.hour <= 23,
        "date": now.strftime("%Y-%m-%d"),
    }

    log.info(f"[Miner] ìˆ˜ì§‘ ì™„ë£Œ: summary={bool(summary)}, db_raw={bool(db_raw)}, today_gen={bool(today_gen_success)}")

    return {
        "raw_metrics": {
            "summary": summary or {},
            "daily_users": daily or [],
            "top_tags": tags or [],
            "heavy_users": users or [],
            "fail_events": fail_7d or [],       # [ë³µêµ¬] Evaluatorìš©
            "success_events": success_7d or [], # [ë³µêµ¬] Evaluatorìš©
            "db_raw": db_raw,
            "today_stats": {
                "gen_success": sum(e.get("count", 0) for e in (today_gen_success or [])),
                "gen_fail": sum(e.get("count", 0) for e in (today_gen_fail or [])),
                "gallery_uploads": sum(e.get("count", 0) for e in (today_gallery or [])),
            },
            "top_posts": top_posts or [],
        },
        "temporal_context": temporal,
        "moderation_queue": [],
        "moderation_results": [],
        "next_action": "evaluate",
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 2: Evaluator â€” ì´ìƒ íƒì§€ (ê·œì¹™ ê¸°ë°˜, LLM ë¯¸ì‚¬ìš©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def evaluator_node(state: AdminAnalystState) -> dict:
    """Z-Score ë° DB í’ˆì§ˆ ì§€í‘œ ê¸°ë°˜ ì´ìƒ íƒì§€."""
    log.info("[Evaluator] ì´ìƒ íƒì§€ ì‹œì‘...")
    anomalies: List[Dict[str, Any]] = []
    metrics = state.get("raw_metrics", {})
    db_raw = metrics.get("db_raw", {})

    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚  CHECK 1: Macro Analytics Anomalies (DAU, Fail Rare)        â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    # â”€â”€ 1-A. DAU ê¸‰ë³€ ê°ì§€ â”€â”€
    daily = metrics.get("daily_users") or []
    dau_spike = False # ë§ˆì¼€íŒ… ê°ì§€ìš© í”Œë˜ê·¸
    if len(daily) >= 3:
        try:
            counts = [d.get("count", d.get("activeUsers", 0)) for d in daily]
            prev, today = counts[:-1], counts[-1]
            mean = sum(prev) / len(prev) if prev else 0
            std = (sum((x - mean) ** 2 for x in prev) / len(prev)) ** 0.5 if prev else 0

            if std > 0:
                z = (today - mean) / std
                if abs(z) > 2.0:
                    severity = "HIGH" if abs(z) > 3.5 else "MEDIUM"
                    direction = "DROP" if z < 0 else "SPIKE"
                    if direction == "SPIKE":
                        dau_spike = True
                        
                    anomalies.append({
                        "metric": "daily_active_users",
                        "current": today,
                        "baseline": round(mean, 1),
                        "severity": severity,
                        "z_score": round(z, 2),
                        "direction": direction,
                    })
        except Exception as e:
            log.warning(f"[Evaluator] DAU ë¶„ì„ ì˜¤ë¥˜: {e}")

    # â”€â”€ 1-B. ìƒì„± ì‹¤íŒ¨ìœ¨ ê¸‰ì¦ â”€â”€
    fail_ev = metrics.get("fail_events") or []
    succ_ev = metrics.get("success_events") or []
    today_failures = metrics.get("today_stats", {}).get("gen_fail", 0)
    
    if fail_ev and succ_ev:
        try:
            fc = [e.get("count", 0) for e in fail_ev]
            # ì˜¤ëŠ˜ ë°ì´í„°ê°€ API ê°±ì‹  ì „ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì‹¤ì‹œê°„ today_stats ìš°ì„  ê³ ë ¤
            if today_failures > 0:
                recent_fail = today_failures
            else:
                recent_fail = sum(fc[-1:]) if fc else 0
            
            recent_succ = metrics.get("today_stats", {}).get("gen_success", 0)
            total = recent_fail + recent_succ

            if total > 5:
                rate = recent_fail / total
                prev_rate_avg = 0.1 # ê¸°ë³¸ê°’
                
                if rate > 0.2: # 20% ì´ìƒ ì‹¤íŒ¨ ì‹œ ì²´í¬
                    anomalies.append({
                        "metric": "generation_fail_rate",
                        "current": round(rate * 100, 1),
                        "baseline": "10.0",
                        "severity": "HIGH" if rate > 0.4 else "MEDIUM",
                        "z_score": round(rate / 0.1, 2),
                        "direction": "SPIKE",
                    })
        except Exception as e:
            log.warning(f"[Evaluator] ì‹¤íŒ¨ìœ¨ ë¶„ì„ ì˜¤ë¥˜: {e}")

    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚  CHECK 2: Micro DB Anomalies (Quality, Latency, Marketing)  â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    # â”€â”€ 2-A. [NEW] í‰ê·  ì•ˆì •ì„± ì ìˆ˜ í•˜ë½ (0.7 ë¯¸ë§Œì´ë©´ ì£¼ì˜) â”€â”€
    avg_stability = db_raw.get("avg_stability", 0.0)
    if avg_stability > 0 and avg_stability < 0.7:
        anomalies.append({
            "metric": "avg_stability_score",
            "current": avg_stability,
            "baseline": 0.85,
            "severity": "HIGH" if avg_stability < 0.5 else "MEDIUM",
            "direction": "DROP",
            "desc": "ìƒì„±ëœ ë¸Œë¦­ì˜ ë¬¼ë¦¬ì  ì•ˆì •ì„±ì´ í¬ê²Œ ë–¨ì–´ì§"
        })

    # â”€â”€ 2-B. [NEW] ìƒì„± ì‹œê°„ ì§€ì—° (í‰ê·  60ì´ˆ ì´ˆê³¼ ì‹œ ì£¼ì˜) â”€â”€
    avg_gen_time = db_raw.get("avg_gen_time", 0.0)
    if avg_gen_time > 60:
        anomalies.append({
            "metric": "avg_generation_time",
            "current": f"{avg_gen_time}s",
            "baseline": "30s",
            "severity": "HIGH" if avg_gen_time > 120 else "MEDIUM",
            "direction": "DELAY",
            "desc": "AI ì—”ì§„ ì²˜ë¦¬ ì†ë„ ì €í•˜ ê°ì§€"
        })

    # â”€â”€ 2-C. [NEW] ë§ˆì¼€íŒ… íš¨ìœ¨/íŠ¸ë˜í”½ í’ˆì§ˆ ê°ì§€ â”€â”€
    # DAUëŠ” ê¸‰ì¦í–ˆëŠ”ë°(SPIKE), ìƒì„± ì‹œë„ëŠ” ëŠ˜ì§€ ì•Šì•˜ë‹¤ë©´ í—ˆìˆ˜ ìœ ì… ê°€ëŠ¥ì„±
    if dau_spike:
        total_gens = db_raw.get("total_jobs_24h", 0)
        # í‰ì†Œ 100ëª…ë‹¹ 10ê°œ ìƒì„±í•œë‹¤ê³  ê°€ì • (10%)
        # íŠ¸ë˜í”½ ëŒ€ë¹„ ìƒì„± ë¹„ìœ¨ì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë§ˆì¼€íŒ… íš¨ìœ¨ ì €í•˜ë¡œ ì˜ì‹¬
        daily_count = metrics.get("daily_users", [])[-1].get("activeUsers", 1) if metrics.get("daily_users") else 1
        conversion_rate = total_gens / max(daily_count, 1)
        
        if conversion_rate < 0.05: # 5% ë¯¸ë§Œì´ë©´ ì²´ë¦¬í”¼ì»¤ ìœ ì… ì˜ì‹¬
            anomalies.append({
                "metric": "traffic_quality_drop",
                "current": f"{round(conversion_rate*100, 1)}%",
                "baseline": "10.0%",
                "severity": "MEDIUM",
                "direction": "DROP",
                "desc": "íŠ¸ë˜í”½ ê¸‰ì¦ ëŒ€ë¹„ ì‹¤ì œ ì‚¬ìš© ì „í™˜ìœ¨ ì €ì¡° (ì €í’ˆì§ˆ ìœ ì…/ë§ˆì¼€íŒ… íš¨ìœ¨ ì˜ì‹¬)"
            })


    # â”€â”€ 3. ì¢…í•© ìœ„í—˜ ì ìˆ˜ (Threshold Tuned) â”€â”€
    # HIGH = 0.5 (í•˜ë‚˜ë§Œ ìˆì–´ë„ ì¦‰ì‹œ ë¦¬í¬íŠ¸ ì „í™˜)
    # MEDIUM = 0.2 (ìµœì†Œ 3ê°œëŠ” ëª¨ì—¬ì•¼ ë¦¬í¬íŠ¸ ì „í™˜)
    # Threshold = 0.5
    risk = sum(0.5 if a["severity"] == "HIGH" else 0.2 for a in anomalies)
    risk = min(1.0, risk)
    
    next_step = "diagnose" if risk >= 0.5 else "report_green"

    log.info(f"[Evaluator] ì™„ë£Œ: {len(anomalies)}ê±´ ì´ìƒ, risk={risk} â†’ {next_step}")

    return {
        "anomalies": anomalies,
        "risk_score": risk,
        "next_action": next_step,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 3: Diagnoser â€” ì¸ê³¼ê´€ê³„ ì¶”ë¡  (LLM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def diagnoser_node(state: AdminAnalystState) -> dict:
    """LLMìœ¼ë¡œ ì´ìƒ ì§•í›„ì˜ ê·¼ë³¸ ì›ì¸ì„ ì¶”ë¡ ."""
    log.info("[Diagnoser] ì›ì¸ ì¶”ë¡  ì‹œì‘...")

    anomaly_text = json.dumps(state.get("anomalies", []), ensure_ascii=False, indent=2)
    summary = state.get("raw_metrics", {}).get("summary", {})
    db_raw = state.get("raw_metrics", {}).get("db_raw", {})
    temporal = state.get("temporal_context", {})
    tags = state.get("raw_metrics", {}).get("top_tags", [])

    prompt = f"""ë‹¹ì‹ ì€ ë¸Œë¦­ì»¤ìŠ¤(Brickers) ì„œë¹„ìŠ¤ì˜ ìˆ˜ì„ SRE(Service Reliability Engineer)ì´ì ìµœê³  ìˆ˜ì¤€ì˜ ë°ì´í„°ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
í˜„ì¬ ê°ì§€ëœ ì´ìƒ ì§•í›„ì— ëŒ€í•´ ê±°ì‹œì  ì§€í‘œ(Analytics)ì™€ ë¯¸ì‹œì  ë¡œê·¸(Database)ë¥¼ ê²°í•©í•˜ì—¬ ì‹¬ì¸µì ì¸ 'ì¸ê³¼ê´€ê³„ ë¶„ì„(Root Cause Analysis)'ì„ ìˆ˜í–‰í•˜ì„¸ìš”.

[í˜„ìƒ: ê°ì§€ëœ ì´ìƒ ì§•í›„]
{anomaly_text}

[ì„œë¹„ìŠ¤ ì‹¤ì‹œê°„ ì§€í‘œ ìš”ì•½ (ê±°ì‹œ)]
- í™œì„± ìœ ì €(DAU): {summary.get('activeUsers', 'N/A')}
- í˜ì´ì§€ë·°: {summary.get('pageViews', 'N/A')}
- ì„¸ì…˜ ìˆ˜: {summary.get('sessions', 'N/A')}

[ë¯¸ì‹œ ë°ì´í„°: DB ì‹¤ì‹œê°„ ì‘ì—… ë¡œê·¸ (ìµœê·¼ 24ì‹œê°„)]
- ì´ ìƒì„± ì‘ì—… ìˆ˜: {db_raw.get('total_jobs_24h', 0)}ê±´
- í‰ê·  í’ˆì§ˆ ì§€í‘œ: ì•ˆì •ì„± {db_raw.get('avg_stability', 0.0)}, ìƒì„±ì‹œê°„ {db_raw.get('avg_gen_time', 0.0)}ì´ˆ
- ì‘ì—… ë‹¨ê³„ ë¶„í¬: {json.dumps(db_raw.get('stage_dist', {}), ensure_ascii=False)}
- ì—ëŸ¬ ìœ í˜• ë¶„í¬: {json.dumps(db_raw.get('error_dist', {}), ensure_ascii=False)}
- ì…ë ¥ ë°©ì‹ ì„ í˜¸: {json.dumps(db_raw.get('input_type_dist', {}), ensure_ascii=False)}

[ì¸ê¸° íƒœê·¸ ë° ì‹œê°„ì  ë§¥ë½]
- ì¸ê¸° íƒœê·¸: {json.dumps(tags[:10], ensure_ascii=False)}
- ì‹œê°: {temporal.get('date')} {temporal.get('hour')}ì‹œ ({temporal.get('day_of_week')})

[ë¶„ì„ ë° ì˜ˆì¸¡ ê°€ì´ë“œë¼ì¸]
1. ì¸ê³¼ê´€ê³„ ê²€ì¦ (Causal Proof): ê±°ì‹œì  ì§€í‘œì˜ í•˜ë½ì´ DB ë¡œê·¸ìƒ íŠ¹ì • 'Stage'ì˜ ì‹¤íŒ¨ë‚˜ íŠ¹ì • 'Error Type'ê³¼ ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€ ì…ì¦í•˜ì„¸ìš”. (ì˜ˆ: ì´ë¯¸ì§€ ì—…ë¡œë“œ ë°©ì‹ì—ì„œ íƒ€ì„ì•„ì›ƒ ì—ëŸ¬ ê¸‰ì¦)
2. ì „ë¬¸ê°€ì  íœ´ë¦¬ìŠ¤í‹± ì¶”ë¡ : ë°ì´í„°ê°€ ë¶€ì¡±í•œ êµ¬ê°„ì€ í’ë¶€í•œ ìš´ì˜ ê²½í—˜ì„ í† ëŒ€ë¡œ 'ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ì‹œë‚˜ë¦¬ì˜¤'ë¥¼ ì¶”ë¡ í•˜ë˜ í™•ì‹ ë„ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
3. ë°ì´í„° ê¸°ë°˜ ì˜ˆì¸¡: í˜„ì¬ ìˆ˜ì¹˜ì˜ 'ê°€ì†ë„(ë³€í™”ìœ¨)'ë¥¼ ê³ ë ¤í•˜ì—¬, ì¡°ì¹˜ ë¯¸ë¹„ ì‹œ í–¥í›„ 1~24ì‹œê°„ ë‚´ ë°œìƒí•  ì„ê³„ì  ëŒíŒŒ ê°€ëŠ¥ì„±ì„ ìˆ˜ì¹˜ë¡œ ì œì‹œí•˜ì„¸ìš”.
4. ì˜í–¥ ë²”ìœ„ êµ¬ì²´í™”: íŠ¹ì • íƒœê·¸ ì„ í˜¸ ìœ ì €êµ°ì— êµ­í•œëœ ë¬¸ì œì¸ì§€ ì•„ë‹ˆë©´ ì „ì²´ ì¸í”„ë¼ ê²°í•¨ì¸ì§€ íŒë³„í•˜ì„¸ìš”.

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ìµœì¢… ê²°ë¡ ì„ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "root_cause": "êµ¬ì²´ì ì¸ ê·¼ë³¸ ì›ì¸ (ë°ì´í„° ê°„ì˜ ìƒê´€ê´€ê³„ì™€ ë…¼ë¦¬ì  ì¶”ë¡  ê³¼ì •ì„ ì„¸ì„¸í•˜ê²Œ ë‚˜ì—´. í•œêµ­ì–´)",
    "confidence": 0.0~1.0 (ë¶„ì„ ë° ì˜ˆì¸¡ì˜ í™•ì‹ ë„),
    "evidence": ["ì¦ê±°1 (DB ìˆ˜ì¹˜ ë° ì—ëŸ¬ ë¡œê·¸ ê¸°ë°˜)", "ì¦ê±°2 (ì• ë„ë¦¬í‹±ìŠ¤ íŠ¸ë Œë“œ ê¸°ë°˜)"],
    "affected_segment": "ë¬¸ì œê°€ ì§‘ì¤‘ëœ ìœ ì €êµ° ë˜ëŠ” ê¸°ëŠ¥ ì˜ì—­",
    "risk_level": "LOW|MEDIUM|HIGH|CRITICAL",
    "forecast": "ì „ë§ ë° ì¡°ì¹˜ ë¯¸ë¹„ ì‹œ ì˜ˆìƒë˜ëŠ” ì‹¤ì§ˆì  íƒ€ê²©ê³¼ ì„ê³„ ìˆ˜ì¹˜"
}}"""

    diagnosis = await call_llm_json(prompt)

    if not diagnosis:
        diagnosis = {
            "root_cause": "LLM ë¶„ì„ ì‹¤íŒ¨ â€” ìˆ˜ë™ í™•ì¸ í•„ìš”",
            "confidence": 0.3,
            "evidence": [f"{len(state.get('anomalies', []))}ê±´ ì´ìƒ ì§•í›„ ê°ì§€"],
            "affected_segment": "ì „ì²´ ìœ ì €",
        }

    log.info(f"[Diagnoser] ì™„ë£Œ: {diagnosis.get('root_cause', '')[:50]}...")
    return {"diagnosis": diagnosis, "next_action": "strategize"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 4: Strategist â€” ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½ (LLM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def strategist_node(state: AdminAnalystState) -> dict:
    """ì§„ë‹¨ ê¸°ë°˜ êµ¬ì²´ ëŒ€ì‘ ì „ëµ ë„ì¶œ."""
    log.info("[Strategist] ì „ëµ ìˆ˜ë¦½ ì‹œì‘...")

    dx = state.get("diagnosis", {})
    confidence = dx.get("confidence", 0.5)

    prompt = f"""ë‹¹ì‹ ì€ ë¸Œë¦­ì»¤ìŠ¤ ì„œë¹„ìŠ¤ì˜ ì œí’ˆ ìš´ì˜ ì „ëµê°€(Product Operations Strategist)ì…ë‹ˆë‹¤.
ì§„ë‹¨ëœ ì›ì¸ì„ ë°”íƒ•ìœ¼ë¡œ ì¦‰ê°ì ì´ê³  ì‹¤íš¨ì„± ìˆëŠ” ëŒ€ì‘ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

[ì§„ë‹¨ ë¦¬í¬íŠ¸ ìš”ì•½]
- ê·¼ë³¸ ì›ì¸: {dx.get('root_cause', '?')}
- ìœ„í—˜ ë“±ê¸‰: {dx.get('risk_level', 'UNKNOWN')}
- ë¶„ì„ í™•ì‹ ë„: {confidence * 100}%
- êµ¬ì²´ì  ì¦ê±°: {json.dumps(dx.get('evidence', []), ensure_ascii=False)}

[ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½ ì§€ì¹¨]
1. ë‹¨ê¸° ì¡°ì¹˜: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ í”¼í•´ ìµœì†Œí™” ë°©ì•ˆ (ì˜ˆ: íŠ¹ì • íƒœê·¸ ì¼ì‹œ ì œí•œ, ì„œë²„ ë¦¬ì†ŒìŠ¤ ì¦ì„¤ ì•Œë¦¼ ë“±)
2. ì¤‘ì¥ê¸° ë°©ì•ˆ: ë™ì¼ ë¬¸ì œ ì¬ë°œ ë°©ì§€ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ ê°œì„ ì•ˆ
3. ì¡°ì¹˜ ì˜µì…˜: ê° ì „ëµì— ëŒ€í•´ ì˜ˆìƒ íš¨ê³¼(Impact)ì™€ ìˆ˜í–‰ ë‚œì´ë„(Effort), ì ì¬ì  ë¦¬ìŠ¤íŠ¸(Risk)ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
4. ìˆœìœ„ ì„ ì •: ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë ¬í•˜ì—¬ ìµœëŒ€ 3ê°œê¹Œì§€ ì œì‹œí•˜ì„¸ìš”.

ë‹¤ìŒ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
[
  {{
    "action": "êµ¬ì²´ì ì¸ ì¡°ì¹˜ ë‚´ìš© (í•œêµ­ì–´)",
    "target": "ì¡°ì¹˜ ëŒ€ìƒ (ê¸°ëŠ¥/ìœ ì €êµ°/ì¸í”„ë¼)",
    "priority": "HIGH|MEDIUM|LOW",
    "expected_impact": "ê¸°ëŒ€ë˜ëŠ” êµ¬ì²´ì  ìˆ˜ì¹˜ ë˜ëŠ” ìƒíƒœ ë³€í™”",
    "risk": "LOW|MEDIUM|HIGH",
    "reason": "í•´ë‹¹ ì¡°ì¹˜ë¥¼ ì¶”ì²œí•˜ëŠ” ì´ìœ "
  }}
]"""

    actions = await call_llm_json(prompt)

    if isinstance(actions, dict):
        actions = [actions]
    if not isinstance(actions, list):
        actions = [{"action": "ìˆ˜ë™ ëª¨ë‹ˆí„°ë§ ê°•í™”", "target": "ì„œë¹„ìŠ¤ ì „ì²´",
                     "expected_impact": "ì‹¤ì‹œê°„ íŒŒì•…", "risk": "LOW", "priority": 1}]

    iteration = state.get("iteration", 0) + 1

    # í™•ì‹ ë„ ë‚®ìœ¼ë©´ ë£¨í”„ë°±
    if confidence < 0.5 and iteration < state.get("max_iterations", 3):
        log.info(f"[Strategist] í™•ì‹ ë„ {confidence} < 0.5 â†’ ì‹¬ì¸µ ì¡°ì‚¬ (iter={iteration})")
        return {"proposed_actions": actions, "iteration": iteration, "next_action": "deep_investigate"}

    return {"proposed_actions": actions, "iteration": iteration, "next_action": "finalize"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 8: Content Miner â€” ê²€ì—´ ëŒ€ìƒ ìˆ˜ì§‘
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def content_miner_node(state: AdminAnalystState) -> dict:
    """ë°±ì—”ë“œì—ì„œ ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ìµœê·¼ ëŒ“ê¸€/ê²Œì‹œê¸€ ìˆ˜ì§‘."""
    from service import backend_client
    log.info("[ContentMiner] ê²€ì—´ ëŒ€ìƒ ìˆ˜ì§‘ ì‹œì‘...")

    # ìµœê·¼ 1ì¼ ë‚´ì˜ ë¯¸ê²€ì—´ ì½˜í…ì¸  ìµœëŒ€ 50ê°œ ìˆ˜ì§‘
    contents = await backend_client.get_recent_contents(days=1, limit=50)

    log.info(f"[ContentMiner] ìˆ˜ì§‘ ì™„ë£Œ: {len(contents or [])}ê±´")
    return {
        "moderation_queue": contents or [],
        "next_action": "guard"
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 9: Guardian â€” ì„ ì •ì„±/í­ë ¥ì„± íŒë‹¨ (LLM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def guardian_node(state: AdminAnalystState) -> dict:
    """LLMì„ ë¸”ë™ë°•ìŠ¤ ê²€ì—´ê´€ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë¶€ì ì ˆì„± íŒë‹¨."""
    log.info("[Guardian] ì½˜í…ì¸  ê²€ì—´ ì‹œì‘...")

    queue = state.get("moderation_queue", [])
    if not queue:
        return {"next_action": "execute_moderation"}

    queue_text = json.dumps(queue, ensure_ascii=False, indent=2)

    prompt = f"""ë‹¹ì‹ ì€ ë¸Œë¦­ì»¤ìŠ¤ ì„œë¹„ìŠ¤ì˜ ì½˜í…ì¸  ë³´ì•ˆ ë° ì •ì±… ì¤€ìˆ˜ ì±…ì„ì(Content Moderation Officer)ì…ë‹ˆë‹¤.
ìˆ˜ì§‘ëœ ìµœê·¼ ëŒ“ê¸€ ë° ê²Œì‹œê¸€ì„ ë¶„ì„í•˜ì—¬ 'ì„ ì •ì„±', 'í­ë ¥ì„±', 'ìš•ì„¤ ë° í˜ì˜¤', 'ì™¸ì„¤ ë° ì•…ìš©' ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì„¸ìš”.

[ê²€ìƒ‰ëœ ì½˜í…ì¸  í]
{queue_text}

[ğŸš¨ ê²€ì—´ ì •ì±… - ë¸Œë¦­ì»¤ìŠ¤ëŠ” ì–´ë¦°ì´ ì „ìš© ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤!]
1. ì„ ì •ì„± (SEXUAL) [ì¦‰ì‹œ ì°¨ë‹¨]:
   - ì„±ì ì¸ í–‰ìœ„ ë¬˜ì‚¬, ì„±ì  ìˆ˜ì¹˜ì‹¬ ìœ ë°œ í‘œí˜„, ì‹ ì²´ ë¶€ìœ„(ê°€ìŠ´, ì„±ê¸° ë“±)ì— ëŒ€í•œ ì§ì ‘/ê°„ì ‘ì  ì–¸ê¸‰.
   - ì•„ë™ ëŒ€ìƒ ê·¸ë£¨ë° ì˜ì‹¬ í‘œí˜„ ('ë²ˆí˜¸ ì¤˜', 'ì‚¬ê·€ì' ë“±) í¬í•¨.
2. í­ë ¥ì„± (VIOLENT) [ì¦‰ì‹œ ì°¨ë‹¨]:
   - ì‚´ìƒ ë¬´ê¸°ë¥¼ ì´ìš©í•œ ê°€í•´ ë°©ë²• ë¬˜ì‚¬, ìí•´/ìì‚´ ì¡°ì¥, ì‹ ì²´ í›¼ì†ì˜ ì”ì¸í•œ í…ìŠ¤íŠ¸ ë¬˜ì‚¬.
   - íƒ€ì¸ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í˜‘ë°• ë° ê³µí¬ì‹¬ ìœ ë°œ.
3. ìš•ì„¤ ë° í˜ì˜¤ (PROFANITY/HATE) [ì¦‰ì‹œ ì°¨ë‹¨]:
   - ì§ì ‘ì  ë¹„ì†ì–´ëŠ” ë¬¼ë¡ , ë³€í˜•ëœ ìš°íšŒ ìš•ì„¤(ã……ã…‚, ã…†ã…‚, 18 ë“±) ì „ì²´ í¬í•¨.
   - íŠ¹ì • ì„±ë³„, ì§€ì—­, ìœ ì €ë¥¼ ì¡°ë¡±í•˜ê±°ë‚˜ ë¹„í•˜í•˜ëŠ” í˜ì˜¤ ë‹¨ì–´ ë° ì¸ê²© ëª¨ë….
4. ì™¸ì„¤ ë° ì•…ìš© (OBSCENE/ABUSE) [ì¦‰ì‹œ ì°¨ë‹¨]:
   - ë°°ì„¤ë¬¼ ê´€ë ¨ ì§€ì €ë¶„í•œ í‘œí˜„ (ì™¸ì„¤ì ì¸ ë˜¥/ì˜¤ì¤Œ ë†ë‹´ ë“± ì–´ë¦°ì´ ì •ì„œì— ìœ í•´í•œ ìˆ˜ì¤€).
   - ê´‘ê³ , ë„ë°• ìœ ë„, ê°œì¸ì •ë³´(ì£¼ì†Œ, ì „í™”ë²ˆí˜¸) ìš”êµ¬.

[íŒë‹¨ ì§€ì¹¨]
- ìœ„ ê¸°ì¤€ ì¤‘ í•˜ë‚˜ë¼ë„ ëª…ë°±íˆ ìœ„ë°˜í–ˆë‹¤ë©´ 'is_violating': trueë¡œ ì„¤ì •í•˜ì„¸ìš”.
- íŒë‹¨ì˜ í™•ì‹ ë„(Confidence)ê°€ 0.8 ì´ìƒì¸ ê²½ìš°ì—ë§Œ ìë™ ì°¨ë‹¨ ì‹œìŠ¤í…œì´ ì‘ë™í•©ë‹ˆë‹¤.
- 'reason': ì™œ ì´ ì½˜í…ì¸ ê°€ ì°¨ë‹¨ë˜ì–´ì•¼ í•˜ëŠ”ì§€ ìœ„ ì •ì±… í•­ëª©(A, B, C, D)ì„ ì¸ìš©í•˜ì—¬ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.

ë‹¤ìŒ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
[
  {{
    "target_id": "ì½˜í…ì¸  ID",
    "type": "COMMENT|POST",
    "is_violating": true|false,
    "violation_type": "SEXUAL|VIOLENT|PROFANITY|ABUSE|NONE",
    "reason": "êµ¬ì²´ì ì¸ ìœ„ë°˜ ì‚¬ìœ  (í•œêµ­ì–´)",
    "confidence": 0.0~1.0
  }}
]"""

    judgments = await call_llm_json(prompt)
    if not isinstance(judgments, list):
        judgments = []

    log.info(f"[Guardian] ê²€ì—´ ì™„ë£Œ: {len(judgments)}ê±´ íŒì •")
    return {
        "moderation_results": judgments,
        "next_action": "execute_moderation"
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 10: Moderator Executor â€” ìë™ ì¡°ì¹˜ ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def moderator_executor_node(state: AdminAnalystState) -> dict:
    """Guardianì˜ íŒë‹¨ì— ë”°ë¼ ë°±ì—”ë“œì— ìë™ ìˆ¨ê¹€ ì²˜ë¦¬ ìš”ì²­."""
    from service import backend_client
    log.info("[ModeratorExecutor] ìë™ ì¡°ì¹˜ ì‹¤í–‰ ì‹œì‘...")

    results = state.get("moderation_results", [])
    executed_count = 0

    for res in results:
        if res.get("is_violating") and res.get("confidence", 0) >= 0.8:
            target_id = res.get("target_id")
            target_type = res.get("type")
            reason = res.get("reason", "AI Automated Moderation")

            success = await backend_client.hide_content(target_type, target_id, reason)
            if success:
                executed_count += 1
                res["action_taken"] = "HIDDEN"
                log.info(f"[ModeratorExecutor] ì¡°ì¹˜ ì™„ë£Œ: {target_type} {target_id}")
            else:
                res["action_taken"] = "FAILED"

    log.info(f"[ModeratorExecutor] ì´ {executed_count}ê±´ ìë™ ì¡°ì¹˜ ì™„ë£Œ")
    return {
        "moderation_results": results,
        "next_action": "finalize"
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 5: Deep Investigator â€” ì‹¬ì¸µ ì¡°ì‚¬ (ë£¨í”„ë°±)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def deep_investigator_node(state: AdminAnalystState) -> dict:
    """30ì¼ ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘ í›„ Diagnoserë¡œ ë£¨í”„ë°±."""
    from service import backend_client

    log.info("[DeepInvestigator] 30ì¼ ì¥ê¸° ë°ì´í„° ìˆ˜ì§‘...")

    long_daily = await backend_client.get_daily_users(30)
    long_tags = await backend_client.get_top_tags(30, limit=20)

    metrics = dict(state.get("raw_metrics", {}))
    metrics["daily_users_30d"] = long_daily or []
    metrics["top_tags_30d"] = long_tags or []

    return {"raw_metrics": metrics, "next_action": "diagnose"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 6: Reporter Green â€” ì •ìƒ ë³´ê³ ì„œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def reporter_green_node(state: AdminAnalystState) -> dict:
    """ì´ìƒ ì§•í›„ê°€ ì—†ì„ ë•Œë„ LLMìœ¼ë¡œ ì‹¬ì¸µ ìš´ì˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±."""
    log.info("[Reporter] ì •ìƒ ìƒíƒœ ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘...")

    metrics = state.get("raw_metrics", {})
    summary = metrics.get("summary", {})
    daily = metrics.get("daily_users", [])
    tags = metrics.get("top_tags", [])
    temporal = state.get("temporal_context", {})

    # íŠ¸ë Œë“œ ìš”ì•½ (LLM ì°¸ê³ ìš©)
    trend_desc = "ë³´í•©ì„¸"
    if daily and len(daily) >= 3:
        try:
            counts = [d.get("count", d.get("activeUsers", 0)) for d in daily]
            recent_avg = sum(counts[-3:]) / 3
            prev_avg = sum(counts[-6:-3]) / 3 if len(counts) >= 6 else counts[0]
            chg = ((recent_avg - prev_avg) / max(prev_avg, 1)) * 100
            trend_desc = f"ìµœê·¼ 3ì¼ í‰ê· ì´ ì´ì „ ëŒ€ë¹„ {chg:+.1f}% {'ìƒìŠ¹' if chg > 0 else 'í•˜ë½'} ì¤‘"
        except: pass

    prompt = f"""ë‹¹ì‹ ì€ ë¸Œë¦­ì»¤ìŠ¤(Brickers) ì„±ì¥ì„ ì±…ì„ì§€ëŠ” Senior Product Growth Leadì…ë‹ˆë‹¤.
í˜„ì¬ ì„œë¹„ìŠ¤ ì§€í‘œëŠ” í†µê³„ì ìœ¼ë¡œ 'ì •ìƒ ë²”ìœ„' ë‚´ì— ìˆì§€ë§Œ, ë°ì´í„°ë¥¼ ì‹¬ì¸µì ìœ¼ë¡œ íŒŒì•…í•˜ì—¬ ìˆ¨ê²¨ì§„ ì„±ì¥ì˜ ì‹¤ë§ˆë¦¬ë¥¼ ì°¾ìœ¼ì„¸ìš”.
ë‹¨ìˆœ ì§€í‘œ ìš”ì•½ì„ ë„˜ì–´, ë°ì´í„°ë¥¼ ë‹¤ê°ë„ë¡œ í•´ì„í•˜ì—¬ ê´€ë¦¬ìì—ê²Œ ê°€ì¹˜ ìˆëŠ” 'ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸'ë¥¼ ì œê³µí•˜ì„¸ìš”.

[ìˆ˜ì§‘ëœ ìš´ì˜ ì§€í‘œ]
- í™œì„± ìœ ì €(DAU): {summary.get('activeUsers', 'N/A')}
- í˜ì´ì§€ë·°/ì„¸ì…˜: {summary.get('pageViews', 'N/A')} / {summary.get('sessions', 'N/A')}
- í˜„ ì‹œì  íŠ¸ë Œë“œ ìš”ì•½: {trend_desc}

[ìœ ì € ê´€ì‹¬ íŠ¸ë Œë“œ]
- ì¸ê¸° íƒœê·¸: {', '.join(f"#{t.get('tag', 'ì•Œìˆ˜ì—†ìŒ')}" for t in tags[:7])}
- ì‹œê°„ëŒ€ë³„ íŠ¹ì„±: {temporal.get('day_of_week')}ìš”ì¼ {temporal.get('hour')}ì‹œ (í”¼í¬íƒ€ì„: {temporal.get('is_peak')})

[ë¶„ì„ ë° ì œì•ˆ ê°€ì´ë“œ]
1. 'ì§€í‘œ ì´ë©´ì˜ ë§¥ë½': í˜„ì¬ ìœ ì €ë“¤ì´ ê°€ì¥ ëª°ì…í•˜ê³  ìˆëŠ” ê¸°ëŠ¥ì´ë‚˜ ì½˜í…ì¸  í…Œë§ˆê°€ ë¬´ì—‡ì¸ì§€ ë°ì´í„°ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
2. 'ì ì¬ì  ìœ„í—˜/ê¸°íšŒ': ì§€í‘œëŠ” ì •ìƒì´ì§€ë§Œ, ì„œì„œíˆ ë³€í•˜ê³  ìˆëŠ” íƒœê·¸ íŠ¸ë Œë“œë‚˜ íŠ¹ì • ì‹œê°„ëŒ€ ìœ ì € ì´íƒˆ ì§•í›„ê°€ ìˆëŠ”ì§€ ê²€í† í•˜ì„¸ìš”.
3. 'ì„±ì¥ ë¶€ìŠ¤íŠ¸ ì „ëµ': ë‚´ì¼ ë‹¹ì¥ ì‹¤í–‰í•´ ë³¼ ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ìš´ì˜ ì•¡ì…˜(ì˜ˆ: íŠ¹ì • íƒœê·¸ íë ˆì´ì…˜, ì´ë²¤íŠ¸ ì‹œì  ì¡°ì • ë“±)ì„ ì œì•ˆí•˜ì„¸ìš”.
4. 'ìœ ì € í˜ë¥´ì†Œë‚˜ ë° í–‰ë™ ì¶”ë¡ ': ì¸ê¸° íƒœê·¸ì™€ ì‹œê°„ëŒ€ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ì–´ë–¤ ìœ ì €ì¸µì´ ë¬´ì—‡ì„ ìœ„í•´ ì ‘ì†í•˜ëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”.

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì ê·¹ í™œìš©í•˜ì—¬, 'ì§€í‘œ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸' â†’ 'ìœ ì € í–‰ë™ ë¶„ì„' â†’ 'ì„±ì¥ ì•¡ì…˜ ì œì•ˆ'ì˜ íë¦„ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

    res = await call_llm_json(prompt)
    report = res.get("report") if res else None

    if not report:
        report = f"## âœ… ì„œë¹„ìŠ¤ ì•ˆì • ìš´ì˜ ì¤‘\n\nëª¨ë“  í•µì‹¬ ì§€í‘œê°€ ì •ìƒ ë²”ìœ„ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìœ ì € ìœ ì… ë° ì „í™˜ íŠ¸ë Œë“œê°€ ì•ˆì •ì ì…ë‹ˆë‹¤. ({trend_desc})"

    return {"final_report": report, "next_action": "end"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 7: Finalizer â€” ì´ìƒ ë°œê²¬ ì‹œ ì¢…í•© ë³´ê³ ì„œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def finalizer_node(state: AdminAnalystState) -> dict:
    """ì´ìƒ ì§•í›„ ë°œê²¬ ì‹œ LLMìœ¼ë¡œ ìœ ê¸°ì ì¸ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±."""
    log.info("[Finalizer] ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì‹œì‘...")

    dx = state.get("diagnosis", {})
    actions = state.get("proposed_actions", [])
    anomalies = state.get("anomalies", [])
    mod_results = state.get("moderation_results", [])
    temporal = state.get("temporal_context", {})

    # ìë™ ì¡°ì¹˜ ë‚´ì—­ ìš”ì•½
    hidden_count = sum(1 for r in mod_results if r.get("action_taken") == "HIDDEN")
    mod_text = ""
    if mod_results:
        mod_text = "\n### ğŸ›¡ï¸ ììœ¨ ì½˜í…ì¸  ê²€ì—´ ë° ì¡°ì¹˜ ë‚´ì—­\n"
        if hidden_count > 0:
            mod_text += f"- **ìë™ ìˆ¨ê¹€ ì²˜ë¦¬**: {hidden_count}ê±´ (AI í™•ì‹ ë„ 80% ì´ìƒ)\n"
        else:
            mod_text += "- íŠ¹ì´ì‚¬í•­: ìœ„ë°˜ ì˜ì‹¬ ì½˜í…ì¸  ì—†ìŒ (í´ë¦° ìƒíƒœ ìœ ì§€ ì¤‘)\n"

        for r in [r for r in mod_results if r.get("is_violating")][:5]:
             mod_text += f"  - [{r.get('violation_type')}] {r.get('target_id')}: {r.get('reason')} ({r.get('action_taken', 'PENDING')})\n"

    prompt = f"""ë‹¹ì‹ ì€ ë¸Œë¦­ì»¤ìŠ¤(Brickers) ì„œë¹„ìŠ¤ì˜ ìœ„ê¸° ëŒ€ì‘ ë³¸ë¶€ì¥ì…ë‹ˆë‹¤.
ê°ì§€ëœ ì´ìƒ ì§•í›„ ë° ììœ¨ ê²€ì—­ ê²°ê³¼ì— ëŒ€í•´ ê²½ì˜ì§„ì´ ì¦‰ì‹œ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ 'ì‹¬ì¸µ ë¶„ì„ ë° ëŒ€ì‘ ë³´ê³ ì„œ'ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[ìˆ˜ì§‘ëœ ì´ìƒ ì§•í›„]
{json.dumps(anomalies, ensure_ascii=False, indent=2)}

[ì½˜í…ì¸  ê²€ì—´ ìš”ì•½]
{mod_text}

[ì§„ë‹¨ ê²°ê³¼ (ì›ì¸ ë° ì˜ˆì¸¡)]
- ê·¼ë³¸ ì›ì¸: {dx.get('root_cause', '?')}
- í–¥í›„ ì „ë§(Forecast): {dx.get('forecast', 'ë°ì´í„° ìˆ˜ì§‘ ì¤‘...')}
- í™•ì‹ ë„: {dx.get('confidence', 0) * 100:.1f}%
- ì¦ê±° ë° ì˜í–¥: {json.dumps(dx.get('evidence', []), ensure_ascii=False)} / {dx.get('affected_segment', 'ì „ì²´')}

[ê¶Œì¥ ëŒ€ì‘ ì „ëµ]
{json.dumps(actions, ensure_ascii=False, indent=2)}

[ë³´ê³ ì„œ ì‘ì„± ê°€ì´ë“œ]
1. ì œëª©ì€ ìƒí™©ì˜ ì‹¬ê°ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì´ëª¨ì§€ì™€ í•¨ê»˜ ì‘ì„±í•˜ì„¸ìš” (ì˜ˆ: ğŸš¨ ê¸´ê¸‰ ëŒ€ì‘ ë° ììœ¨ ë³´ì•ˆ ë³´ê³ ì„œ)
2. 'ë¸Œë¦¬í•‘': ë¬´ì—‡ì´ ë¬¸ì œì´ê³  ì–¼ë§ˆë‚˜ ì‹¬ê°í•œì§€ ì „ë¬¸ê°€ ì‹œê°ì—ì„œ í•œ ë¬¸ë‹¨ ìš”ì•½
3. 'ììœ¨ ë³´ì•ˆ ì¡°ì¹˜': Content Guardianì´ ê°ì§€í•˜ê³  ì¡°ì¹˜í•œ ë‚´ì—­ì— ëŒ€í•œ í‰ê°€ì™€ ì¶”ê°€ ê¶Œê³  ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”.
4. 'ì¸ê³¼ê´€ê³„ ë° ë¯¸ë˜ ì˜ˆì¸¡': ì™œ ë°œìƒí–ˆëŠ”ì§€ì™€ í•¨ê»˜ 'ì¡°ì¹˜ ë¯¸ë¹„ ì‹œ ì˜ˆìƒë˜ëŠ” íƒ€ê²©(Forecast/ë¯¸ë˜ ì˜ˆì¸¡ê°’)'ì„ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
5. 'ìš°ì„ ìˆœìœ„ ì¡°ì¹˜ ê³„íš': ì œì•ˆëœ ì „ëµë“¤ì„ ì‹¤í–‰ ìˆœì„œì™€ ê¸°ëŒ€ íš¨ê³¼ ì¤‘ì‹¬ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”.
6. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„± ìˆê²Œ ì‘ì„±í•˜ì„¸ìš” (í…Œì´ë¸”, ì¸ìš©êµ¬ ë“± ê¶Œì¥).

ë‹¤ìŒ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{"report": "ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ë‚´ìš© (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)"}}"""

    res = await call_llm_json(prompt)
    report = res.get("report") if res else None

    if not report:
        # Fallback í…œí”Œë¦¿
        report = f"## ğŸš¨ ê´€ë¦¬ì ì£¼ì˜: ì´ìƒ ì§•í›„ ê°ì§€\n\n- ì›ì¸: {dx.get('root_cause', '?')}\n- ì¡°ì¹˜: {len(actions)}ê±´ì˜ ì „ëµ ìˆ˜ë¦½ë¨."

    return {"final_report": report, "next_action": "end"}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node 11: Query Analyst â€” ì¸í„°ë™í‹°ë¸Œ ì§ˆì˜ì‘ë‹µ (NEW)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def query_analyst_node(state: AdminAnalystState) -> dict:
    """ì „ëµì  AI ì–´ë“œë°”ì´ì €: ëŒ€í™” ì´ë ¥ê³¼ 100ì—¬ ì§€í‘œë¥¼ ì¢…í•©í•˜ì—¬ ì…ì²´ì  ì „ëµ ìˆ˜ë¦½."""
    log.info("[QueryAnalyst] ëŒ€í™” ë§¥ë½ í¬í•¨ ì „ëµ ë¶„ì„ ì‹œì‘...")

    user_query = state.get("user_query", "í˜„ì¬ ì„œë¹„ìŠ¤ ìš´ì˜ ìƒíƒœ ì¢…í•© ì§„ë‹¨")
    history = state.get("history", []) # [NEW] ëŒ€í™” ì´ë ¥
    metrics = state.get("raw_metrics", {})
    summary = metrics.get("summary", {})
    daily = metrics.get("daily_users", [])
    tags = metrics.get("top_tags", [])
    today = metrics.get("today_stats", {})
    top_posts = metrics.get("top_posts", [])
    temporal = state.get("temporal_context", {})

    # ì´ì „ ëŒ€í™” ë§¥ë½ ìš”ì•½
    history_context = ""
    if history:
        history_context = "\n[ì´ì „ ëŒ€í™” ë§¥ë½]\n" + "\n".join([f"{h['role']}: {h['content']}" for h in history[-3:]])

    prompt = f"""ë‹¹ì‹ ì€ ë¸Œë¦­ì»¤ìŠ¤(Brickers)ì˜ ëª¨ë“  ì§€í‘œë¥¼ ê¿°ëš«ì–´ë³´ê³  ìˆëŠ” ìµœê³ ì˜ ë°ì´í„° ë¶„ì„ê°€ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ê´€ë¦¬ìì˜ íŠ¹ì • ì§ˆë¬¸ì— ëŒ€í•´ í˜„ì¬ ìˆ˜ì§‘ëœ ê±°ì‹œì  ì§€í‘œ(Analytics)ì™€ ë¯¸ì‹œì  ë¡œê·¸(Database)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì •í™•í•˜ê³  í†µì°°ë ¥ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
{history_context}

[ê´€ë¦¬ìì˜ ì§ˆë¬¸]
"{user_query}"

[ì‹¤ì‹œê°„ ìš´ì˜ ë°ì´í„° (Analytics & DB Integrated)]
- ì„œë¹„ìŠ¤ ìš”ì•½ (7D): {json.dumps(summary, ensure_ascii=False)}
- ì˜¤ëŠ˜ ì‹¤ì‹œê°„ í˜„í™©: ìƒì„±ì„±ê³µ({today.get('gen_success')}), ìƒì„±ì‹¤íŒ¨({today.get('gen_fail')}), ê°¤ëŸ¬ë¦¬ì—…ë¡œë“œ({today.get('gallery_uploads')})
- DB ì •ë°€ ë¡œê·¸ (24H): ì´ì‘ì—…({db_raw.get('total_jobs_24h')}), ë‹¨ê³„ë¶„í¬({json.dumps(db_raw.get('stage_dist', {}), ensure_ascii=False)})
- ìµœê·¼ íŠ¸ë˜í”½ ì¶”ì´ (14ì¼): {json.dumps(daily, ensure_ascii=False)}
- ì¸ê¸° íƒœê·¸ ë° ì¸ê¸° í¬ìŠ¤íŠ¸: {json.dumps(tags[:10], ensure_ascii=False)}, {json.dumps(top_posts, ensure_ascii=False)}
- ì‹œê°„ì  ë§¥ë½: {json.dumps(temporal, ensure_ascii=False)}

[ì‘ì„± ê°€ì´ë“œë¼ì¸]
1. ë°ì´í„° ê¸°ë°˜ ë‹µë³€: ë‹µë³€ì˜ ê·¼ê±°ë¥¼ ë°˜ë“œì‹œ ìœ„ [ì‹¤ì‹œê°„ ìš´ì˜ ë°ì´í„°]ì—ì„œ ì¸ìš©í•˜ê³ , ê±°ì‹œ ë°ì´í„°ì™€ ë¯¸ì‹œ ë°ì´í„°ì˜ ìƒê´€ê´€ê³„ë¥¼ ì§šì–´ì£¼ì„¸ìš”.
2. ì „ë¬¸ê°€ì  ì¶”ë¡  (Heuristic): ë°ì´í„°ê°€ ë¶€ì¡±í•  ê²½ìš°, í’ë¶€í•œ ë¶„ì„ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ì ì¸ ì¶”ì¸¡ì„ ë”í•˜ë˜ í™•ì‹  ìˆ˜ì¤€ì„ ëª…ì‹œí•˜ì„¸ìš”.
3. ìš´ì˜ ë° ë³´ê³ ì„œ ê°œì„  ì œì•ˆ: ì§ˆë¬¸ì´ ì„œë¹„ìŠ¤ ê°œì„ ì´ë‚˜ ë³´ê³ ì„œ ìˆ˜ì •ê³¼ ê´€ë ¨ë˜ì–´ ìˆë‹¤ë©´, ìƒˆë¡œìš´ ì§€í‘œ ìˆ˜ì§‘ ê´€ì ì´ë‚˜ GA4 ë§ì¶¤ ì •ì˜ í•­ëª©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•˜ì„¸ìš”.
4. ê°€ë…ì„±: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì ê·¹ í™œìš©í•˜ì—¬ ì „ë¬¸ì ì´ê³  ê¹”ë”í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

ì¹œì ˆí•˜ë©´ì„œë„ ì§€ê·¹íˆ ì „ë¬¸ì ì¸ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”."""

    res = await call_llm_json(prompt)
    report = res.get("report") if isinstance(res, dict) else str(res)
    
    if not report or report == "None":
        from .llm_utils import call_llm_text
        report = await call_llm_text(prompt)

    # ì´ë ¥ ì—…ë°ì´íŠ¸ëŠ” í˜¸ì¶œë¶€ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ì œì•ˆ (í˜„ì¬ ë…¸ë“œì—ì„œëŠ” ê²°ê³¼ë§Œ ë°˜í™˜)
    return {"final_report": report, "next_action": "end"}
