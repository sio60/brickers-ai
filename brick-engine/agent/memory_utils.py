"""
Co-Scientist í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ ëª¨ë“ˆ (v2)
- ë¹„ë™ê¸° ì €ì¥ (Background Thread)
- ì¬ì‹œë„ ë¡œì§ (Retry with Backoff)
- HuggingFace ë¡œì»¬ ì„ë² ë”© (Fallback)
- Vector Search ì¸ë±ìŠ¤ ì²´í¬
"""

import os
import sys
import uuid
import logging
import threading
from queue import Queue
from datetime import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path

# LangSmith Tracing (Optional)
try:
    from langsmith import traceable
except ImportError:
    def traceable(func): return func

# DB Connection
try:
    from yang_db import get_db
except ImportError:
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    try:
        from yang_db import get_db
    except ImportError:
        get_db = None

# Config
try:
    import config
except ImportError:
    sys.path.append(str(Path(__file__).resolve().parent.parent.parent))
    import config

# Logging
logger = logging.getLogger("CoScientistMemory")

# ============================================================================
# Background Worker for Async Save
# ============================================================================

class BackgroundSaver:
    """ë¹„ë™ê¸° DB ì €ì¥ì„ ìœ„í•œ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤"""
    
    def __init__(self):
        self.queue: Queue = Queue()
        self.worker_thread: Optional[threading.Thread] = None
        self.running = False
        
    def start(self):
        if self.running:
            return
        self.running = True
        self.worker_thread = threading.Thread(target=self._worker, daemon=True)
        self.worker_thread.start()
        logger.info("ğŸš€ Background saver started")
        
    def stop(self):
        self.running = False
        if self.worker_thread:
            self.queue.put(None)  # Poison pill
            self.worker_thread.join(timeout=5)
            
    def enqueue(self, task: callable):
        """ì €ì¥ ì‘ì—…ì„ íì— ì¶”ê°€"""
        if not self.running:
            self.start()
        self.queue.put(task)
        
    def _worker(self):
        while self.running:
            try:
                task = self.queue.get(timeout=1)
                if task is None:
                    break
                task()  # Execute the save task
            except Exception as e:
                if "Empty" not in str(type(e).__name__):
                    logger.error(f"Background save failed: {e}")


# Global background saver instance
_bg_saver = BackgroundSaver()


# ============================================================================
# Helper Functions
# ============================================================================

def calculate_delta(before: Dict[str, Any], after: Dict[str, Any]) -> Dict[str, Any]:
    """metrics_beforeì™€ metrics_afterì˜ ì°¨ì´ ìë™ ê³„ì‚°"""
    delta = {}
    for key in before:
        if key in after:
            try:
                if isinstance(before[key], (int, float)) and isinstance(after[key], (int, float)):
                    change = after[key] - before[key]
                    delta[key] = round(change, 4) if isinstance(change, float) else change
            except:
                pass
    return delta


def ensure_not_empty(value: Any, default: Any) -> Any:
    """ë¹ˆ ê°’ì´ë©´ ê¸°ë³¸ê°’ ë°˜í™˜"""
    if value is None or value == "" or value == {} or value == []:
        return default
    return value


def build_hypothesis(observation: str, hypothesis: str = None, reasoning: str = None, prediction: str = None) -> Dict[str, str]:
    """í‘œì¤€í™”ëœ hypothesis ê°ì²´ ìƒì„± (ë¹ˆê°’ ë°©ì§€)"""
    return {
        "observation": ensure_not_empty(observation, "No observation"),
        "hypothesis": ensure_not_empty(hypothesis, "No explicit hypothesis"),
        "reasoning": ensure_not_empty(reasoning, "Automatic tool selection"),
        "prediction": ensure_not_empty(prediction, "Improvement expected")
    }


def build_experiment(tool: str, parameters: Dict = None, model_name: str = None, duration_sec: float = None) -> Dict[str, Any]:
    """í‘œì¤€í™”ëœ experiment ê°ì²´ ìƒì„± (ë¹ˆê°’ ë°©ì§€)"""
    return {
        "tool": ensure_not_empty(tool, "unknown"),
        "parameters": ensure_not_empty(parameters, {}),
        "model_name": ensure_not_empty(model_name, "gemini-2.5-flash"),
        "duration_sec": ensure_not_empty(duration_sec, 0.0)
    }


def build_verification(passed: bool, metrics_before: Dict, metrics_after: Dict, numerical_analysis: str = None) -> Dict[str, Any]:
    """í‘œì¤€í™”ëœ verification ê°ì²´ ìƒì„± (delta ìë™ ê³„ì‚°)"""
    delta = calculate_delta(metrics_before, metrics_after)
    return {
        "passed": passed,
        "metrics_before": ensure_not_empty(metrics_before, {}),
        "metrics_after": ensure_not_empty(metrics_after, {}),
        "delta": delta,
        "numerical_analysis": ensure_not_empty(numerical_analysis, f"Delta: {delta}")
    }


def build_improvement(lesson_learned: str, next_hypothesis: str = None) -> Dict[str, str]:
    """í‘œì¤€í™”ëœ improvement ê°ì²´ ìƒì„± (ë¹ˆê°’ ë°©ì§€)"""
    return {
        "lesson_learned": ensure_not_empty(lesson_learned, "No lesson recorded"),
        "next_hypothesis": ensure_not_empty(next_hypothesis, "Continue current strategy")
    }


# ============================================================================
# Memory Utils Class
# ============================================================================

class MemoryUtils:
    """
    Co-Scientist í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤.
    - MongoDB êµ¬ì¡°í™”ëœ ì‹¤í—˜ ë°ì´í„° ì €ì¥ (Experiments)
    - ì„¸ì…˜ ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë°ì´í„° ì €ì¥ (Sessions)
    - ì‹¤ì‹œê°„ RAGë¥¼ ìœ„í•œ Vector Embedding ë° Indexing
    """
    
    def __init__(self):
        self.db = get_db() if get_db else None
        self.collection_exps = self.db["co_scientist_experiments"] if self.db is not None else None
        self.collection_sessions = self.db["co_scientist_sessions"] if self.db is not None else None
        
        # Vector Search ì„¤ì •
        self.vector_index_name = getattr(config, "ATLAS_VECTOR_INDEX_MEMORY", "co_scientist_memory_index")
        self.use_vector = bool(getattr(config, "MONGODB_URI", "")) and bool(self.vector_index_name)
        self._vector_index_verified = False  # ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ ìºì‹œ
        
        # HuggingFace ì„ë² ë”© ëª¨ë¸ (Lazy Loading)
        self._hf_model = None
        self._hf_tokenizer = None
        self._embed_lock = threading.Lock()  # Thread-safe ëª¨ë¸ ë¡œë”©
        
    def _load_hf_model(self):
        """HuggingFace ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (Lazy)"""
        if self._hf_model is not None:
            return
            
        with self._embed_lock:
            if self._hf_model is not None:
                return
                
            try:
                from transformers import AutoTokenizer, AutoModel
                model_name = getattr(config, "HF_EMBED_MODEL", "intfloat/multilingual-e5-small")
                logger.info(f"ğŸ“¦ Loading HF embedding model: {model_name}")
                self._hf_tokenizer = AutoTokenizer.from_pretrained(model_name)
                self._hf_model = AutoModel.from_pretrained(model_name)
                logger.info("âœ… HF embedding model loaded")
            except Exception as e:
                logger.error(f"Failed to load HF model: {e}")
        
    def _get_embedding(self, text: str, max_retries: int = 2) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (HuggingFace ìš°ì„ , Gemini Fallback)"""
        if not text:
            return []
        
        # 1ì°¨: HuggingFace ë¡œì»¬ ëª¨ë¸ (ë¬´ë£Œ, ì˜¤í”„ë¼ì¸ ê°€ëŠ¥)
        try:
            self._load_hf_model()
            if self._hf_model and self._hf_tokenizer:
                import torch
                inputs = self._hf_tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
                with torch.no_grad():
                    outputs = self._hf_model(**inputs)
                embedding = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()
                return embedding
        except Exception as e:
            logger.warning(f"HF embedding failed: {e}")
        
        # Fallback: Gemini API (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        for attempt in range(max_retries):
            try:
                if getattr(config, "GEMINI_API_KEY", ""):
                    import google.generativeai as genai
                    genai.configure(api_key=config.GEMINI_API_KEY)
                    result = genai.embed_content(
                        model="models/text-embedding-004",
                        content=text,
                        task_type="retrieval_document"
                    )
                    return result['embedding']
            except Exception as e:
                logger.warning(f"Gemini embedding attempt {attempt+1} failed: {e}")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(0.5 * (attempt + 1))
            
        return []

    def _format_context_for_embedding(self, observation: str, verification: Dict[str, Any] = None) -> str:
        """[ì‹ ê·œ] ì„ë² ë”©ìš© ë¬¸ë§¥ í¬ë§·íŒ… (ì •í™•ë„ í–¥ìƒìš©)"""
        context_parts = []
        
        if verification:
            # 1. ì‹¤íŒ¨ ìœ í˜• ëª…ì‹œ
            if not verification.get("stable", True):
                context_parts.append("Status: Unstable")
            elif verification.get("floating_bricks_count", 0) > 0:
                context_parts.append(f"Status: Floating Bricks ({verification.get('floating_bricks_count')} bricks)")
            
            # 2. í•µì‹¬ ìˆ˜ì¹˜ ì •ë³´
            if "small_brick_ratio" in verification:
                ratio = float(verification["small_brick_ratio"])
                context_parts.append(f"SmallBrickRatio: {ratio:.2f}")
                
        # 3. ê´€ì°° í…ìŠ¤íŠ¸
        context_parts.append(f"Observation: {observation}")
        
        return " | ".join(context_parts)

    def _verify_vector_index(self) -> bool:
        """Vector Search ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ìºì‹œë¨)"""
        if self._vector_index_verified:
            return True
            
        if not self.collection_exps:
            return False
            
        try:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ì¸ë±ìŠ¤ í™•ì¸
            test_pipeline = [
                {"$vectorSearch": {
                    "index": self.vector_index_name,
                    "path": "embedding",
                    "queryVector": [0.0] * 384,  # ë”ë¯¸ ë²¡í„°
                    "numCandidates": 1,
                    "limit": 1
                }}
            ]   
            list(self.collection_exps.aggregate(test_pipeline))
            self._vector_index_verified = True
            logger.info(f"âœ… Vector index '{self.vector_index_name}' verified")
            return True
        except Exception as e:
            if "index not found" in str(e).lower() or "Atlas" in str(e):
                logger.warning(f"âš ï¸ Vector index '{self.vector_index_name}' not found. RAG disabled.")
            else:
                logger.warning(f"Vector index check failed: {e}")
            return False

    @traceable(name="MemoryUtils.log_experiment")
    def log_experiment(
        self,
        session_id: str,
        model_id: str,
        agent_type: str,
        iteration: int,
        hypothesis: Dict[str, str],
        experiment: Dict[str, Any],
        verification: Dict[str, Any],
        improvement: Dict[str, Any],
        async_save: bool = True,  # ë¹„ë™ê¸° ì €ì¥ ì˜µì…˜
    ) -> str:
        """ë‹¨ì¼ ì‹¤í—˜ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì €ì¥ (ë¹„ë™ê¸° ê°€ëŠ¥)"""
        if self.collection_exps is None:
            logger.warning("DB connection not available. Skipping log.")
            return ""

        exp_id = str(uuid.uuid4())
        timestamp = datetime.utcnow().isoformat()
        
        # Document êµ¬ì¡° ìƒì„±
        doc = {
            "_id": exp_id,
            "session_id": session_id,
            "model_id": model_id,
            "agent_type": agent_type,
            "iteration": iteration,
            "timestamp": timestamp,
            "hypothesis": hypothesis,
            "experiment": experiment,
            "verification": verification,
            "improvement": improvement,
            "result_success": verification.get("passed", False)
        }
        
        # RAG ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ (Observation + ìƒì„¸ ë©”íŠ¸ë¦­ ì„ë² ë”©)
        # "ìƒí™© ìœ ì‚¬ë„" ì •í™•ë„ í–¥ìƒì„ ìœ„í•´ êµ¬ì¡°í™”ëœ í¬ë§· ì‚¬ìš©
        search_text = self._format_context_for_embedding(hypothesis.get('observation', ''), verification)
        
        # LLMì—ê²Œ ë³´ì—¬ì¤„ ì „ì²´ ìš”ì•½
        summary_text = (
            f"Observation: {hypothesis.get('observation', '')} "
            f"Hypothesis: {hypothesis.get('hypothesis', '')} "
            f"Action: {experiment.get('tool', '')} "
            f"Result: {verification.get('numerical_analysis', '')} "
            f"Lesson: {improvement.get('lesson_learned', '')}"
        )
        
        def _do_save():
            """ì‹¤ì œ ì €ì¥ ì‘ì—… (ì„ë² ë”© í¬í•¨)"""
            nonlocal doc
            try:
                # Vector Embedding (Dual Strategy)
                if self.use_vector:
                    # 1. Main Embedding (Full Context): ë‚˜ì¤‘ì— ë¶„ì„ìš©
                    doc["embedding"] = self._get_embedding(summary_text)
                    
                    # 2. Scoring Embedding (Observation Only): ê²€ìƒ‰/ì ìˆ˜ì‚°ì •ìš©
                    # "ìƒí™©ì´ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œê°€?"ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•´ ì‚¬ìš©
                    doc["observation_embedding"] = self._get_embedding(search_text)
                    
                    doc["summary_text"] = summary_text
                    doc["search_text"] = search_text 
                    
                # DB Insert
                self.collection_exps.insert_one(doc)
                logger.info(f"âœ… Experiment logged: {exp_id}")
            except Exception as e:
                logger.error(f"Failed to log experiment: {e}")
        
        # ë¹„ë™ê¸° ë˜ëŠ” ë™ê¸° ì €ì¥
        if async_save:
            _bg_saver.enqueue(_do_save)
        else:
            _do_save()
            
        return exp_id

    def start_session(self, model_id: str, agent_type: str) -> str:
        """ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘"""
        session_id = str(uuid.uuid4())
        
        if self.collection_sessions is None:
            return session_id
            
        doc = {
            "_id": session_id,
            "model_id": model_id,
            "agent_type": agent_type,
            "start_time": datetime.utcnow().isoformat(),
            "status": "RUNNING"
        }
        
        try:
            self.collection_sessions.insert_one(doc)
        except Exception as e:
            logger.error(f"Failed to start session: {e}")
            
        return session_id

    def end_session(self, session_id: str, final_status: str, summary: Dict[str, Any]):
        """ì„¸ì…˜ ì¢…ë£Œ ì²˜ë¦¬"""
        if self.collection_sessions is None:
            return
            
        try:
            self.collection_sessions.update_one(
                {"_id": session_id},
                {"$set": {
                    "end_time": datetime.utcnow().isoformat(),
                    "status": final_status,
                    "summary": summary
                }}
            )
        except Exception as e:
            logger.error(f"Failed to end session: {e}")

    @traceable(name="MemoryUtils.search_similar_cases")
    def search_similar_cases(self, observation: str, limit: int = 10, min_score: float = 0.5, verification_metrics: Dict[str, Any] = None) -> List[Dict]:
        """RAG: ìœ ì‚¬ í›„ë³´êµ° ê²€ìƒ‰ (Re-rankingì„ ìœ„í•´ ë„‰ë„‰íˆ ê²€ìƒ‰)"""
        if not self.use_vector or self.collection_exps is None:
            return []
            
        # ì¸ë±ìŠ¤ í™•ì¸ (ì²« í˜¸ì¶œ ì‹œë§Œ)
        if not self._verify_vector_index():
            return []
            
        # ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ìƒì„± (ë©”íŠ¸ë¦­ í¬í•¨)
        query_text = self._format_context_for_embedding(observation, verification_metrics)
        query_vector = self._get_embedding(query_text)
        if not query_vector:
            return []
            
        # 1. ì ìˆ˜ ê¸°ë°˜ í•„í„°ë§ ê²€ìƒ‰ (Observation ê¸°ì¤€)
        pipeline = [
            {
                "$vectorSearch": {
                    "index": self.vector_index_name,
                    "path": "observation_embedding",  # [ë³€ê²½] ìƒí™© ìœ ì‚¬ë„ ê¸°ì¤€ ê²€ìƒ‰
                    "queryVector": query_vector,
                    "numCandidates": limit * 10,
                    "limit": limit * 2
                }
            },
            {
                "$addFields": {
                    "similarity_score": {"$meta": "vectorSearchScore"}
                }
            },
            {
                "$match": {
                    "similarity_score": {"$gte": min_score}
                }
            },
            {
                "$limit": limit
            },
            {
                "$project": {
                    "_id": 0,
                    # embedding, observation_embeddingì€ ê²°ê³¼ ë¶„ì„ì„ ìœ„í•´ í¬í•¨
                    "session_id": 0,
                }
            }
        ]
        
        try:
            results = list(self.collection_exps.aggregate(pipeline))
            
            # 2. ê²°ê³¼ê°€ ì—†ìœ¼ë©´ Fallback (ì ìˆ˜ ë¬´ì‹œí•˜ê³  ê°€ì¥ ìœ ì‚¬í•œ ê²ƒ 1ê°œ ê²€ìƒ‰)
            if not results:
                logger.info(f"ğŸ” No matches with score >= {min_score}. Trying fallback...")
                fallback_pipeline = [
                    {
                        "$vectorSearch": {
                            "index": self.vector_index_name,
                            "path": "observation_embedding",
                            "queryVector": query_vector,
                            "numCandidates": 10,
                            "limit": 1
                        }
                    },
                    {
                        "$project": {
                            "_id": 0,
                            # embedding í¬í•¨
                            "session_id": 0,
                        }
                    }
                ]
                results = list(self.collection_exps.aggregate(fallback_pipeline))
                if results:
                    logger.info("ğŸ” Fallback successful: Found 1 similar case.")
            else:
                logger.info(f"ğŸ” Found {len(results)} similar cases (score >= {min_score})")
                
            return results
        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            return []

    def generate_session_report(self, session_id: str) -> Dict[str, Any]:
        """
        ì„¸ì…˜ì˜ ëª¨ë“  ì‹¤í—˜ì„ ë¶„ì„í•˜ì—¬ í”¼ë“œë°± ë³´ê³ ì„œ ìƒì„±
        
        Returns:
            Dict containing:
            - model_id: ëª¨ë¸ íŒŒì¼ëª…
            - total_iterations: ì´ ë°˜ë³µ íšŸìˆ˜
            - successful_count: ì„±ê³µí•œ ì‹¤í—˜ ìˆ˜
            - failed_count: ì‹¤íŒ¨í•œ ì‹¤í—˜ ìˆ˜
            - success_rate: ì„±ê³µë¥ 
            - tools_used: ì‚¬ìš©ëœ ë„êµ¬ í†µê³„
            - key_lessons: í•µì‹¬ êµí›ˆ
            - timeline: ì‹¤í—˜ íƒ€ì„ë¼ì¸
            - final_recommendation: ìµœì¢… ê¶Œì¥ì‚¬í•­
        """
        if self.collection_exps is None:
            return {"error": "Database not connected"}
        
        try:
            # ì„¸ì…˜ì˜ ëª¨ë“  ì‹¤í—˜ ì¡°íšŒ
            experiments = list(self.collection_exps.find(
                {"session_id": session_id}
            ).sort("iteration", 1))
            
            if not experiments:
                return {"error": "No experiments found for session"}
            
            # ê¸°ë³¸ ì •ë³´
            model_id = experiments[0].get("model_id", "unknown")
            agent_type = experiments[0].get("agent_type", "unknown")
            
            # í†µê³„ ê³„ì‚°
            total = len(experiments)
            successful = sum(1 for e in experiments if e.get("result_success", False))
            failed = total - successful
            
            # ë„êµ¬ ì‚¬ìš© í†µê³„
            tools_used = {}
            for exp in experiments:
                tool = exp.get("experiment", {}).get("tool", "unknown")
                if tool not in tools_used:
                    tools_used[tool] = {"count": 0, "success": 0, "fail": 0}
                tools_used[tool]["count"] += 1
                if exp.get("result_success"):
                    tools_used[tool]["success"] += 1
                else:
                    tools_used[tool]["fail"] += 1
            
            # ë„êµ¬ë³„ ì„±ê³µë¥  ê³„ì‚°
            for tool in tools_used:
                stats = tools_used[tool]
                stats["success_rate"] = round(stats["success"] / stats["count"] * 100, 1) if stats["count"] > 0 else 0
            
            # í•µì‹¬ êµí›ˆ ì¶”ì¶œ
            lessons = []
            for exp in experiments:
                lesson = exp.get("improvement", {}).get("lesson_learned", "")
                if lesson and lesson not in lessons:
                    lessons.append(lesson)
            
            # íƒ€ì„ë¼ì¸ (ê°„ëµí™”)
            timeline = []
            for exp in experiments:
                timeline.append({
                    "iteration": exp.get("iteration", 0),
                    "tool": exp.get("experiment", {}).get("tool", "unknown"),
                    "success": exp.get("result_success", False),
                    "analysis": exp.get("verification", {}).get("numerical_analysis", ""),
                    "delta": exp.get("verification", {}).get("delta", {})
                })
            
            # ì´ˆê¸°/ìµœì¢… ìƒíƒœ ë¹„êµ (detailed_metrics)
            first_exp = experiments[0]
            last_exp = experiments[-1]
            initial_metrics = first_exp.get("verification", {}).get("metrics_before", {})
            final_metrics = last_exp.get("verification", {}).get("metrics_after", {})
            
            improvement_by_metric = {}
            for key in initial_metrics:
                if key in final_metrics:
                    try:
                        start_val = initial_metrics[key]
                        end_val = final_metrics[key]
                        if isinstance(start_val, (int, float)) and isinstance(end_val, (int, float)):
                            delta = end_val - start_val
                            pct = round((start_val - end_val) / start_val * 100, 1) if start_val != 0 else 0
                            improvement_by_metric[key] = {
                                "start": start_val,
                                "end": end_val,
                                "delta": delta,
                                "improvement_pct": pct  # ì–‘ìˆ˜ = ê°œì„ 
                            }
                    except:
                        pass
            
            # ì„±ê³µ/ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
            tool_sequence = [t["tool"] for t in timeline]
            successful_sequences = []
            failed_sequences = []
            
            # ì—°ì†ëœ ë„êµ¬ ì¡°í•© íŒ¨í„´ ì¶”ì¶œ
            for i in range(len(timeline) - 1):
                pair = [timeline[i]["tool"], timeline[i+1]["tool"]]
                if timeline[i+1]["success"]:
                    if pair not in successful_sequences:
                        successful_sequences.append(pair)
                else:
                    if pair not in failed_sequences:
                        failed_sequences.append(pair)
            
            # ë©”íŠ¸ë¦­ë³„ ìµœì  ë„êµ¬ ë¶„ì„
            best_tool_by_metric = {}
            for metric in improvement_by_metric:
                best_delta = 0
                best_tool_for_metric = "none"
                for exp in experiments:
                    exp_delta = exp.get("verification", {}).get("delta", {}).get(metric, 0)
                    if exp_delta < best_delta:  # ê°ì†Œê°€ ê°œì„  (floating ë“±)
                        best_delta = exp_delta
                        best_tool_for_metric = exp.get("experiment", {}).get("tool", "unknown")
                if best_tool_for_metric != "none":
                    best_tool_by_metric[metric] = best_tool_for_metric
            
            # ìµœì¢… ê¶Œì¥ì‚¬í•­ ìƒì„±
            best_tool = max(tools_used.items(), key=lambda x: x[1]["success_rate"])[0] if tools_used else "none"
            worst_tool = min(tools_used.items(), key=lambda x: x[1]["success_rate"])[0] if tools_used else "none"
            
            recommendation = f"ê°€ì¥ íš¨ê³¼ì ì¸ ë„êµ¬: {best_tool} ({tools_used.get(best_tool, {}).get('success_rate', 0)}% ì„±ê³µë¥ )"
            if worst_tool != best_tool:
                recommendation += f" | í”¼í•´ì•¼ í•  ë„êµ¬: {worst_tool} ({tools_used.get(worst_tool, {}).get('success_rate', 0)}% ì„±ê³µë¥ )"
            
            # RAGìš© ì„ë² ë”© ìš”ì•½ ìƒì„±
            success_pct = round(successful / total * 100) if total > 0 else 0
            tools_summary = " ".join([f"{t}:{s['success']}/{s['count']}" for t, s in tools_used.items()])
            embedding_summary = f"{model_id} {agent_type} iter={total} success={success_pct}% {tools_summary}"
            
            # ë³´ê³ ì„œ ìƒì„±
            report = {
                "session_id": session_id,
                "model_id": model_id,
                "agent_type": agent_type,
                "generated_at": datetime.utcnow().isoformat(),
                "statistics": {
                    "total_iterations": total,
                    "successful_count": successful,
                    "failed_count": failed,
                    "success_rate": round(successful / total * 100, 1) if total > 0 else 0
                },
                "detailed_metrics": {
                    "initial_state": initial_metrics,
                    "final_state": final_metrics,
                    "improvement_by_metric": improvement_by_metric
                },
                "tools_analysis": tools_used,
                "patterns": {
                    "tool_sequence": tool_sequence,
                    "successful_sequences": successful_sequences[-3:],  # ìµœê·¼ 3ê°œ
                    "failed_sequences": failed_sequences[-3:],
                    "best_tool_by_metric": best_tool_by_metric
                },
                "key_lessons": lessons[-5:],  # ìµœê·¼ 5ê°œ
                "timeline": timeline,
                "final_recommendation": recommendation,
                "embedding_summary": embedding_summary
            }
            
            # DBì— ë³´ê³ ì„œ ì €ì¥ (sessions ì»¬ë ‰ì…˜ ì—…ë°ì´íŠ¸)
            if self.collection_sessions:
                self.collection_sessions.update_one(
                    {"_id": session_id},
                    {"$set": {
                        "report": report,
                        "status": "COMPLETED",
                        "end_time": datetime.utcnow().isoformat()
                    }}
                )
            
            logger.info(f"ğŸ“Š Session report generated: {model_id} - {successful}/{total} success")
            return report
            
        except Exception as e:
            logger.error(f"Failed to generate session report: {e}")
            return {"error": str(e)}


# Singleton Instance
memory_manager = MemoryUtils()
