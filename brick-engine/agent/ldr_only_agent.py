# ============================================================================
# LDR-ONLY Co-Scientist Agent
# ì›ë³¸ llm_regeneration_agent.pyì˜ ìˆ˜ì •ë³¸ìœ¼ë¡œ, GLB ë³€í™˜ ì—†ì´ LDR íŒŒì¼ë§Œìœ¼ë¡œ ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
# ============================================================================

import sys
import os
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Literal, TypedDict, Union
from dataclasses import dataclass, field, asdict
import json

# LangGraph & LangChain imports
try:
    from langgraph.graph import StateGraph, END
    from langgraph.graph.message import add_messages
    from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage, ToolMessage
    from typing import Annotated
except ImportError:
    print("âŒ LangGraph ë˜ëŠ” LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install langgraph langchain-core'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    sys.exit(1)

# ëª¨ë“ˆ ê²½ë¡œ ì„¤ì •
_THIS_DIR = Path(__file__).resolve().parent
_BRICK_ENGINE_DIR = _THIS_DIR.parent
_PROJECT_ROOT = _BRICK_ENGINE_DIR.parent
_PHYSICAL_VERIFICATION_DIR = _PROJECT_ROOT / "physical_verification"

for p in (_THIS_DIR, _BRICK_ENGINE_DIR, _PROJECT_ROOT, _PHYSICAL_VERIFICATION_DIR):
    sp = str(p)
    if sp not in sys.path:
        sys.path.insert(0, sp)

# LLM í´ë¼ì´ì–¸íŠ¸ & ë„êµ¬ ì„í¬íŠ¸
try:
    from .llm_clients import BaseLLMClient, GroqClient, GeminiClient
    from .agent_tools import TuneParameters, FixFloatingBricks, MergeBricks
except ImportError:
    from llm_clients import BaseLLMClient, GroqClient, GeminiClient
    from agent_tools import TuneParameters, FixFloatingBricks, MergeBricks

# DB ì—°ê²°
try:
    from yang_db import get_db
except ImportError:
    print("âš ï¸ yang_db.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Memory ì˜ì†í™” ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    get_db = None

# ============================================================================
# Memory & DB Helper Functions
# ============================================================================

import config  # This registers AGENT_DIR in sys.path
from memory_utils import memory_manager, build_hypothesis, build_experiment, build_verification, build_improvement

# Legacy functions (kept for compatibility)
def get_memory_collection(): return memory_manager.collection_exps if memory_manager else None
def load_memory_from_db(model_id: str): return {}
def save_memory_to_db(model_id: str, memory: Dict): pass

# ============================================================================
# ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì •ì˜
# ============================================================================

DEFAULT_PARAMS = {
    "target": 25,
    "min_target": 5,
    "budget": 150,
    "shrink": 0.7,
    "search_iters": 6,
    "flipx180": False,
    "flipy180": False,
    "flipz180": False,
    "kind": "brick",
    "plates_per_voxel": 3,
    "interlock": True,
    "max_area": 20,
    "solid_color": 4,
    "use_mesh_color": True,
    "invert_y": False,
    "smart_fix": True,
    "fill": True,
    "step_order": "bottomup",
}

# ============================================================================
# ë°ì´í„° êµ¬ì¡° ë° í—¬í¼ í•¨ìˆ˜
# ============================================================================

@dataclass
class VerificationFeedback:
    stable: bool = True
    total_bricks: int = 0
    fallen_bricks_count: int = 0
    floating_bricks_count: int = 0
    floating_brick_ids: List[str] = field(default_factory=list)
    fallen_brick_ids: List[str] = field(default_factory=list)
    failure_ratio: float = 0.0
    first_failure_brick: Optional[str] = None
    max_drift: float = 0.0
    collision_count: int = 0
    small_brick_count: int = 0
    small_brick_ratio: float = 0.0

def extract_verification_feedback(result, total_bricks: int) -> VerificationFeedback:
    feedback = VerificationFeedback()
    feedback.total_bricks = total_bricks
    feedback.stable = result.is_valid
    
    fallen_bricks = set()
    floating_bricks = set()
    first_failure = None
    collision_count = 0
    
    for ev in result.evidence:
        if ev.type == "FIRST_FAILURE":
            if ev.brick_ids:
                first_failure = ev.brick_ids[0]
                fallen_bricks.update(ev.brick_ids)
        elif ev.type == "COLLAPSE_AFTERMATH":
            if ev.brick_ids:
                fallen_bricks.update(ev.brick_ids)
        elif ev.type == "FLOATING_BRICK":
            if ev.brick_ids:
                floating_bricks.update(ev.brick_ids)
        elif ev.type == "COLLISION":
            collision_count += 1
    
    feedback.fallen_bricks_count = len(fallen_bricks)
    feedback.floating_bricks_count = len(floating_bricks)
    feedback.floating_brick_ids = list(floating_bricks)
    feedback.fallen_brick_ids = list(fallen_bricks)
    feedback.first_failure_brick = first_failure
    feedback.collision_count = collision_count
    
    if total_bricks > 0:
        feedback.failure_ratio = (len(fallen_bricks) + len(floating_bricks)) / total_bricks
    
    return feedback

def _format_feedback(feedback: VerificationFeedback) -> str:
    if feedback.stable and feedback.floating_bricks_count == 0:
        status = "âœ… ì•ˆì •"
    elif feedback.stable and feedback.floating_bricks_count > 0:
        status = "âš ï¸ ë¶€ë¶„ ì•ˆì • (ê³µì¤‘ë¶€ì–‘ ì¡´ì¬)"
    else:
        status = "âŒ ë¶ˆì•ˆì •"
        
    lines = [
        f"ê²€ì¦ ê²°ê³¼:",
        f"- ìƒíƒœ: {status}",
        f"- ì´ ë¸Œë¦­ ìˆ˜: {feedback.total_bricks}ê°œ",
    ]
    
    if feedback.small_brick_count > 0:
        lines.append(f"- 1x1 ë¸Œë¦­: {feedback.small_brick_count}ê°œ ({feedback.small_brick_ratio * 100:.1f}%)")
        if feedback.small_brick_ratio > 0.3:
            lines.append(f"  â†’ ğŸ’¡ 1x1 ë¸Œë¦­ ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. MergeBricksë¡œ ì—°ê²° ê°•í™”ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    if not feedback.stable or feedback.floating_bricks_count > 0:
        lines.extend([
            f"- ë–¨ì–´ì§„ ë¸Œë¦­: {feedback.fallen_bricks_count}ê°œ",
            f"- ê³µì¤‘ë¶€ì–‘ ë¸Œë¦­: {feedback.floating_bricks_count}ê°œ",
            f"- ì‹¤íŒ¨ìœ¨: {feedback.failure_ratio * 100:.1f}%",
        ])
        if feedback.first_failure_brick:
            lines.append(f"- ìµœì´ˆ ë¶•ê´´ ë¸Œë¦­: {feedback.first_failure_brick}")
        if feedback.floating_brick_ids:
            lines.append(f"- ê³µì¤‘ë¶€ì–‘ ë¸Œë¦­ ID ëª©ë¡: {feedback.floating_brick_ids}")
        if feedback.fallen_brick_ids:
            lines.append(f"- ë–¨ì–´ì§„ ë¸Œë¦­ ID ëª©ë¡: {feedback.fallen_brick_ids}")
            
    if feedback.collision_count > 0:
        lines.append(f"- ì¶©ëŒ ê°ì§€: {feedback.collision_count}ê±´")
    
    return "\n".join(lines)


# ============================================================================
# LangGraph State ì •ì˜
# ============================================================================

class AgentState(TypedDict):
    glb_path: Optional[str]  # Optional for LDR-only mode
    ldr_path: str
    params: Dict[str, Any]
    max_retries: int
    acceptable_failure_ratio: float
    verification_duration: float
    gui: bool
    
    attempts: int
    session_id: str
    messages: Annotated[List[BaseMessage], add_messages]
    
    verification_raw_result: Any 
    floating_bricks_ids: List[str]
    verification_errors: int
    
    tool_usage_count: Dict[str, int]
    last_tool_used: Optional[str]
    consecutive_same_tool: int
    
    previous_metrics: Dict[str, Any]
    current_metrics: Dict[str, Any]
    
    final_report: Dict[str, Any]
    memory: Dict[str, Any]
    next_action: str


# ============================================================================
# LangGraph Agent Logic (LDR-ONLY MODIFIED)
# ============================================================================

class RegenerationGraph:
    def __init__(self, llm_client: Optional[BaseLLMClient] = None):
        if llm_client is None:
            self.llm_client = GeminiClient()
        else:
            self.llm_client = llm_client
            
        # LDR ì „ìš©ì— ë§ê²Œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
        self.SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë ˆê³  ë¸Œë¦­ êµ¬ì¡°ë¬¼ ì„¤ê³„ ë° ì•ˆì •í™” ì „ë¬¸ê°€(Co-Scientist)ì…ë‹ˆë‹¤.
LDR 3D ëª¨ë¸ì˜ êµ¬ì¡°ì  ë¶ˆì•ˆì •ì„± ë¬¸ì œë¥¼ í•´ê²°í•´ì•¼ í•©ë‹ˆë‹¤.

ë‹¹ì‹ ì—ê²ŒëŠ” ë‘ ê°€ì§€ ì£¼ìš” ìˆ˜ë¦¬ ë„êµ¬ê°€ ìˆìŠµë‹ˆë‹¤:
1. `FixFloatingBricks`: ì „ì²´ì ìœ¼ë¡œëŠ” ê´œì°®ì§€ë§Œ ì¼ë¶€ ê³µì¤‘ë¶€ì–‘í•˜ê±°ë‚˜ ë¶ˆì•ˆì •í•œ ë¸Œë¦­ì´ ìˆì„ ë•Œ, í•´ë‹¹ ë¸Œë¦­ì„ *ì‚­ì œ*í•˜ì—¬ ì •ë¦¬í•©ë‹ˆë‹¤. (ê°•ë ¥ ê¶Œì¥)
2. `MergeBricks`: ê°™ì€ ìƒ‰ìƒì˜ ì¸ì ‘í•œ 1x1 ë¸Œë¦­ë“¤ì„ í° ë¸Œë¦­(1x2~1x8)ìœ¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤. ì—°ê²°ì´ ê°•í™”ë˜ì–´ ì•ˆì •ì„±ì´ í–¥ìƒë©ë‹ˆë‹¤.
3. `TuneParameters`: (ì£¼ì˜) ì´ ë„êµ¬ëŠ” GLB íŒŒì¼ì´ í•„ìš”í•˜ë¯€ë¡œ í˜„ì¬ ëª¨ë“œì—ì„œëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

**ì˜ì‚¬ê²°ì • ì•Œê³ ë¦¬ì¦˜ (Decision Logic):**
1. **ê³µì¤‘ë¶€ì–‘/ë–¨ì–´ì§„ ë¸Œë¦­ IDê°€ ëª…í™•íˆ ìˆìœ¼ë©´** â†’ `FixFloatingBricks`ë¡œ í•´ë‹¹ ë¸Œë¦­ ì‚­ì œ
2. **1x1 ë¸Œë¦­ì´ ë§ì•„ ì—°ê²°ì´ ì•½í•˜ë‹¤ëŠ” ì§•í›„ê°€ ìˆìœ¼ë©´** â†’ `MergeBricks`ë¡œ ë³´ê°• (1x1ë“¤ì„ í° ë¸Œë¦­ìœ¼ë¡œ í†µí•©)
3. **ë‘˜ ë‹¤ í•´ë‹¹ë˜ë©´** â†’ ë¨¼ì € `MergeBricks`ë¡œ ë³´ê°• â†’ ì¬ê²€ì¦ í›„ í•„ìš”ì‹œ `FixFloatingBricks`

ëª©í‘œ: ë¬¼ë¦¬ì ìœ¼ë¡œ ì•ˆì •ì (Stable)ì¸ ë ˆê³  êµ¬ì¡°ë¬¼ì„ ë§Œë“œëŠ” ê²ƒ.
ê³µì¤‘ë¶€ì–‘ ë¸Œë¦­ì´ 0ê°œê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
"""

        self.verifier = None
        
    # --- Nodes ---

    def node_generator(self, state: AgentState) -> Dict[str, Any]:
        """GLB -> LDR ë³€í™˜ ë…¸ë“œ (LDR-only ëª¨ë“œì—ì„œëŠ” Dummy ì—­í• )"""
        print(f"\n[Generator] LDR-only ëª¨ë“œì´ë¯€ë¡œ ë³€í™˜ ë‹¨ê³„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {"next_action": "verify"}

    def node_verifier(self, state: AgentState) -> Dict[str, Any]:
        """ë¬¼ë¦¬ ê²€ì¦ ë…¸ë“œ"""
        from physical_verification.pybullet_verifier import PyBulletVerifier
        from physical_verification.ldr_loader import LdrLoader
        
        print("\n[Verifier] ë¬¼ë¦¬ ê²€ì¦ ìˆ˜í–‰ ì¤‘...")
        
        if not os.path.exists(state['ldr_path']):
            return {"messages": [HumanMessage(content="LDR íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")], "next_action": "end"}
            
        try:
            loader = LdrLoader()
            plan = loader.load_from_file(state['ldr_path'])
            total_bricks = len(plan.bricks)
            
            small_brick_parts = {"3005.dat", "3024.dat"}
            small_brick_count = 0
            for b in plan.bricks:
                part_id = getattr(b, 'part_id', None) or (b.get('part') if isinstance(b, dict) else None)
                if part_id in small_brick_parts:
                    small_brick_count += 1
            small_brick_ratio = small_brick_count / total_bricks if total_bricks > 0 else 0.0
            
            if self.verifier is not None:
                try:
                    self.verifier._close_simulation()
                except:
                    pass
            
            verifier = PyBulletVerifier(plan, gui=state['gui'])
            self.verifier = verifier
            
            stab_result = verifier.run_stability_check(duration=state['verification_duration'], auto_close=False)
            
            feedback = extract_verification_feedback(stab_result, total_bricks)
            feedback.small_brick_count = small_brick_count
            feedback.small_brick_ratio = small_brick_ratio
            
            feedback_text = _format_feedback(feedback)
            
            if feedback.stable and feedback.floating_bricks_count == 0:
                short_status = "âœ… ì•ˆì •"
            elif feedback.stable and feedback.floating_bricks_count > 0:
                short_status = "âš ï¸ ë¶€ë¶„ ì•ˆì • (ê³µì¤‘ë¶€ì–‘ ì¡´ì¬)"
            else:
                short_status = "âŒ ë¶ˆì•ˆì •"
            
            print(f"  ê²°ê³¼: {short_status}")
            
            if not feedback.stable or feedback.floating_bricks_count > 0:
                 summary_text = feedback_text.replace('\n', ', ').replace('\r', '')
                 if len(summary_text) > 200:
                     summary_text = summary_text[:200] + "..."
                 print(f"  ìš”ì•½: {summary_text}")
            
            floating_ids = []
            for ev in stab_result.evidence:
                if ev.type == "FLOATING_BRICK" and ev.brick_ids:
                    floating_ids.extend(ev.brick_ids)
            
            current_metrics = {
                "failure_ratio": feedback.failure_ratio,
                "small_brick_ratio": small_brick_ratio,
                "small_brick_count": small_brick_count,
                "total_bricks": total_bricks,
                "floating_count": feedback.floating_bricks_count,
                "fallen_count": feedback.fallen_bricks_count,
            }
            
            is_physically_okay = feedback.stable or (feedback.failure_ratio <= state['acceptable_failure_ratio'])
            is_success = is_physically_okay and (feedback.floating_bricks_count == 0)
            
            if is_success:
                print("ğŸ‰ ëª©í‘œ ë‹¬ì„±! í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                final_report = {
                    "success": True,
                    "total_attempts": state['attempts'],
                    "tool_usage": state.get('tool_usage_count', {}),
                    "final_metrics": current_metrics,
                    "message": "ì•ˆì •ì ì¸ êµ¬ì¡°ë¬¼ ìƒì„± ì™„ë£Œ"
                }
                return {"next_action": "end", "final_report": final_report}
            
            if state['attempts'] >= state['max_retries']:
                print("ğŸ’¥ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼.")
                final_report = {
                    "success": False,
                    "total_attempts": state['attempts'],
                    "tool_usage": state.get('tool_usage_count', {}),
                    "final_metrics": current_metrics,
                    "message": "ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ë¡œ ì¢…ë£Œ"
                }
                return {"next_action": "end", "final_report": final_report}

            custom_feedback = feedback_text
            if feedback.floating_bricks_count > 0:
                custom_feedback += "\n\nâš ï¸ **ì¤‘ìš”: ì•„ì§ ê³µì¤‘ë¶€ì–‘(Floating) ë¸Œë¦­ì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤. ì´ ìƒíƒœë¡œëŠ” ì ˆëŒ€ ì‘ì—…ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ FixFloatingBricks ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ í•´ê²°í•˜ì„¸ìš”.**"
            
            return {
                "verification_raw_result": stab_result,
                "floating_bricks_ids": floating_ids,
                "messages": [HumanMessage(content=custom_feedback)],
                "current_metrics": current_metrics,
                "next_action": "reflect"
            }
            
        except Exception as e:
            print(f"  âŒ ê²€ì¦ ì¤‘ ì—ëŸ¬: {e}")
            verification_errors = state.get('verification_errors', 0) + 1
            if verification_errors >= 3:
                return {"next_action": "end"} # ì¬ìƒì„± ë¶ˆê°€í•˜ë¯€ë¡œ ì¢…ë£Œ
            else:
                import time
                time.sleep(1)
                return {"verification_errors": verification_errors, "next_action": "verifier"}

    def node_model(self, state: AgentState) -> Dict[str, Any]:
        """LLMì´ ìƒí™©ì„ ë¶„ì„í•˜ê³  ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ë…¸ë“œ"""
        import time
        time.sleep(2) 
        
        print("\n[Co-Scientist] ìƒí™© ë¶„ì„ ì¤‘...")
        
        # Tools definitions
        # TuneParametersëŠ” ì œì™¸í•˜ê±°ë‚˜ ê²½ê³  ì²˜ë¦¬í•  ìˆ˜ë„ ìˆì§€ë§Œ, ì¼ë‹¨ í¬í•¨í•˜ë˜ í”„ë¡¬í”„íŠ¸ì—ì„œ ì œí•œ
        # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ FixFloatingBricks, MergeBricksë§Œ í™œì„±í™”
        tools = [FixFloatingBricks, MergeBricks]
    
        messages_to_send = state['messages'][:]
        
        if memory_manager:
            last_msg = messages_to_send[-1]
            obs = last_msg.content if isinstance(last_msg, HumanMessage) else ""
            similar_cases = memory_manager.search_similar_cases(obs, limit=3)
            
            if similar_cases:
                memory_info = "\n**ğŸ“š ìœ ì‚¬í•œ ê³¼ê±° ì‹¤í—˜ ì‚¬ë¡€ (RAG):**\n"
                for i, case in enumerate(similar_cases, 1):
                    tool = case['experiment'].get('tool', 'Unknown')
                    result = case['verification'].get('numerical_analysis', 'N/A')
                    outcome = "ì„±ê³µ" if case.get('result_success') else "ì‹¤íŒ¨"
                    memory_info += f"[{i}] {outcome} ({tool}): {result}\n"
                messages_to_send.append(SystemMessage(content=memory_info))

        # Legacy Memory (Fallback)
        memory = state.get('memory', {})
        lessons = memory.get('lessons', [])
        failed_approaches = memory.get('failed_approaches', [])
        
        if lessons or failed_approaches:
            memory_info = "\n**ğŸ“š ì´ì „ ê²½í—˜ (Memory):**\n"
            if lessons:
                memory_info += "- ìµœê·¼ êµí›ˆ: " + "; ".join(lessons[-3:]) + "\n"
            if failed_approaches:
                memory_info += "- í”¼í•´ì•¼ í•  ì ‘ê·¼ë²•: " + "; ".join(failed_approaches[-3:]) + "\n"
            messages_to_send.append(SystemMessage(content=memory_info))
        
        # íŒíŠ¸ ì£¼ì…
        last_msg = messages_to_send[-1]
        if isinstance(last_msg, HumanMessage) and "ê²€ì¦ ê²°ê³¼" in str(last_msg.content):
            floating_ids = state.get('floating_bricks_ids', [])
            if floating_ids:
                advice = f"âš ï¸ ê³µì¤‘ë¶€ì–‘ ë¸Œë¦­ {len(floating_ids)}ê°œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ `FixFloatingBricks`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
                messages_to_send.append(SystemMessage(content=advice))

        try:
            model_with_tools = self.llm_client.bind_tools(tools)
            response = model_with_tools.invoke(messages_to_send)
            
            if response.tool_calls:
                print(f"  ğŸ”¨ ë„êµ¬ ì„ íƒ: {[tc['name'] for tc in response.tool_calls]}")
                return {"messages": [response], "next_action": "tool"}
            else:
                print(f"  ğŸ’­ LLM ì˜ê²¬: {response.content}")
                
                # ê°•ì œ ì§„í–‰ ìœ ë„
                retry_msg = "ë„êµ¬ë¥¼ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ë©´ ë°˜ë“œì‹œ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤."
                return {"messages": [response, HumanMessage(content=retry_msg)], "next_action": "model"}
                
        except Exception as e:
            print(f"  âš ï¸ LLM í˜¸ì¶œ ì—ëŸ¬: {e}")
            if "429" in str(e):
                time.sleep(10)
                return {"next_action": "model"}
            return {"next_action": "end"}

    def node_tool_executor(self, state: AgentState) -> Dict[str, Any]:
        """ì„ íƒëœ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ë…¸ë“œ"""
        last_message = state['messages'][-1]
        
        if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
            return {"next_action": "model"}
        
        tool_results = []
        next_step = "verify" # ê¸°ë³¸ì ìœ¼ë¡œ ë‹¤ì‹œ ê²€ì¦ìœ¼ë¡œ ì´ë™
        
        tool_usage_count = state.get('tool_usage_count', {})
        previous_metrics = state.get('previous_metrics', {})
        
        for tool_call in last_message.tool_calls:
            tool_name = tool_call['name']
            args = tool_call['args']
            tool_call_id = tool_call['id']
            
            tool_usage_count[tool_name] = tool_usage_count.get(tool_name, 0) + 1
            print(f"\n[Tool Execution] {tool_name} ì‹¤í–‰... (ì´ {tool_usage_count[tool_name]}íšŒ)")
            
            result_content = ""
            
            if tool_name == "FixFloatingBricks":
                from ldr_modifier import apply_llm_decisions
                bricks_to_delete = args.get('bricks_to_delete', [])
                if not bricks_to_delete:
                    result_content = "ì‚­ì œí•  ë¸Œë¦­ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                else:
                    decisions = [{"action": "delete", "brick_id": bid} for bid in bricks_to_delete]
                    try:
                        stats = apply_llm_decisions(state['ldr_path'], decisions)
                        result_content = f"ìˆ˜ì • ì™„ë£Œ: {stats['deleted']}ê°œ ë¸Œë¦­ ì‚­ì œë¨."
                    except Exception as e:
                        result_content = f"ìˆ˜ì • ì‹¤íŒ¨: {e}"
            
            elif tool_name == "MergeBricks":
                from ldr_modifier import merge_small_bricks
                target_brick_ids = args.get('target_brick_ids', None)
                min_merge_count = args.get('min_merge_count', 2)
                try:
                    stats = merge_small_bricks(
                        state['ldr_path'],
                        target_brick_ids=target_brick_ids,
                        min_merge_count=min_merge_count
                    )
                    result_content = f"ë³‘í•© ì™„ë£Œ: {stats['merged']}ê°œ ê·¸ë£¹ ë³‘í•©ë¨"
                except Exception as e:
                    result_content = f"ë³‘í•© ì‹¤íŒ¨: {e}"
            else:
                result_content = f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë„êµ¬: {tool_name}"
            
            print(f"  ê²°ê³¼: {result_content}")
            
            tool_results.append(ToolMessage(content=result_content, tool_call_id=tool_call_id))
            
        return {
            "messages": tool_results, 
            "next_action": "verifier", # ë¬´ì¡°ê±´ ê²€ì¦ìœ¼ë¡œ
            "tool_usage_count": tool_usage_count,
        }

    def node_reflect(self, state: AgentState) -> Dict[str, Any]:
        """íšŒê³  ë…¸ë“œ"""
        print("\n[Reflect] ì‹¤ì œ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        
        memory = state.get('memory', {"failed_approaches": [], "successful_patterns": [], "lessons": [], "consecutive_failures": 0})
        current_metrics = state.get('current_metrics', {})
        
        # ì´ì „ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
        previous_metrics = state.get('previous_metrics', {})
        if not previous_metrics:
            return {"memory": memory, "previous_metrics": current_metrics, "next_action": "model"}

        # ë©”íŠ¸ë¦­ ë¹„êµ
        prev_floating = previous_metrics.get('floating_count', 0)
        curr_floating = current_metrics.get('floating_count', 0)
        floating_improved = curr_floating < prev_floating
        
        last_tool = state.get('last_tool_used', 'unknown')
        
        # ê°„ë‹¨í•œ ì„±ê³µ íŒì •
        success = floating_improved
        lesson = f"{last_tool}: ê³µì¤‘ë¶€ì–‘ {prev_floating}->{curr_floating} ({'ì„±ê³µ' if success else 'ì‹¤íŒ¨'})"
        
        if success:
             memory["successful_patterns"].append(f"{last_tool}: íš¨ê³¼ í™•ì¸")
             memory["consecutive_failures"] = 0
        else:
             memory["failed_approaches"].append(f"{last_tool}: íš¨ê³¼ ë¯¸ë¯¸")
             memory["consecutive_failures"] += 1
             
        memory["lessons"].append(lesson)

        # Unified Logging (í‘œì¤€í™”ëœ í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
        if memory_manager:
            try:
                # ìƒì„¸ observation ìƒì„±
                detailed_obs = f"floating={prev_floating}, ratio={previous_metrics.get('small_brick_ratio', 0):.2f}, total={previous_metrics.get('total_bricks', 0)}"
                
                memory_manager.log_experiment(
                    session_id=state.get('session_id', 'ldr_session'),
                    model_id=Path(state['ldr_path']).name,
                    agent_type="ldr_only",
                    iteration=state['attempts'],
                    hypothesis=build_hypothesis(
                        observation=detailed_obs,
                        hypothesis=f"{last_tool} ì ìš©ìœ¼ë¡œ floating ê°ì†Œ ê¸°ëŒ€",
                        reasoning=f"Memory lessons: {memory.get('lessons', [])[-1] if memory.get('lessons') else 'None'}",
                        prediction=f"floating: {prev_floating}â†’{curr_floating} ì˜ˆìƒ"
                    ),
                    experiment=build_experiment(
                        tool=last_tool,
                        parameters=state.get('params', {}),
                        model_name="gemini-2.5-flash"
                    ),
                    verification=build_verification(
                        passed=success,
                        metrics_before=previous_metrics,
                        metrics_after=current_metrics,
                        numerical_analysis=f"floating {prev_floating}â†’{curr_floating} ({curr_floating - prev_floating:+d}), ratio {previous_metrics.get('small_brick_ratio', 0):.2f}â†’{current_metrics.get('small_brick_ratio', 0):.2f}"
                    ),
                    improvement=build_improvement(
                        lesson_learned=lesson,
                        next_hypothesis="Continue" if success else "Try different tool"
                    )
                )
            except Exception as e:
                print(f"âš ï¸ [Memory] ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")

        # Legacy Save (Fallback)
        try:
             model_id = Path(state['ldr_path']).name
             save_memory_to_db(model_id, memory)
        except: pass
        
        return {
            "memory": memory, 
            "previous_metrics": current_metrics,
            "next_action": "model"
        }

    def build(self):
        workflow = StateGraph(AgentState)
        
        workflow.add_node("generator", self.node_generator)
        workflow.add_node("verifier", self.node_verifier)
        workflow.add_node("model", self.node_model)
        workflow.add_node("tool_executor", self.node_tool_executor)
        workflow.add_node("reflect", self.node_reflect)
        
        def route_next(state: AgentState):
            return state['next_action']
            
        workflow.add_conditional_edges("generator", route_next, {"verify": "verifier"})
        workflow.add_conditional_edges("verifier", route_next, {"model": "model", "end": END, "verifier": "verifier", "reflect": "reflect"})
        workflow.add_conditional_edges("model", route_next, {"tool": "tool_executor", "model": "model", "end": END})
        workflow.add_conditional_edges("tool_executor", route_next, {"verifier": "verifier"})
        workflow.add_conditional_edges("reflect", route_next, {"model": "model"})
        
        # START POINT CHANGED TO VERIFIER
        workflow.set_entry_point("verifier")
        
        return workflow.compile()

# ============================================================================
# ì‹¤í–‰ í•¨ìˆ˜
# ============================================================================

def regeneration_loop(
    ldr_path: str,
    llm_client: Optional[BaseLLMClient] = None,
    max_retries: int = 5,
    gui: bool = False,
):
    print("=" * 60)
    print("ğŸ¤– Co-Scientist Agent (LDR-Only Ver.)")
    print("=" * 60)
    
    graph_builder = RegenerationGraph(llm_client)
    app = graph_builder.build()
    
    system_msg = SystemMessage(content=graph_builder.SYSTEM_PROMPT)
    
    # Memory Load
    initial_memory = {"failed_approaches": [], "successful_patterns": [], "lessons": [], "consecutive_failures": 0}
    try:
        model_id = Path(ldr_path).name
        loaded_mem = load_memory_from_db(model_id)
        if loaded_mem:
            initial_memory.update(loaded_mem)
    except:
        pass

    initial_state = AgentState(
        glb_path=None,
        ldr_path=ldr_path,
        params=DEFAULT_PARAMS.copy(),
        attempts=0,
        session_id=memory_manager.start_session(Path(ldr_path).name, "ldr_only") if memory_manager else "offline",
        max_retries=max_retries,
        acceptable_failure_ratio=0.1,
        verification_duration=2.0,
        gui=gui,
        messages=[system_msg],
        verification_raw_result=None,
        floating_bricks_ids=[],
        verification_errors=0,
        tool_usage_count={},
        last_tool_used=None,
        consecutive_same_tool=0,
        previous_metrics={},
        current_metrics={},
        final_report={},
        memory=initial_memory,
        next_action="verifier" # START ACTION
    )
    
    final_state = app.invoke(initial_state)
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ ìµœì¢… ê²°ê³¼")
    print("=" * 60)
    if 'final_report' in final_state and final_state['final_report'].get('success'):
        print("âœ… ì„±ê³µ")
    else:
        print("âŒ ì‹¤íŒ¨ ë˜ëŠ” ì¤‘ë‹¨ë¨")
    
    # ğŸ“Š ì„¸ì…˜ í”¼ë“œë°± ë³´ê³ ì„œ ìƒì„±
    if memory_manager:
        try:
            session_id = final_state.get('session_id', '')
            if session_id and session_id != 'offline':
                feedback_report = memory_manager.generate_session_report(session_id)
                if 'error' not in feedback_report:
                    print("\nğŸ“Š [Co-Scientist] ì„¸ì…˜ í”¼ë“œë°± ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
                    print(f"   - ì´ ë°˜ë³µ: {feedback_report.get('statistics', {}).get('total_iterations', 0)}íšŒ")
                    print(f"   - ì„±ê³µë¥ : {feedback_report.get('statistics', {}).get('success_rate', 0)}%")
                    print(f"   - ê¶Œì¥ì‚¬í•­: {feedback_report.get('final_recommendation', '')}")
        except Exception as e:
            print(f"âš ï¸ [Co-Scientist] ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
    
    return final_state

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("ldr", help="ìµœì í™”í•  LDR íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--max-retries", type=int, default=5)
    parser.add_argument("--gui", action="store_true")
    parser.add_argument("--api-key", help="API Key")
    
    args = parser.parse_args()
    
    client = GeminiClient(api_key=args.api_key)
    
    regeneration_loop(
        args.ldr,
        llm_client=client,
        max_retries=args.max_retries,
        gui=args.gui
    )
