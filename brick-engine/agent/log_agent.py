from typing import TypedDict, Annotated, List, Optional, Dict, Any, Union
import os
import docker
import json
import logging
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langgraph.graph import StateGraph, END

# Logger configuration
logger = logging.getLogger("agent.log_agent")

# LLM Client Import
try:
    from .llm_clients import GeminiClient
    from .agent_tools import ReadFileSnippet, CheckDBStatus, CheckSystemHealth, CheckSQSStatus, execute_read_file, execute_check_db, execute_check_system, execute_check_sqs
except ImportError:
    # Standalone execution support
    import sys
    from pathlib import Path
    sys.path.append(str(Path(__file__).resolve().parent))
    from llm_clients import GeminiClient
    from agent_tools import ReadFileSnippet, CheckDBStatus, CheckSystemHealth, CheckSQSStatus, execute_read_file, execute_check_db, execute_check_system, execute_check_sqs

# --- State Definition ---
class LogAnalysisState(TypedDict):
    container_name: str
    logs: str  # Raw logs
    messages: List[Annotated[str, "History"]] 
    analysis_result: Optional[str] 
    error_count: int
    iteration: int # Loop counter

# --- Tool Execution Logic ---
# --- Tool Execution Logic (Moved to agent_tools.py or imported) ---
# execute_read_file is now imported from agent_tools.py
# ensuring we use the centralized definition.

# --- Nodes ---

# --- Nodes (ë…¸ë“œ ì •ì˜) ---



# --- Nodes (ë…¸ë“œ ì •ì˜) ---

def fetch_logs_node(state: LogAnalysisState):
    """
    [ë…¸ë“œ 1: ë¡œê·¸ ìˆ˜ì§‘]
    Docker SDKë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰ ì¤‘ì¸ ì»¨í…Œì´ë„ˆì˜ ìµœì‹  ë¡œê·¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    container_name = state.get("container_name", "brickers-ai-container")
    logger.info(f"--- [ë¡œê·¸ ì—ì´ì „íŠ¸] 1ë‹¨ê³„: ì»¨í…Œì´ë„ˆ ë¡œê·¸ ìˆ˜ì§‘ ì¤‘ ({container_name}) ---")
    try:
        client = docker.from_env()
        container = client.containers.get(container_name)
        logs = container.logs(tail=500).decode("utf-8", errors="replace")
        logger.info(f"âœ… ë¡œê·¸ ìˆ˜ì§‘ ì„±ê³µ ({len(logs)} ë°”ì´íŠ¸).")
    except Exception as e:
        # ë…ì»¤ ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜ ë¡œê·¸ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        existing_logs = state.get("logs", "")
        if existing_logs and ("ERROR" in existing_logs or "Traceback" in existing_logs):
             logger.warning("âš ï¸ ë…ì»¤ ì—°ê²° ì‹¤íŒ¨. ìƒíƒœì— ì €ì¥ëœ í…ŒìŠ¤íŠ¸ìš© ë¡œê·¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
             logs = existing_logs 
        else:
             logger.error(f"âŒ ë…ì»¤ ë¡œê·¸ ìˆ˜ì§‘ ì—ëŸ¬: {str(e)}")
             logs = f"Dockerì—ì„œ ë¡œê·¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n(ë…ì»¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”)"
    
    user_prompt = f"""
    [ì‹œìŠ¤í…œ ë¡œê·¸]
    {logs[-4000:]} 
    
    ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ ì˜¤ë¥˜(Traceback, Exception, Timeout)ë¥¼ ì‹ë³„í•˜ì‹­ì‹œì˜¤.
    
    ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
    1. `read_file`: Tracebackì—ì„œ íŒŒì¼ ê²½ë¡œê°€ ë³´ì¼ ë•Œ ì½”ë“œë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ ì‚¬ìš©.
    2. `check_db`: 'ConnectionTimeout', 'MongoError' ë“± DB ê´€ë ¨ ì˜¤ë¥˜ ì‹œ ì‚¬ìš©.
    3. `check_sqs`: 'Empty Message', 'Boto3Error', ì²˜ë¦¬ ì§€ì—° ë°œìƒ ì‹œ ì‚¬ìš©.
    4. `check_system`: 'MemoryError', 'Kill signal', ì „ë°˜ì ì¸ ëŠë ¤ì§ ë°œìƒ ì‹œ ì‚¬ìš©.
    
    ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ë¶„ì„ì„ ì¢…ë£Œí•˜ê¸° ìœ„í•œ JSONì„ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
    """
    
    return {
        "logs": logs, 
        "messages": [HumanMessage(content=user_prompt)], 
        "iteration": 0,
        "error_count": 0
    }

def diagnose_node(state: LogAnalysisState):
    """
    [ë…¸ë“œ 2: ì—ëŸ¬ ì§„ë‹¨ ë° ì˜ì‚¬ê²°ì •]
    LLMì´ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ 'ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€' ì•„ë‹ˆë©´ 'ë¶„ì„ì„ ì¢…ë£Œí• ì§€' ê²°ì •í•©ë‹ˆë‹¤.
    """
    messages = state.get("messages", [])
    iteration = state.get("iteration", 0)
    logger.info(f"--- [ë¡œê·¸ ì—ì´ì „íŠ¸] 2ë‹¨ê³„: ì—ëŸ¬ ì§„ë‹¨ ì¤‘ (ë°˜ë³µ: {iteration}) ---")
    
    # ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    system_prompt = """
    ë‹¹ì‹ ì€ ì „ë¬¸ ë””ë²„ê¹… ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
    ëª©í‘œ: ì—ëŸ¬ì˜ ê·¼ë³¸ ì›ì¸(ì½”ë“œ, DB, SQS ë˜ëŠ” ì‹œìŠ¤í…œ)ì„ ì°¾ìœ¼ì‹­ì‹œì˜¤.
    
    ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤:
    1. **ë¡œê·¸ ë¶„ì„**: í‚¤ì›Œë“œë¥¼ ì°¾ìœ¼ì‹­ì‹œì˜¤.
       - ì½”ë“œ ì—ëŸ¬ -> `read_file` (ì£¼ì˜: ì¸ìëª…ì€ 'file_path'ë¥¼ ì‚¬ìš©)
       - DB ì—ëŸ¬ (Timeout, Connection) -> `check_db`
       - Queue/AWS ì—ëŸ¬ -> `check_sqs`
       - ë¦¬ì†ŒìŠ¤/í¬ë˜ì‹œ -> `check_system`
    
    2. **ì •êµí™”**: ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆë‹¤ë©´, ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ê·¸ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì‹­ì‹œì˜¤.
    
    ì¶œë ¥ í˜•ì‹ (JSON):
    - ë„êµ¬ ì‚¬ìš©: `{"action": "ë„êµ¬ì´ë¦„", "args": {...}, "reasoning": "ì´ìœ "}`
    - ì¢…ë£Œ: `{"action": "finish", "analysis": {"error_found": true, "summary": "ìš”ì•½(í•œêµ­ì–´)", "root_cause": "ì›ì¸(í•œêµ­ì–´)", "suggestion": "í•´ê²°ì±…(í•œêµ­ì–´)"}}`
    
    ëª¨ë“  ë¶„ì„ ê²°ê³¼(summary, root_cause, suggestion)ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    """
    
    try:
        llm = GeminiClient()
        response = llm.generate_json(messages[-1].content, system_prompt)
        logger.info(f"ğŸ¤– AI ê²°ì •: {json.dumps(response, ensure_ascii=False)}")
        
        return {"analysis_result": json.dumps(response, ensure_ascii=False), "iteration": iteration + 1}
        
    except Exception as e:
         logger.error(f"âŒ AI ì§„ë‹¨ ì‹¤íŒ¨: {str(e)}")
         return {"analysis_result": json.dumps({"action": "finish", "analysis": {"error_found": True, "summary": f"ì§„ë‹¨ ë„ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}"}})}

def tool_execution_node(state: LogAnalysisState):
    """
    [ë…¸ë“œ 3: ë„êµ¬ ì‹¤í–‰]
    `diagnose_node`ì—ì„œ ìš”ì²­í•œ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    raw_result = state.get("analysis_result")
    try:
        decision = json.loads(raw_result)
    except:
        logger.error("âŒ ë„êµ¬ ì‹¤í–‰ ë…¸ë“œì—ì„œ JSON íŒŒì‹± ì—ëŸ¬ ë°œìƒ.")
        return {"messages": [HumanMessage(content="JSON ì˜ì‚¬ê²°ì • íŒŒì‹± ì—ëŸ¬.")]}

    action = decision.get("action")
    args = decision.get("args", {})
    logger.info(f"ğŸ› ï¸ [ë¡œê·¸ ì—ì´ì „íŠ¸] 3ë‹¨ê³„: ë„êµ¬ '{action}' ì‹¤í–‰ ì¤‘...")
    
    tool_output = ""

    if action == "read_file":
        tool_output = execute_read_file(args)
    elif action == "check_db":
        tool_output = execute_check_db(args)
    elif action == "check_system":
        tool_output = execute_check_system(args)
    elif action == "check_sqs":
        tool_output = execute_check_sqs(args)
    
    if tool_output:
        logger.info(f"ğŸ“¥ ë„êµ¬ ê²°ê³¼ ìˆ˜ì‹  ({len(tool_output)} ë°”ì´íŠ¸).")
        # LLMì—ê²Œ ë„êµ¬ ê²°ê³¼ ì „ë‹¬
        feedback_msg = f"""
        [{action} ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]
        {tool_output}
        
        ì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê·¼ë³¸ ì›ì¸ì„ íŒŒì•…í–ˆìŠµë‹ˆê¹Œ?
        íŒŒì•…í–ˆë‹¤ë©´ finishë¥¼, ë” ì •ë³´ê°€ í•„ìš”í•˜ë©´ ë‹¤ë¥¸ ë„êµ¬ë¥¼ ìš”ì²­í•˜ì‹­ì‹œì˜¤.
        """
        messages = state.get("messages", [])
        messages.append(AIMessage(content=f"Executed {action}"))
        messages.append(HumanMessage(content=feedback_msg))
        
        return {"messages": messages}
    
    logger.warning("âš ï¸ ë„êµ¬ê°€ ì•„ë¬´ëŸ° ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return {}

# --- Conditional Edge (ë¶„ê¸° ì¡°ê±´) ---
def should_continue(state: LogAnalysisState):
    iteration = state.get("iteration", 0)
    raw_result = state.get("analysis_result")
    
    try:
        decision = json.loads(raw_result)
        action = decision.get("action")
        
        # ë„êµ¬ ì‚¬ìš© ìš”ì²­ì´ê³ , ë°˜ë³µ íšŸìˆ˜ê°€ 5íšŒ ë¯¸ë§Œì´ë©´ ê³„ì† ì§„í–‰
        if action in ["read_file", "check_db", "check_system", "check_sqs"] and iteration < 5: 
            logger.info(f"ğŸ”„ Routing to 'inspect_code' (Current Iteration: {iteration})")
            return "inspect_code"
        else:
            logger.info(f"ğŸ”š Routing to 'END' (Action: {action}, Iteration: {iteration})")
            return END 
    except:
        logger.error("âŒ Error in routing logic, forced to END.")
        return END

# --- Graph Construction (ê·¸ë˜í”„ ì¡°ë¦½) ---
workflow = StateGraph(LogAnalysisState)

# 1. ë…¸ë“œ ì¶”ê°€
workflow.add_node("fetch_logs", fetch_logs_node)      # ë¡œê·¸ ìˆ˜ì§‘
workflow.add_node("diagnose_error", diagnose_node)    # ë¶„ì„ ë° íŒë‹¨
workflow.add_node("inspect_code", tool_execution_node) # ì½”ë“œ ì¡°íšŒ (Tool)

# 2. ì—£ì§€ ì—°ê²° (íë¦„ ì •ì˜)
workflow.set_entry_point("fetch_logs")                # ì‹œì‘ì 
workflow.add_edge("fetch_logs", "diagnose_error")     # ìˆ˜ì§‘ -> ì§„ë‹¨

# 3. ë¶„ê¸° ë° ìˆœí™˜ ì„¤ì •
workflow.add_conditional_edges(
    "diagnose_error",
    should_continue,
    {
        "inspect_code": "inspect_code",  # ì½”ë“œ ë” ë´ì•¼ í•˜ë©´ -> inspect_code
        END: END                         # ë‹¤ ë´¤ìœ¼ë©´ -> ë
    }
)

workflow.add_edge("inspect_code", "diagnose_error") # ì½”ë“œ ë´¤ìœ¼ë©´ ë‹¤ì‹œ ì§„ë‹¨ (Loop Back)

app = workflow.compile()

