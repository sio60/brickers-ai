import docker
import logging
from datetime import datetime
from .state import LogAnalysisState

# DB Connection (Lazy import to avoid issues)
def get_db_collection():
    try:
        from ..yang_db import get_db
        db = get_db()
        return db["failed_job_logs"] if db is not None else None
    except:
        return None

logger = logging.getLogger("agent.log_analyzer.persistence")

async def archive_failed_job_logs(job_id: str, container_name: str = "brickers-ai-container"):
    """
    ì‹¤íŒ¨í•œ Jobì˜ ë¡œê·¸ë¥¼ Dockerì—ì„œ ì¶”ì¶œí•˜ì—¬ MongoDBì— ì•„ì¹´ì´ë¹™í•©ë‹ˆë‹¤.
    (Full Context ë³´ì¡´ ì „ëµ)
    """
    logger.info(f"ğŸ“¦ [ë¡œê·¸ ì•„ì¹´ì´ë¸Œ] Job ID [{job_id}] ë¡œê·¸ ë°±ì—… ì‹œì‘...")
    
    try:
        client = docker.from_env()
        container = client.containers.get(container_name)
        # ë„‰ë„‰í•˜ê²Œ ìµœê·¼ 5000ì¤„ ì •ë„ë¥¼ í›‘ì–´ì„œ í•´ë‹¹ Job IDê°€ í¬í•¨ëœ ë§¥ë½ì„ ë‹¤ ê¸ì–´ì˜´
        raw_logs = container.logs(tail=5000).decode("utf-8", errors="replace")
        
        job_logs = [line for line in raw_logs.splitlines() if job_id in line]
        
        if not job_logs:
            logger.warning(f"âš ï¸ [ë¡œê·¸ ì•„ì¹´ì´ë¸Œ] Job ID [{job_id}]ë¥¼ ë¡œê·¸ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return False
            
        full_log_text = "\n".join(job_logs)
        
        collection = get_db_collection()
        if collection is not None:
            doc = {
                "jobId": job_id,
                "logs": full_log_text,
                "timestamp": datetime.utcnow().isoformat(),
                "container": container_name,
                "status": "FAILED"
            }
            collection.replace_one({"jobId": job_id}, doc, upsert=True)
            logger.info(f"âœ… [ë¡œê·¸ ì•„ì¹´ì´ë¸Œ] Job ID [{job_id}] DB ì €ì¥ ì™„ë£Œ ({len(job_logs)}ì¤„)")
            return True
        else:
            logger.error("âŒ [ë¡œê·¸ ì•„ì¹´ì´ë¸Œ] DB ì—°ê²° ì‹¤íŒ¨.")
            return False
            
    except Exception as e:
        logger.error(f"âŒ [ë¡œê·¸ ì•„ì¹´ì´ë¸Œ] ì—ëŸ¬ ë°œìƒ: {str(e)}")
        return False

async def get_archived_logs(job_id: str) -> Optional[str]:
    """DBì—ì„œ ì•„ì¹´ì´ë¹™ëœ ë¡œê·¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    collection = get_db_collection()
    if collection is not None:
        doc = collection.find_one({"jobId": job_id})
        return doc.get("logs") if doc else None
    return None
