
import os
import json
import asyncio
import logging
from typing import Dict, Any, List, Optional
from pathlib import Path

# External Libraries
import trimesh
import numpy as np

# Project Modules
try:
    from ..llm_clients import OpenAIClient
    from ..memory_utils import MemoryUtils, build_hypothesis
    import config
except ImportError:
    # For standalone testing
    import sys
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))
    from llm_clients import OpenAIClient
    from memory_utils import MemoryUtils, build_hypothesis
    import config

logger = logging.getLogger("HypothesisMaker")


class HypothesisMaker:
    """
    Co-Scientist V2 í•µì‹¬ ë¡œì§
    - Shape Analysis: GLB í˜•íƒœ ë¶„ì„ (ë¶€í”¼, ë¹„ìœ¨)
    - Dual-Model RAG: 
        1. Gemini (Creator): ì„±ê³µ ì‚¬ë¡€ ê¸°ë°˜ ê³„íš ìˆ˜ë¦½
        2. GPT (Critic): ì‹¤íŒ¨ ì‚¬ë¡€ ê¸°ë°˜ ë¹„íŒ ë° ê°œì„ 
    """
    def __init__(self, memory_manager: MemoryUtils, gemini_client: Any):
        self.memory = memory_manager
        self.gemini_client = gemini_client
        
        # GPT Client (Critic)
        self.gpt_client = OpenAIClient(model_name="gpt-4o-mini")
        if not self.gpt_client.client:
            logger.warning("âš ï¸ GPT Client not available. Critic mode disabled.")

    def analyze_shape(self, glb_path: str) -> Dict[str, Any]:
        """
        GLB íŒŒì¼ì˜ ê¸°í•˜í•™ì  íŠ¹ì§•(Shape Fingerprint) ì¶”ì¶œ
        """
        try:
            mesh = trimesh.load(glb_path, force='mesh')
            
            # 1. Bounds & Dimensions
            bounds = mesh.bounds
            extents = mesh.extents
            
            # 2. Volume (Watertightê°€ ì•„ë‹ ìˆ˜ ìˆìœ¼ë¯€ë¡œ Convex Hull ì‚¬ìš©)
            try:
                volume = mesh.volume
            except:
                volume = mesh.convex_hull.volume
                
            # 3. Aspect Ratio (Width / Depth)
            # Y is up in GLB usually, but check extents logic
            width, height, depth = extents
            aspect_ratio = width / depth if depth > 0 else 1.0
            
            # 4. Center of Mass
            center_mass = mesh.center_mass.tolist() if hasattr(mesh, 'center_mass') else [0,0,0]

            metrics = {
                "volume": float(volume),
                "bbox_size": [float(x) for x in extents],
                "aspect_ratio": float(aspect_ratio),
                "center_mass": center_mass,
                "is_watertight": mesh.is_watertight
            }
            return metrics

        except Exception as e:
            logger.error(f"Shape analysis failed: {e}")
            return {}

    async def make_hypothesis(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        [Advanced Dual-Model Flow]
        1. Search: Success & Failure cases (Parallel)
        2. Draft (Gemini): Create initial plan based on Success cases
        3. Critique (GPT): Analyze Draft against Failure cases ("Does this plan look like a known failure?")
        4. Refine (Gemini): Finalize plan considering Critique
        """
        observation = state.get("observation", "")
        verification = state.get("verification_result", {})
        
        # 1. Shape Analysis (if new GLB available)
        shape_metrics = {} 
        # TODO: Integrate shape analysis if GLB path is available in state
        
        # 2. Dual-Search (Async)
        logger.info(f"ğŸ” ì´ì¤‘ ê²€ìƒ‰(Dual-Search) ì‹œì‘: {observation[:50]}...")
        rag_results = await asyncio.to_thread(
            self.memory.search_success_and_failure,
            observation=observation,
            limit=3,
            min_score=0.4,
            verification_metrics=verification,
            shape_metrics=shape_metrics
        )
        
        success_cases = rag_results.get("success", [])
        failure_cases = rag_results.get("failure", [])
        logger.info(f"âœ… ê²€ìƒ‰ ê²°ê³¼: ì„±ê³µ ì‚¬ë¡€ {len(success_cases)}ê±´ / ì‹¤íŒ¨ ì‚¬ë¡€ {len(failure_cases)}ê±´ ë°œê²¬")
        
        # 3. Gemini Draft (Based on Success)
        draft_hypothesis = await self._run_draft_creator(observation, success_cases, verification)
        logger.info(f"ğŸ“ Gemini ì´ˆì•ˆ(Draft): {draft_hypothesis.get('hypothesis')}")

        # 4. GPT Critic (Based on Failure + Draft)
        # GPTì—ê²Œ "Geminiê°€ ì´ëŸ° ê³„íšì„ ì§°ëŠ”ë°, ê³¼ê±° ì‹¤íŒ¨ ì‚¬ë¡€ë‘ ë¹„ìŠ·í•˜ë‹ˆ?" ë¼ê³  ë¬¼ì–´ë´„
        critique_result = await self._run_critic(failure_cases, draft_hypothesis, observation)
        logger.info(f"ğŸ§ GPT ë¹„í‰(Critique): {critique_result}")
        
        # 5. Gemini Refine (Final Synthesis)
        final_hypothesis = await self._run_final_creator(
            observation, 
            draft_hypothesis, 
            critique_result, 
            verification
        )
        logger.info(f"ğŸ’¡ ìµœì¢… ê°€ì„¤(Final Hypothesis): {final_hypothesis.get('hypothesis')}")
        
        return final_hypothesis

    async def _run_draft_creator(
        self, 
        observation: str, 
        success_cases: List[Dict], 
        verification: Dict
    ) -> Dict[str, Any]:
        """
        Gemini (Draft): ì„±ê³µ ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ˆì•ˆ ì‘ì„±
        """
        success_text = "\n".join([
            f"- Case {i+1}: Algo={c.get('algorithm', 'unknown')}, Params={c.get('experiment', {}).get('parameters')}, Shape={c.get('shape_metrics', {})}"
            for i, c in enumerate(success_cases)
        ])
        
        if not success_text:
            success_text = "ì§ì ‘ì ì¸ ì„±ê³µ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë¬¼ë¦¬í•™ ì›ë¦¬ì— ì˜ì¡´í•˜ì„¸ìš”."

        prompt = f"""
        You are a Structural Engineer Expert.
        
        [Current Context]
        Observation: {observation}
        Current Metrics: {json.dumps(verification.get('metrics_after', {}), indent=2)}
        
        [Tweakable Parameters]
        - target (int): Overall size. Decrease to reduce weight.
        - shrink (float: 0.1-1.0): Scales the model. Lower = smaller/lighter.
        - plates_per_voxel (int: 1-3): Vertical density. Higher = stronger but heavier.
        - support_ratio (float: 0.0-2.0): Support density. Higher = more stability.
        - fill (bool): Fill internal cavities. True = stronger.
        - interlock (bool): Overlap bricks. True = much stronger.
        - erosion_iters (int: 0-3): Removes thin parts. Higher = cleaner but might lose detail.
        - auto_remove_1x1 (bool): Removes weak 1x1 bricks. True = safer.
        - smart_fix (bool): Enable algorithmic repair logic.
        
        [Success Patterns]
        {success_text}
        
        Based ONLY on success patterns and physics, propose an initial hypothesis to fix the issue.
        Write the 'hypothesis' and 'reasoning' in Korean.
        Respond in JSON: 
        {{ 
            "hypothesis": "ê°€ì„¤ (í•œêµ­ì–´)", 
            "reasoning": "ê·¼ê±° (í•œêµ­ì–´)", 
            "proposed_params": {{
                "target": 60,
                "support_ratio": 1.2,
                ...
            }} 
        }}
        """
        try:
            # Fix: Wrap synchronous call in to_thread
            return await asyncio.to_thread(self.gemini_client.generate_json, prompt)
        except Exception as e:
            logger.error(f"ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"hypothesis": "General adjustment", "reasoning": "Draft failed"}

    async def _run_critic(self, failure_cases: List[Dict], draft: Dict, current_observation: str) -> str:
        """
        GPT-4o-mini (Critic): ë“œë˜í”„íŠ¸ê°€ ê³¼ê±° ì‹¤íŒ¨ì™€ ìœ ì‚¬í•œì§€ ê²€ì¦
        """
        if not self.gpt_client.client:
            return "ë¹„í‰ ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¨."
            
        if not failure_cases:
            return "ìœ ì‚¬í•œ ì‹¤íŒ¨ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤. ì£¼ì˜í•´ì„œ ì§„í–‰í•˜ì„¸ìš”."

        failures_text = "\n".join([
            f"- Failure {i+1}: Algo={c.get('algorithm', 'unknown')}, Params={c.get('experiment', {}).get('parameters')}, Cause={c.get('improvement', {}).get('lesson_learned')}"
            for i, c in enumerate(failure_cases)
        ])
        
        draft_summary = f"Plan: {draft.get('hypothesis')}, Params: {draft.get('proposed_params')}"
        
        prompt = f"""
        Review this proposed plan against past failures.
        
        [Proposed Plan]
        {draft_summary}
        
        [Past Failures for similar issue "{current_observation}"]
        {failures_text}
        
        Task:
        1. Does the proposed plan resemble any past failure?
        2. Identify specific risks.
        3. Suggest 1 concrete modification to avoid failure (Write this in Korean!).
        
        Be concise. Write everything in Korean.
        """
        
        try:
            return await asyncio.to_thread(self.gpt_client.generate, prompt)
        except Exception as e:
            logger.error(f"ë¹„í‰ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ë¹„í‰ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ."

    async def _run_final_creator(
        self, 
        observation: str, 
        draft: Dict, 
        critique: str, 
        verification: Dict
    ) -> Dict[str, Any]:
        """
        Gemini (Refine): ì´ˆì•ˆ + ë¹„íŒì„ ë°˜ì˜í•˜ì—¬ ìµœì¢… ê°€ì„¤ ìˆ˜ë¦½
        """
        prompt = f"""
        Finalize the structural hypothesis.
        
        [Draft Plan]
        {draft.get('hypothesis')} (Reason: {draft.get('reasoning')})
        
        [Critic Feedback (Risk Analysis)]
        {critique}
        
        [Task]
        Refine the draft plan to address the critic's warnings. 
        If the critic found no issues, expand on the draft.
        Ensure you provide a complete set of proposed parameters in JSON format.
        
        CRITICAL: All text fields ("hypothesis", "reasoning", "prediction") MUST be in Korean.
        
        Respond in JSON:
        {{
            "hypothesis": "ìµœì¢… ê°€ì„¤ (í•œêµ­ì–´)",
            "reasoning": "ì™œ ì´ ë°©ë²•ì´ ì•ˆì „í•˜ê³  íš¨ê³¼ì ì¸ì§€ (í•œêµ­ì–´, ë¹„í‰ê°€ ë‚´ìš© ì¸ìš©)",
            "prediction": "ì˜ˆìƒë˜ëŠ” ê²°ê³¼ (í•œêµ­ì–´)",
            "proposed_params": {{
                "target": 60,
                "shrink": 0.8,
                "plates_per_voxel": 3,
                "support_ratio": 1.2,
                "fill": true,
                "interlock": true,
                "erosion_iters": 1,
                "auto_remove_1x1": true,
                "smart_fix": true,
                "step_order": "bottomup"
            }}
        }}
        """
        try:
            # Fix: Wrap synchronous call in to_thread
            return await asyncio.to_thread(self.gemini_client.generate_json, prompt)
        except Exception as e:
            logger.error(f"ìµœì¢… ìƒì„± ì‹¤íŒ¨: {e}")
            return draft # Fallback to draft
